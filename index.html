<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Life Career</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Life Career">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Life Career">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Life Career">
  
    <link rel="alternate" href="/atom.xml" title="Life Career" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Life Career</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-笔记：redis设计与实现" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/20/笔记：redis设计与实现/" class="article-date">
  <time datetime="2019-01-20T03:00:07.000Z" itemprop="datePublished">2019-01-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/20/笔记：redis设计与实现/">笔记：redis设计与实现</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="redis设计与实现笔记（一）：redis数据结构介绍"><a href="#redis设计与实现笔记（一）：redis数据结构介绍" class="headerlink" title="redis设计与实现笔记（一）：redis数据结构介绍"></a>redis设计与实现笔记（一）：redis数据结构介绍</h2><h3 id="redis用到的几种数据结构："><a href="#redis用到的几种数据结构：" class="headerlink" title="redis用到的几种数据结构："></a>redis用到的几种数据结构：</h3><ul>
<li>简单动态字符串SDS，Simple Dynamic String</li>
<li>链表</li>
<li>字典</li>
<li>跳表</li>
<li>整数集合</li>
<li>压缩列表</li>
<li>对象</li>
</ul>
<h3 id="底层数据结构"><a href="#底层数据结构" class="headerlink" title="底层数据结构"></a>底层数据结构</h3><ul>
<li>SDS<ul>
<li>SDS的结构。通过一个length属性表示字符串长度，free属性表示剩余可用长度，char[]属性记录字符串值，用以适应redis中使用C字符串产生的不足</li>
</ul>
</li>
<li>链表。linkedlist<ul>
<li>就是一般的链表结构，C语言没有链表数据结构，所以Redis自己进行了实现</li>
<li>Redis链表的一些特征：双向、无环、带表头表尾指针、长度计数器、多态</li>
</ul>
</li>
<li>字典。又称符号表（Symbol Table），关联数组（associative array），或映射（map），用于保存键值对<ul>
<li>类似于java中的HashMap，因为C语言没有这个结构，所以Redis自己进行了实现</li>
<li>Redis的数据库就是通过字典来实现</li>
<li>dict数据结构包含一个长度为2的哈希表dictht数组，一个dictType指针保存不同类型对象的哈希等处理方法，哈希表内部使用链表来处理哈希冲突</li>
<li>当loadfactor过高时（有BGSAVE或BGREWRITEAOF运行时=5，没有时=1），会触发Redis rehash操作，渐进式rehash执行过程中的相关操作都要在dictht[1]上也执行对应的操作（如添加新的键值对时，也要rehash到dictht[1]）</li>
<li>MurmurHash2算法：名字来源于MU（multiply）R（Rotate），很多开源项目都在使用（Redis、Lucene、Memcached等），与其它流行hash算法相比，对于规律性较强的key，MurmurHash随机分布特征表现更良好，key大于10时运行速度更快</li>
</ul>
</li>
<li>跳表。skiplist是一个平均O(LogN)，最坏O(N)查找复杂度的有序数据结构，性能可以媲美平衡树，但是实现比平衡树简单，所以不少程序使用跳表来替代平衡树<ul>
<li>跳表是有序集合的底层实现之一，包含zskiplist和zskiplistNode两个数据结构，zskiplist记录跳表的头尾、长度等基础信息</li>
<li>节点按分值大小有序排列，当分值相同时，按对象自身的大小比较逻辑排列</li>
</ul>
</li>
<li>整数集合intset。当一个集合只包含整数元素且数量不多时，Redis就会使用整数集合作为集合的底层实现<ul>
<li>ordered、distinct方式保存数值</li>
<li>有利于更高效的处理整数类型的小集合，如状态位、标志位、或者我们业务中常用到的代理商列表</li>
<li>主要通过对数字类型进行保守处理（用最小的长度）来节约整数消耗的内存</li>
<li>因为可能涉及O(N)的类型变更和内存再分配，所以不适用大集合</li>
</ul>
</li>
<li>压缩列表ziplist。压缩列表是哈希和列表的底层实现之一，当一个列表只包含少量数据，且只有小整数或短字符串时，Redis就会使用压缩列表来实际存储这些数据，从而节约内存<ul>
<li>encoding属性记录数据的类型及长度</li>
<li>跟java的不同主要在于列表底层类型不固定，可以重新分配数据类型，重新分配内存，Redis中涉及很多类似的设计</li>
<li>previous_entry_length更新可能会导致连锁更新（当列表元素长度变大，例如原始1字节254字节以内，变为500字节，就需要将previous_entry_length扩展），所以也不使用大集合</li>
<li>用连续内存存储，相比hashtable减小了内存碎片；节省了指针占用的内存；</li>
</ul>
</li>
<li>对象。Redis并没有直接使用上述数据结构来实现kv数据库，而是基于这些数据结构创建了一个对象系统，包括字符串对象、列表对象、哈希对象、集合对象、有序集合对象<ul>
<li>使用对象的好处：<ul>
<li>Redis命令执行前，可以根据对象的类型来判断一个对象是否可以执行给定的命令。</li>
<li>针对不同的使用场景，从上述底层数据结构中选择合适的底层实现，从而优化不同场景的性能</li>
</ul>
</li>
<li>Redis实现了基于引用计数的内存回收机制</li>
<li>Redis实现了对象共享机制，通过共享数据来节约内存</li>
<li>Redis对象的定义：type、encoding、ptr(底层数据结构)</li>
</ul>
</li>
</ul>
<h3 id="上层数据结构"><a href="#上层数据结构" class="headerlink" title="上层数据结构"></a>上层数据结构</h3><ul>
<li>String对象的底层实现：<pre><code>- int。保存整数值
- embstr。小于39字节的字符串、long double浮点数
- raw。大于39字节字符串、long double浮点数
</code></pre></li>
<li>列表对象list底层：<ul>
<li>ziplist。字符串长度小于64字节，元素个数小于512个。</li>
<li>linkedlist。</li>
</ul>
</li>
<li>哈希对象底层：<ul>
<li>ziplist。key-value都小于64字节，元素数小于512个。随机访问和写入都是O(N)复杂度</li>
<li>hashtable。内存占用大，O(1)随机访问和写入复杂度</li>
</ul>
</li>
<li>集合对象set底层：<ul>
<li>intset。当所有数据都是整数且数量不多于512时</li>
<li>hashtable。</li>
</ul>
</li>
<li>有序集合对象zset：<ul>
<li>ziplist。元素小于64字节且数量不多于128个</li>
<li>zset。使用一个跳表和一个dict共同实现。跳表用于有序查找，dict保存元素的score用于随机获取分值</li>
</ul>
</li>
</ul>
<h3 id="其它数据特性"><a href="#其它数据特性" class="headerlink" title="其它数据特性"></a>其它数据特性</h3><ul>
<li>命令类型检查。检查对象是否支持当前命令，否则返回错误提示</li>
<li>命令多态。针对不同的底层数据结构，路由到对应的底层API</li>
<li>引用计数支持的内存回收和对象共享（只共享0-9999数字）</li>
<li>空转时长支持内存LRU</li>
</ul>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><ul>
<li>可以看到Redis实现，做了许多内存友好性的工作，例如自建的字符串结构、intset、ziplist等，有些场景甚至牺牲了部分性能来优化内存，这是Redis的取胜之道</li>
</ul>
<h2 id="redis设计与实现笔记（二）：单机数据库实现"><a href="#redis设计与实现笔记（二）：单机数据库实现" class="headerlink" title="redis设计与实现笔记（二）：单机数据库实现"></a>redis设计与实现笔记（二）：单机数据库实现</h2><h3 id="数据库基础"><a href="#数据库基础" class="headerlink" title="数据库基础"></a>数据库基础</h3><ul>
<li>服务器状态类redisServer，redisServer包含一个redisDB数组表示数据库，并通过配置指定dbNum个数据库。默认redisClient访问的是db[0]，可以通过select命令指定数据库。</li>
<li>redisDb结构主要属性是一个dict字典结构，这个dict保存了数据库中所有的键值对，这个字典称为键空间（key space）</li>
<li>一般的增删改查操作都是在这个dict进行的，可以理解为java map中的相关的get/set等操作，并针对不同的对象进行了扩展，比如如果map的对象还是一个map，支持hset/hget等。</li>
<li>redisDb还会维护一些常用基本信息，比如keyCount，keyspace_hits，keyspace_misses等</li>
<li>过期时间相关操作：expire/expireAt/setex/ttl等。过期之后相应的key就无法查询到，数据库会通过一定的策略删除过期key</li>
<li>redisDb结构包含一个expires字典，保存了数据库中所有key的过期时间，通过该字典支持上述的过期相关的操作</li>
<li>过期键删除策略<ul>
<li>定时删除。设置过期键的同时，创建一个定时器（Timer），让定时器在键的过期时间来临时，立即对键执行删除操作。内存最友好、CPU最不友好，难以实现。</li>
<li>惰性删除。CPU最友好，内存最不友好，且如果大量键不再被访问或很少被访问，效果会等同于内存溢出，只能手动FLUSHDB</li>
<li>定期删除。定时和惰性的折中方案，定期删除，并设置执行时间和频率减少对CPU影响。Redis通过一个随机策略来执行，而不是遍历</li>
</ul>
</li>
</ul>
<h3 id="RDB持久化"><a href="#RDB持久化" class="headerlink" title="RDB持久化"></a>RDB持久化</h3><ul>
<li>RDB文件是一个压缩的二进制文件，用于对redis数据库进行持久化，防止数据丢失。RDB文件不同于AOF，它存储的是持久化时数据库的快照，而AOF类似于数据库binlog和事件流</li>
<li>SAVE 阻塞式的持久化，BGSAVE异步非阻塞式生成RDB文件</li>
<li>自动定期保存，可以结合更新操作的频率设置不同的条件，定期自动通过BGSAVE进行持久化保存，比如60s内执行了1000次更新，300秒内执行了100次更新，1000秒内执行了1次更新等。这个操作有ServerCron定期执行，默认100毫秒就会执行一次</li>
<li>RDB文件结构。RDB文件持久化或从RDB加载时的文件格式，涉及一些文件checksum校验，压缩存储等基本思想，不在这里一一罗列，请参考原作了解</li>
</ul>
<h3 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h3><ul>
<li>AOF（append only file）、RDB和replication对过期键的处理<ul>
<li>生成RDB不会写入过期键</li>
<li>载入RDB取决于启动模式，主服务器模式不载入过期键，从服务器会载入过期键</li>
<li>AOF写入。没有影响，append DEL记录即可</li>
<li>AOF重写。与生成RDB类似，不写入过期键</li>
<li>replication。由主服务器进行删除管理，从服务器存在过期数据被读取到的可能，这种模式可以保证主从服务器数据一致性</li>
</ul>
</li>
<li>AOF持久化可以分为命令追加（append）、文件写入、文件同步（sync）</li>
<li>AOF处于打开时，服务器执行完一个写命令后，会按协议将被执行的命令追加写入到redisServer.aof_buf缓冲区</li>
<li>AOF文件写入和同步，可以指定不同的策略进行写入和落盘；特别敏感的场景也可以配置Redis绕过操作系统的写文件缓存，防止数据丢失</li>
<li>AOF载入。通过载入AOF文件完成数据还原，相当于事件流架构（Event Architecture and Event Streaming）中使用时间溯源</li>
<li>AOF重写。防止AOF爆炸，实际上是从当前数据库快照去虚拟写入一个key-val的操作，写入到rewrite之后的AOF文件中，这样删除的key就不再有AOF记录，多次修改的key也仅有一个写入AOF记录，从而减小AOF文件大小。通过BGREWRITEAOF后台实现，后台执行时，其它命令的执行还要写入新的AOF记录，在rewrite完成之后再追加这些记录即可</li>
</ul>
<h3 id="数据库通知。"><a href="#数据库通知。" class="headerlink" title="数据库通知。"></a>数据库通知。</h3><ul>
<li>Redis2.8新增的功能，可以让客户端订阅给定的频道或者模式，获知数据库中键的变化和命令的执行情况</li>
<li>发送通知的实现：在相关操作完成后，调用通知函数</li>
</ul>
<h3 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h3><ul>
<li><p>Redis服务器实际上是一个事件驱动程序，处理两类事件：</p>
<ul>
<li>文件事件。Redis服务器通过套接字与客户端或其它Redis服务器进行连接，文件事件是服务器对套接字操作的抽象。服务器与客户端的通信操作会产生相应的文件事件，服务器通过监听和处理这些事件来完成网络通信操作</li>
<li>时间事件。对Redis服务器中需要定时执行的操作的抽象</li>
</ul>
</li>
<li><p>文件事件。 Redis基于reactor模式实现了自己的网络事件处理器，称为文件事件处理器。</p>
<ul>
<li>使用I/O多路复用程序来同时监听多个套接字，并根据套接字正在执行的任务来为套接字关联不同的时间处理器</li>
<li>当被监听的套接字准备好执行accept、read、write、close等操作时，操作相对应的文件事件就会产生，文件事件处理器随机调用套接字关联好的事件处理器来处理这些事件</li>
<li>Redis自己封装了select，epoll，evport，kqueue等函数库</li>
<li>事件类型：<ul>
<li>当事件变得可读时（客户端对套接字执行write，close操作，或有新的acceptable套接字出现），套接字产生AE_READABLE事件</li>
<li>当事件变得可写时（客户端对套接字执行read操作），套接字产生AE_WRITABLE事件</li>
<li>先处理读事件，再处理写事件</li>
</ul>
</li>
<li>文件事件处理器<ul>
<li>连接应答处理器。对连接服务器的客户端进行应答</li>
<li>命令请求处理器。接收客户端传来的命令请求。</li>
<li>命令回复处理器。向客户端返回命令执行结果。</li>
<li>复制处理器。主从服务器进行复制操作。</li>
</ul>
</li>
</ul>
</li>
<li><p>时间事件</p>
<ul>
<li>分类<ul>
<li>定时事件</li>
<li>周期性事件</li>
</ul>
</li>
<li>用一个链表来存储时间事件，实际上一般只有serverCron一个时间事件    - serverCron默认1秒执行10次，它完成一些常见的服务器后台工作：<ul>
<li>更新服务器统计信息，如时间、内存占用等</li>
<li>删除过期key</li>
<li>清理失效链接</li>
<li>尝试AOF和RDB持久化</li>
<li>主从同步</li>
<li>集群心跳测试和同步</li>
</ul>
</li>
</ul>
</li>
<li><p>事件调度与执行</p>
<ul>
<li>注意所有的事件都是同步、有序、原子的执行的，不存在中断事件和事件抢断的问题。</li>
<li>耗时的事件通过子线程后台执行</li>
<li>某些可能耗时的操作提供了主动让出执行权的机制，从而防止饥饿</li>
</ul>
</li>
</ul>
<h3 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h3><ul>
<li>Redis为每个连接创建redisClient结构对象，以链表的形式保存在redisServer中，redisClient保存了当前客户端的状态信息，包括socket、名字、flag、身份验证、输入输出buffer、最后连接时间等</li>
</ul>
<h3 id="服务器"><a href="#服务器" class="headerlink" title="服务器"></a>服务器</h3><ul>
<li><p>命令请求执行过程</p>
<ul>
<li>客户端发送命令请求<ul>
<li>用户输入命令</li>
<li>按协议格式转换命令</li>
</ul>
</li>
<li>服务器接收并执行命令<ul>
<li>套接字读取到客户端命令请求，将其保存到对应客户端对象的输入缓冲区</li>
<li>事件分派器分发到对应的事件处理器</li>
<li>提取命令、参数、参数个数，分别存到argv和argc参数中</li>
<li>调用命令执行器，执行命令</li>
<li>命令执行器（一）根据客户端传来的命令名，从命令字典查找实现命令RedisCommand对象</li>
<li>命令执行器（二）执行预备操作</li>
<li>命令执行器（三）调用命令的实现函数，包括映射到具体数据结构的操作命令</li>
<li>命令执行器（四）添加AOF记录、慢日志、replication广播等</li>
</ul>
</li>
<li>服务器返回执行结果<ul>
<li>写入输出缓冲区，通过命令回复处理器发送命令回复。</li>
<li>客户端接收并输出执行结果<ul>
<li>从服务器获取到协议格式的回复</li>
<li>解析回复并输出</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>ServerCron</p>
<ul>
<li>更新服务器时间缓存。Redis保存有一个时间缓存，用于一些对时间精度要求不高的场景使用该缓存，减小获取时间系统调用，serverCron要定期更新这个缓存</li>
<li>更新LRU时钟。lruclock是一个估算值，因此使用定时更新的方式处理，每10s处理一次</li>
<li>更新服务器每秒执行命令数。通过1/1000抽样估算每秒执行命令数</li>
<li>更新服务器内存峰值。</li>
<li>处理SIGTERM信号，优雅退出</li>
<li>管理客户端资源。释放超时链接等</li>
<li>管理数据库资源。删除过期键等</li>
<li>执行被延迟的BGREWRITEAOF</li>
<li>FLUSH AOF缓冲区</li>
</ul>
</li>
<li><p>初始化服务器</p>
<ul>
<li>初始化服务器状态结构。创建redisServer数据结构，并初始化一些默认配置</li>
<li>载入配置。</li>
<li>初始化服务器数据结构。server.clients链表、server.db数组、共享对象、打开AOF文件等</li>
<li>还原数据库状态。从AOF或RDB文件恢复数据库</li>
<li>执行事件循环。开启事件while-true循环</li>
</ul>
</li>
</ul>
<h3 id="思考："><a href="#思考：" class="headerlink" title="思考："></a>思考：</h3><ul>
<li>redis multi databases的意义？schema用于在某些场景替代新增节点或不必要的集群化，从而简化更多节点或集群化的监控和管理成本。<a href="https://stackoverflow.com/questions/16221563/whats-the-point-of-multiple-redis-databases" target="_blank" rel="external">https://stackoverflow.com/questions/16221563/whats-the-point-of-multiple-redis-databases</a></li>
<li>redis服务器实质上是一个事件处理循环，并且尽可能的使用单进程、单线程、顺序阻塞的模式处理文件事件和时间事件，降低了系统的复杂度，且由于redis通过IO多路复用、内存方面的高效，这种模式也没有对响应速度造成影响。</li>
</ul>
<h2 id="redis设计与实现笔记（三）：集群数据库实现"><a href="#redis设计与实现笔记（三）：集群数据库实现" class="headerlink" title="redis设计与实现笔记（三）：集群数据库实现"></a>redis设计与实现笔记（三）：集群数据库实现</h2><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><ul>
<li>Redis2.8以前不能高效的处理断线后复制的情况，2.8的部分重同步功能解决</li>
<li>部分重同步通过复制偏移量、复制积压缓冲区、服务器运行ID三个部分实现</li>
<li>主服务器向从服务器传播命令来更新从服务器状态，保持主从一致</li>
<li>从服务器向主服务器发送心跳，以及检测命令丢失</li>
</ul>
<h3 id="Sentinel"><a href="#Sentinel" class="headerlink" title="Sentinel"></a>Sentinel</h3><ul>
<li>Sentinel是Redis高可用性high availability的解决方案：由一个或多个Sentinel实例组成的Sentinel系统可以监视任意多个主服务器及其所有从服务器。能够在主服务器下线时，自动将下线主服务器对应的某个从服务器升级为新的主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。<ul>
<li><ol>
<li>Sentinel只是一个运行在特殊模式下的Redis服务器，它使用了和普通模式不同的命令表</li>
</ol>
</li>
<li><ol>
<li>Sentinel会读入用户指定的配置文件，为每个要监视的主服务器创建相应的实例结构，并创建连接向主服务器的命令连接和订阅连接，命令连接用于向主服务器发送命令请求，订阅连接用于接收指定频道的消息</li>
</ol>
</li>
<li><ol>
<li>Sentinel通过向主服务器发送INFO命令，获得主服务器下所有从服务器列表，为这些从服务器创建实例结构、命令连接和订阅连接</li>
</ol>
</li>
<li><ol>
<li>一般情况下，Sentinel以10s一次频率向被监视的服务器发送INFO命令，当主服务器处于下线状态或故障转移状态时，频率提高到1s一次</li>
</ol>
</li>
<li><ol>
<li>监视同一个服务器的多个sentinel，会以2s一次的频率向被监视服务器的<strong>sentinel</strong>:hello频道发送消息向其它Sentinel宣告自己的存在</li>
</ol>
</li>
<li><ol>
<li>Sentinel与Sentinel之间只创建命令连接</li>
</ol>
</li>
<li><ol>
<li>Sentinel以1s一次的频率向其它实例（主服务器、从服务器、其它Sentinel）发送PING请求，当连续PING不通时Sentinel会将这个实例判定为主观下线</li>
</ol>
</li>
<li><ol>
<li>当Sentinel判定一个主服务器下线时，它会向其它监视这个主服务器的Sentinel询问，看它们是否同意主观下线</li>
</ol>
</li>
<li><ol>
<li>当收集足够多的主观下线投票时，Sentinel会判定服务器客观下线，随后发起故障转移操作</li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><ul>
<li>Redis集群是Redis提供的分布式数据库方案，集群通过分片（sharding）进行数据共享，并提供复制和故障转移功能。</li>
<li><p>集群节点</p>
<ul>
<li>使用MEET命令将某个目标服务器加入当前服务器所在的集群，需要在Redis启动前开启cluster-enabled选项</li>
<li>除了集群模式下特有的数据结构clusterNode、clusterLink、clusterState，还会完整使用单机模式下的所有结构和功能</li>
<li>MEET命令实现上，就是两个节点通信，并分别在本地为对方创建clusterNode数据结构</li>
</ul>
</li>
<li><p>槽指派</p>
<ul>
<li>槽slot相当于数据分片，0-16383个槽必须全部分配到某个节点上，且处于服务状态，集群才可用。使用CLUSTER ADDSLOT手动指派槽</li>
<li>槽指派信息用一个bitmap（2048个字节的位数组）来记录，且不同节点的信息会互相同步到集群所有节点的clusterNode对象保存</li>
<li>clusterState中还要反向记录一个slot-node的映射信息（槽指派信息）</li>
<li>CLUSTER ADDSLOTS实现：检查slots是否被占用，若没被占用就分别更新和传播clusterState.slots和slotbit信息</li>
<li>key-&gt;槽映射。CRC16(key) &amp; 16383</li>
<li>重新分片。Redis的集群管理工具redis-trib进行了封装。基本原理是一个一个节点处理，在目标服务器写入slots相关数据，在原服务器删除slots相关数据，并完成数据迁移</li>
<li>重新分片的数据迁移过程中，可能出现同样的slot，有的key在原服务器上，有的key在目标服务器上，这时候通过slot-to-key数据结构可以进行错误提示或命令重定位（ASK错误）</li>
</ul>
</li>
<li><p>复制与故障转移</p>
<ul>
<li>主从节点各有相关的标志位来标示，从节点的clusterNode结构中保存了指向主节点的指针</li>
<li>通过PING来互相获知其它节点的服务状态，并互相同步/报告下线的服务器（创建新的clusterNodeFailReport结构），当半数以上主节点认为某个主节点疑似下线，集群就会广播其客观下线的消息，并触发故障转移</li>
<li>故障转移步骤：选出新的主节点候选-&gt;候选设置主节点标记正式成为主节点-&gt;迁移已下线主节点的slot信息到新的主节点-&gt;新主节点向集群广播PONG消息，表明自己正式成为主节点-&gt;新的主节点开始处理自己负责的槽对应的相关命令</li>
<li>主节点选举。由其它主节点投票，从节点向所有其它主节点发送消息，当收到确认后，对应的主节点就投了发送消息的从节点一票（结果似乎谁先发声谁占优势），获得N/2+1及以上个投票的从节点会成为新的主节点。涉及算法：Raft算法的领头选举方法leader election</li>
</ul>
</li>
<li><p>消息。集群中的节点通过message来通信，一个message包括header和data两个部分，主要有5种消息：</p>
<ul>
<li>MEET。请求receiver加入sender所在的集群</li>
<li>PING。随机发送PING消息到某个已知节点，若超过一定阈值没发送也会发送（防止随机产生饥饿）</li>
<li>PONG。用于响应MEET或PING，也用于直接向集群其它节点广播当前状态，比如故障转移时选举出来的主节点准备好后，向集群确认自己成为主节点</li>
<li>FAIL。向集群广播某主服务器下线</li>
<li>PUBLISH。广播某个命令</li>
</ul>
</li>
</ul>
<h2 id="redis设计与实现笔记（四）：独立功能"><a href="#redis设计与实现笔记（四）：独立功能" class="headerlink" title="redis设计与实现笔记（四）：独立功能"></a>redis设计与实现笔记（四）：独立功能</h2><h3 id="发布-订阅"><a href="#发布-订阅" class="headerlink" title="发布/订阅"></a>发布/订阅</h3><ul>
<li>支持发布/订阅、模式订阅（PUBLISH/SUBSCRIBE/PSUBSCRIBE）</li>
<li>redisServer结构中保存有频道订阅关系的dict结构，pubsub_channels</li>
<li>SUBSCRIBE命令就是向pubsub_channels字典的某个频道对应的链表（没有则创建）添加自己的服务器，UNSUBSCRIBE正好相反</li>
<li>模式订阅用另一个数据结构pubsub_patterns链表来存储</li>
<li>PSUBSCRIBE命令向pubsub_patterns链表添加新的节点，UNPSUBSCRIBE相反</li>
<li>发送消息时，需要分别向channel和其匹配pattern的订阅者发送消息。<ul>
<li>向channel发送消息时，遍历channel下的订阅方链表，逐个向subscriber发送消息</li>
<li>向pattern发送消息时，遍历pattern链表，找到所有跟channel匹配的的subscriber，逐个发送消息</li>
</ul>
</li>
<li>查看订阅信息PUBSUB命令，查询相关结构并打印数据</li>
</ul>
<h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><ul>
<li>基本流程<ul>
<li>Redis使用MULTI、EXEC、WATCH等命令实现事务功能。</li>
<li>MULTI命令开启事务模式，在事务模式下，不属于MULTI//EXEC/WATCH/DISCARD的命令不会被马上执行，而是加入到事务队列中</li>
<li>redisClient.multiState用FIFO队列记录了等待被事务执行的命令列表</li>
<li>服务器端收到EXEC命令后，会按顺序执行队列中的命令，并将每个命令的执行结果加入结果队列，最后重置事务状态，返回执行结果队列</li>
</ul>
</li>
<li>WATCH<ul>
<li>WATCH是一个乐观锁，用于监视一个或多个指定的key，当key发生变化时，服务器会拒绝执行事务</li>
<li>被监视的key用redisDB.watched_keys字典存储</li>
<li>监视触发。写命令（PUSH、SET、SADD等）执行后，会通过watched_keys字典检查当前key是否被监视，如果被监视，就将监视key的客户端的REDIS_DIRTY_CAS标记打开，表示该客户端的事务安全性已被破坏</li>
</ul>
</li>
<li>ACID。传统数据库中，唱唱用ACID检验事务功能的可靠性和安全性<ul>
<li>Atomicity。原子性上，Redis满足要么全执行，要么全不执行的准则，但是不支持回滚机制，如果有一个命令执行错误，剩余的命令也会被完整的执行。作者antirez在事务的文档中解释为回滚这种复杂的功能和Redis追求的简单高效的设计主旨不相符，而且他认为，Redis事务的执行时错误通常都是编码问题导致的，生产环境很少遇到这种问题。</li>
<li>Consistency。一致性上，WATCH命令可以控制脏读脏写，入队错误、执行错误和服务器停机异常场景都进行了覆盖，不会产生非法或无效错误数据</li>
<li>Isolation。隔离性上，Redis是单线程执行事务和命令的，也不会在事务执行期间中断事务，因此Redis事务总是以串行方式执行的，并且也总是有隔离性的</li>
<li>Durability。Redis事务没有涉及单独的持久化逻辑，如果有必要可以在事务中手动加入SAVE命令，但是这样做效率太低，不具有实用性</li>
</ul>
</li>
</ul>
<h3 id="Lua脚本"><a href="#Lua脚本" class="headerlink" title="Lua脚本"></a>Lua脚本</h3><ul>
<li>Lua脚本是一个小巧的脚本语言，一个完整的Lua解释器不超过200k，由C语言写成，设计目的是为了嵌入应用程序，使应用程序可以灵活的扩展和定制功能。</li>
<li>Redis使用Lua的目的和场景<ul>
<li>减小网络开销。一次性传输多个命令，且脚本存储到服务器端，可以重复调用</li>
<li>原子操作。</li>
<li>源码小巧、速度快、可移植</li>
<li>模块化一些常用操作</li>
<li>一些redis使用Lua的场景。限流：<a href="https://www.cnblogs.com/yanghuahui/p/3697996.html" target="_blank" rel="external">https://www.cnblogs.com/yanghuahui/p/3697996.html</a> 库存：<a href="https://www.cnblogs.com/yanghuahui/p/3697996.html" target="_blank" rel="external">https://www.cnblogs.com/yanghuahui/p/3697996.html</a></li>
</ul>
</li>
<li>Redis启动时会对内嵌的Lua环境执行一系列修改操作，从而确保内嵌的Lua环境可以满足redis在功能性、安全性等方面的需求</li>
<li>Redis服务器专门使用一个伪客户端执行Lua脚本中包含的Redis命令</li>
</ul>
<h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><ul>
<li>SORT可以对列表、集合、有序集合进行排序，底层使用快速排序算法。</li>
<li>SORT <key> 实现<ul>
<li>创建一个redisSortObject结构数组tmp[]，并将数组tmp[]的元素指向要排序的列表的元素O(N)</li>
<li>计算并写入每个tmp[]数组项的double评分score O(N)</li>
<li>tmp[]按值进行排序</li>
<li>按tmp[]顺序，获取原数组的元素组成返回结果</li>
</ul>
</key></li>
<li>ALPHA选项实现。上述sort <key>的实现中，第三步值排序换成字符串排序</key></li>
<li>ASC/DESC调整。调节排序过程中的排序比对算法即可</li>
<li>BY实现。根据模式找出相应的值，并调整排序过程</li>
<li>LIMIT实现。</li>
<li>GET选项实现。（这里Foreign Key形式的松散对象的模型看着有些别扭）</li>
<li>STORE选项。将排序结果存储到一个指定的key中，以复用结果</li>
</ul>
<h3 id="二进制位数组"><a href="#二进制位数组" class="headerlink" title="二进制位数组"></a>二进制位数组</h3><ul>
<li>Redis提供了SETBIT、GETBIT、BITCOUNT、BITOP四个命令来操作位数组</li>
<li>SETBIT、GETBIT算法比较简单，通过X/8和X%8+1找到对应的字节对应的位完成读写操作即可</li>
<li>BITCOUNT则要复杂一些，下面罗列常见的算法：<ul>
<li>遍历。不具体阐述，复杂度O(N)</li>
<li>查表法。按字节或多个字节创建不同字节到BITCOUNT的表，例如，用一个字节来创建表，可以一次获知1000 0000的BITCOUNT是1，对每个字节进行操作再求和，算法复杂度直接降到O(N/8)。扩大表的范围（2个以上字节）理想情况下能更多的提升性能O(N/x*8)，但是受限于内存，CPU缓存，实际上不容易实现，效果也没有保证</li>
<li>variable-precision SWAR算法。数学上对于BITCOUNT的过程称为计算Hamming Weight。Hamming Weight经常被用于信息论、编码理论、密码学，所以有很多算法，variable-precision SWAR是目前最好的算法。它本质上是个分治divide-conquer算法，所以能拿到O(logN)的复杂度。实际上使用时，如果循环四次，一次拿到一个4字节32位的Hamming-Weight再循环相加，最终的复杂度是O(N/32*4)</li>
<li>Redis实现。8位表+四次variable-precision SWAR循环算法一次性计算128位的BITCOUNT</li>
</ul>
</li>
<li>BITOP在进行AND/OR/XOR操作时，会创建一个新的数组保存结果。</li>
</ul>
<h3 id="慢日志"><a href="#慢日志" class="headerlink" title="慢日志"></a>慢日志</h3><ul>
<li>Redis慢日志记录执行时间超过指定时长的命令</li>
<li>慢日志并没有打印到日志文件，而是保存到redisServer结构的slowlog链表，可以用SLOWLOG GET查询</li>
<li>新日志添加表头，当链表长度超过最大值时从表尾删除</li>
<li>执行命令前后都会获取UNIX时间戳，并用slowlogPushEntryIfNeeded来处理<br>监视器</li>
<li>通过执行MONITOR命令，客户端可以将自己变为一个监视器，实时的接收并打印服务器当前处理的命令相关信息</li>
<li>redisServer维护了一个监视器列表数据结构monitors链表</li>
<li>一个monitor实质上是一个redis-client，有一个client.flags&amp;REDIS_MONITOR = REDIS_MONITOR标志位</li>
<li>命令执行前有一个replicationFeedMonitors函数来向监视器发布信息</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/20/笔记：redis设计与实现/" data-id="cjr4jact600013xfy7k6hw7b5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/redis/">redis</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/技术内幕/">技术内幕</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-常见设计模式总结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/20/常见设计模式总结/" class="article-date">
  <time datetime="2019-01-20T01:00:07.000Z" itemprop="datePublished">2019-01-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/20/常见设计模式总结/">常用设计模式总结</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="单例模式"><a href="#单例模式" class="headerlink" title="单例模式"></a>单例模式</h2><ul>
<li>注意的点：<ul>
<li>私有构造方法</li>
<li>静态对象+静态方法</li>
<li>线程安全性，不能重复创建（类初始化时就加载没有线程安全性问题）</li>
<li>性能，减小锁的使用</li>
</ul>
</li>
<li>代码：<pre><code><br>public class Singleton{<br>  private static volatile Singleton s = null;<br>  private static final ReentrantLock LOCK = new ReentrantLock();<br>  public static Singleton get(){<pre><code>if(s==null){
    try{
        if(LOCK.lock()){
            if(s==null){
                   s = new Singleton();
               }
        }
    }
}
return s;
</code></pre>  }<br>}<br></code></pre></li>
</ul>
<h2 id="简单工厂模式"><a href="#简单工厂模式" class="headerlink" title="简单工厂模式"></a>简单工厂模式</h2><ul>
<li>注意的点：<ul>
<li>工厂接收传入的参数，返回一个接口对应的多个实现类的其中一个实例</li>
<li>扩展：结合单例<br>优点：</li>
<li>按接口规范调用产品对象的所有功能方法</li>
<li>使用方不需要关心实现细节，构造容易，逻辑简单<br>缺点：</li>
<li>全部if-else hard code，增减类型的时候都需要修改代码，对系统的维护可扩展不利。违反“开放-关闭原则”</li>
<li>所有类的实例创建逻辑都集中到一个工厂类中，违反“高内聚责任分配原则”</li>
</ul>
</li>
<li><img src="../images/design-pattern-simple-factory.png" alt="image"></li>
<li>代码示例：<pre><code><br>public interface IProduct{<br>  void A();<br>  void B();<br>}</code></pre></li>
</ul>
<p>public class Product1 implements IProduct{<br>    public void A(){}<br>    public void B(){}<br>}<br>public class Product2 implements IProduct{<br>    public void A(){}<br>    public void B(){}<br>}</p>
<p>public class ProductFactory{<br>    public static IProduct create(String name){<br>        if(P1.equals(“1”)){<br>            return new Product1();<br>        }else if(P2.equals(“2”)){<br>            return new Product2();<br>        }else{<br>            return null;<br>        }<br>    }<br>}<br></p>
<h2 id="工厂方法模式"><a href="#工厂方法模式" class="headerlink" title="工厂方法模式"></a>工厂方法模式</h2><ul>
<li>注意的点<ul>
<li>在简单工厂方法的基础上，将产品的创建从简单的单一工厂，拆分成多个实例工厂</li>
<li>保留了简单工厂方法封装对象创建细节的特点的同时，解决了简单工厂扩展维护苦难的问题</li>
</ul>
</li>
<li>类划分：<ul>
<li>抽象产品/产品接口</li>
<li>具体产品/产品实现类</li>
<li>抽象工厂</li>
<li>真实工厂</li>
</ul>
</li>
<li>优点：<ul>
<li>减少了单一工厂负责所有对象创建逻辑的耦合度</li>
<li>符合“开放-关闭原则”，增减新的类型，只需要增加/删除相应的工厂类和产品类即可</li>
<li>符合符合迪米特原则：又叫最少知识原则，即一个对象应尽可能少的了解其它对象。</li>
<li>符合里式替换原则：任何基类可以出现的地方，一定可以用子类替换。目标是使用抽象和多台将设计中的静态结构改为动态结构</li>
</ul>
</li>
<li><img src="../images/design-pattern-factory-method.png" alt="image"></li>
<li>代码示例<pre><code><br>public interface IProduct(){<br>  void A();<br>}<br>public interface IFactory(){<br>  IProduct createProduct();<br>}<br>public class Product1() implements IProduct{<br>  public void A(){}<br>}<br>public class Product2() implements IProduct{<br>  public void A(){}<br>}<br>public class Factory1() implements IFactory1{<br>  public IProduct createProduct(){<pre><code>return new Product1();
</code></pre>  }<br>}<br>public class Factory2() implements IFactory2{<br>  public IProduct createProduct(){<pre><code>return new Product2();
</code></pre>  }<br>}<br>public class Client{<br>  public static void main(String[] args){<pre><code>Factory1 f1 = new Factory1();
IProduct p1 = f1.createProduct();
Factory2 f2 = new Factory2();
IProduct p2 = f2.createProduct();
</code></pre>  }<br>}<br></code></pre></li>
</ul>
<h2 id="抽象工厂模式"><a href="#抽象工厂模式" class="headerlink" title="抽象工厂模式"></a>抽象工厂模式</h2><ul>
<li>为创建一组相关或相互依赖的对象提供一个接口，而且无需指定他们的类</li>
<li>区别于工厂方法模式：工厂方法针对一个产品等级结构（一个产品接口/基类），而抽象工厂模式针对多个产品等级结构。举例来说，当需要通过工厂来管理男人/女人/女博士一个维度的产品分类对象时，可以使用工厂方法模式；而如果出了男人/女人/女博士一个维度，还要管理黄/黑/白三个肤色人种，或者再加一种基督/佛教/锡克教等宗教维度，就可以用到抽象工厂模式。</li>
<li>缺点：<ul>
<li>上层维度（产品族）扩展非常困难。底层维度扩展时，只需要直接新增产品类和产品工厂类；而上层维度扩展首先要修改IFactory，违反“开放-关闭原则”</li>
</ul>
</li>
<li><img src="../images/design_pattern_abstract_factory.png" alt="image"></li>
<li>代码示例<pre><code><br>//以下是个苹果专卖店和三星专卖店分别销售手机和平板的例子<br>//大家可以假设富士康开了两条不同的流水线，分别生产苹果产品和三星产品，自己写一个不同维度的工厂方法组织方式<br>public interface Mobile{<br>  void makeCall();<br>}<br>public interface Pad{<br>  void game();<br>}<br>public interface DigitSellerFactory{<br>  Mobile sellMobile();<br>  Pad sellPad();<br>}<br>public class IPhone implements Mobile{<br>  public void makeCall(){}<br>}<br>public class Note2 implements Mobile{<br>  public void makeCall(){}<br>}<br>public class IPad implements Pad{<br>  public void game(){}<br>}<br>public class Tab implements Pad{<br>  public void game(){}<br>}<br>public class AppleSeller implements DigitSellerFactory{<br>  public Mobile sellMobile(){<pre><code>return new IPhone();
</code></pre>  }<br>  public Pad sellPad(){<pre><code>return new IPad();
</code></pre>  }<br>}<br>public class SumsungSeller implements DigitSellerFactory{<br>  public Mobile sellMobile(){<pre><code>return new Note2();
</code></pre>  }<br>  public Pad sellPad(){<pre><code>return new Tab();
</code></pre>  }<br>}<br></code></pre></li>
</ul>
<h2 id="装饰器模式"><a href="#装饰器模式" class="headerlink" title="装饰器模式"></a>装饰器模式</h2><ul>
<li>子类集成的方法对于功能多样化的扩展是极为不利的，除了功能多样难于管理，不同功能之间的组装更是有着不可计数的可能性。</li>
<li>注意的点：<ul>
<li>动态扩展</li>
<li>不改变原有的类</li>
<li>不用生成子类的继承方式</li>
<li>Decorator的功能通常不能有关联关系</li>
</ul>
</li>
<li>核心组件：<ul>
<li>原始类接口</li>
<li>原始类的基础实现</li>
<li>装饰器接口（一般类或抽象类）</li>
<li>继承装饰器接口的一系列具体装饰器</li>
</ul>
</li>
<li><img src="../images/design-pattern-decorator.png" alt="image"></li>
<li>代码示例<pre><code><br>public interface Phone{<br>  void func();<br>}<br>public class BasePhone implements Phone{<br>  public void func(){<pre><code>System.out.println(&quot;make call&quot;);
</code></pre>  }<br>}<br>public abstract class PhoneDecorator implements Phone{<br>  private Phone phone;<br>  public void func(){<pre><code>phone.func();
decoration();
</code></pre>  }<br>  public abstract void decoration();<br>}<br>public class  GameDecorator extends PhoneDecorator{<br>  public void decoration(){<pre><code>System.out.println(&quot;game!!!&quot;);
</code></pre>  }<br>}<br>public class ShuangKaShuangDaiDecorator extends PhoneDecorator{<br>  public void decoration(){<pre><code>System.out.println(&quot;shuang ka shuang dai!!!&quot;);
</code></pre>  }<br>}<br>public class Main{<br>  public static void main(String[] args){<pre><code>Phone basePhone = new BasePhone();
basePhone.func();
Phone gamePhone = new GameDecorator(basePhone);
gamePhone.func();
Phone shuangkaPhone = new ShuangkaShuangDaiDecorator(basePhone);
shuangkaPhone.func();
Phone shuangkaGamePhone = new ShuangkaShuangDaiDecorator(gamePhone);
shuangkaGamePhone.func();
</code></pre>  }<br>}<br></code></pre></li>
</ul>
<h2 id="观察者模式-发布-订阅模式"><a href="#观察者模式-发布-订阅模式" class="headerlink" title="观察者模式/发布-订阅模式"></a>观察者模式/发布-订阅模式</h2><ul>
<li>定义了一种一对多的依赖关系，让多个观察者同时监听某一个主题对象，当这个主题对象发生变化时，会通知所有观察者对象，使他们可以自动更新自己<br>注意的点：<ul>
<li>多个观察者主动加入监听，被监听对象不关心有多少观察者，低耦合</li>
<li>被监听对象发通知，观察者自己接收通知并完成后续处理</li>
<li>观察者可以主动注册和撤销监听</li>
<li>避免循环引用，观察者一般要异步去完成后续处理<br>优点：</li>
<li>观察者和被观察者是抽象耦合的，有一套触发机制<br>缺点：</li>
<li>观察者过多时，通知耗时</li>
<li>观察者只知道状态变化，不知道状态变化的过程</li>
</ul>
</li>
<li><img src="../images/design-pattern-decorator.png" alt="image"></li>
<li><pre><code>
public class Subject{
  private List<observer> observers;
  private int state;
  public void subscribe(Observer observer){
      observers.add(observer);
  }
  public void unsubscribe(Observer observer){
      observers.remove(observer);
  }
  public void notifyAll(){
      observers.foreach(x -> {
          x.update()
      })
  }
}
public abstract class Observer{
  protected Subject subject;
  public abstract void update();
}
</observer></code></pre>

</li>
</ul>
<h2 id="MVC模式"><a href="#MVC模式" class="headerlink" title="MVC模式"></a>MVC模式</h2><ul>
<li>将应用程序切分为Model/View/Control三类核心组件，它们各自处理自己的任务<ul>
<li>模型：持有数据、状态和程序逻辑</li>
<li>视图：用来呈现模型</li>
<li>控制器：负责接收用户输入、解析输入并返回给模型</li>
<li>MVC通过观察者模式实现视图和模型的分离，当Model数据发生变化时，通知到其相关的所有View</li>
<li>MVC通过策略模式将视图行为委托到Controller，并实现了视图行为的灵活切换</li>
</ul>
</li>
<li>优点：<ul>
<li>一个模型可以由不同的视图展示，模型数据发生变化时，模型将通知它对应的视图</li>
<li>模型可复用</li>
<li>提高开发效率</li>
</ul>
</li>
</ul>
<h2 id="命令模式"><a href="#命令模式" class="headerlink" title="命令模式"></a>命令模式</h2><ul>
<li>命令模式是一种数据驱动的设计模式，它属于行为模式。它将请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适对象，并把命令传递给相应的对象，该对象执行命令。</li>
<li>主要组件：<ul>
<li>被操作实体类</li>
<li>命令接口</li>
<li>命令实现类（含被操作的实体类的组件）</li>
</ul>
</li>
<li>命令接收与处理</li>
<li><code><pre><br>public interface ICommand{<br>  void execute();<br>}<br>public class Entity{<br>  public void op1(){}<br>  public void op2(){}<br>}<br>public class op1OnEntity implements ICommand{<br>  private Entity entity;<br>  public void execute(){<pre><code>entity.op1();
</code></pre>  }<br>}<br>public class op2OnEntity implements ICommand{<br>  private Entity entity;<br>  public void execute(){<pre><code>entity.op2();
</code></pre>  }<br>}<br>public class Broker{<br>  private List<icommand> toDoOperations;<br>  public void receiveCommand(ICommand c){<pre><code>toDoOperations.add(c);
</code></pre>  }<br>  public void doCommand(){<pre><code>toDoOperations.foreach(x -&gt; x.execute());
</code></pre>  }<br>}<br></icommand></pre></code></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/20/常见设计模式总结/" data-id="cjr4jact200003xfyazu37tmr" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/笔记/">笔记</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/设计模式/">设计模式</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-笔记——《ElasticSearch技术内幕》" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/20/笔记——《ElasticSearch技术内幕》/" class="article-date">
  <time datetime="2019-01-20T00:00:07.000Z" itemprop="datePublished">2019-01-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/20/笔记——《ElasticSearch技术内幕》/">笔记——《ElasticSearch技术内幕》</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="ElasticSearch的设计理念"><a href="#ElasticSearch的设计理念" class="headerlink" title="ElasticSearch的设计理念"></a>ElasticSearch的设计理念</h2><ul>
<li>合理的默认配置，使用户简单安装之后就可以直接使用，例如有了dynamic mapping，基本上就不需要再单独写mappings</li>
<li>默认分布式工作模式。每个节点总是假设自己属于某个集群</li>
<li>集群易于伸缩</li>
<li>对数据结构没有任何限制</li>
<li>准实时+版本同步</li>
</ul>
<h2 id="ES工作流程"><a href="#ES工作流程" class="headerlink" title="ES工作流程"></a>ES工作流程</h2><ul>
<li>启动过程。所有节点通过广播/单播组件结成集群，并选举产生master节点。master节点负责集群的状态管理及拓扑变化（集群伸缩时的分片迁移）</li>
<li>故障检测。master节点向其它节点发送心跳检测，当发生故障时，master就会启动拓扑更新和分片数据转移，保证集群的正常工作</li>
<li>索引数据。构建索引只会在master节点完成，再同步shard到不同的其它节点</li>
<li>查询数据。包括分散阶段scatter phase和合并阶段gather phase两个阶段。分散阶段将query分发到不同的分片完成查询（这里也起到了负载均衡的作用），合并阶段收集各分片上的搜索结果，进行合并、排序、后续处理并返回给客户端</li>
</ul>
<h2 id="底层索引控制"><a href="#底层索引控制" class="headerlink" title="底层索引控制"></a>底层索引控制</h2><ul>
<li>lucene 4.0支持了多种相似度计算模型（相似度是指查询向量同某个文档的余弦匹配度）。除了传统的TF/IDF，还有Okapi BM25、随机偏离、基于信息的模型几种。不同的field可以配置不同的相似度计算策略</li>
<li>索引文件编解码方式。通过配置不同的编解码方式，可以控制压缩程度和高基字段的预加载，从而在查询速度和内存之间做权衡</li>
<li>索引可见流程。<ul>
<li>索引更新与提交过程。Lucene在接收新的Document之后，在索引变得可见之前，还要经过以下几个阶段：①document处理（类型映射等）②创建只读的Segment_N文件（commit操作）③Searcher刷新（Searcher需要重新打开才能看到新索引，默认1s刷新）。可以看到，从lucene开始处理索引，到索引可以被查询到，有1s左右的延迟，这也是lucene/ES自称为准实时系统的原因</li>
<li>事务日志。因为不能频繁提交，所以遇到错误时有些数据可能会从内存中丢失，ES使用事务日志来记录所有的未提交事务，在发生错误时检查事务日志，执行未完成的操作。VSearch中似乎抽象了checkpoint的概念，跟写事务日志类似</li>
<li>准实时读取。可以通过使用事务日志，将提交的事务也进行查询，从而获取未提交版本的数据</li>
</ul>
</li>
<li>索引合并的3种策略。force merge操作</li>
</ul>
<h2 id="分布式索引架构"><a href="#分布式索引架构" class="headerlink" title="分布式索引架构"></a>分布式索引架构</h2><ul>
<li>问题<ul>
<li>如何为集群选择合适的shard和replication数量</li>
<li>什么是路由</li>
<li>分片分配器</li>
<li>如何应对数据和查询的增长</li>
</ul>
</li>
<li>实现<ul>
<li>将一个索引切分成若干个小索引，以便在同一集群的不同节点上分配它们，实现查询的并发处理。ES默认将每个索引分成5个shards，并做1个replication。即使是只有1个节点，这样做也可以方便扩容</li>
<li>一般来说，N个节点的集群，切分为N个分片+1个replication，总共2N个分片，可以最大化集群的分布式优势。但是这不是绝对的，因为查询过程的scatter phase和gather phase也是有代价的，有些时候（比如数据少的时候、有明确路由规则的时候）</li>
<li>路由类似mysql的分库分表过程，使用统一的分片规则和查询规则，可以实现只在特定分片上查询，从而避免不必要的scatter&amp;gather过程。例如按用户对订单数据进行分片，查询某个用户就能映射到某一特定分片，在这一个分片上查询即可<ul>
<li>不指定路由规则时。es会自动查询所有分片，修改或删除某一分片时也要定位到特定分片，所以只要保证一个id对应的document一直生成相同的值即可</li>
<li>指定路由规则。在mapping中添加_mappings字段，指定任意一个未分词的字段即可。要确保对同一个document，始终能计算得出一个相同的routing值</li>
</ul>
</li>
</ul>
</li>
<li>分片分配机制。<ul>
<li>当集群拓扑发生改变时，ShardAllocator负责分片的再分配。同一分片的primary shard和replication shard不能分配到同一节点（多于一个节点时）。分配机制会考虑多种因素：磁盘空间、同一分片的安全性、节点包含的同一个索引的分片数等</li>
<li>even_shard分配。保证每个节点有相同的分片数</li>
<li>balanced分配。提供一些可控参数交由用户控制</li>
<li>可以自行实现ShardAllocator接口</li>
</ul>
</li>
<li>ES集群跟redis集群的一点区别<ul>
<li>ES集群所有节点都可以配置为master候选节点，当master节点故障时其它节点会选举出新的master节点，并进行分片数据迁移</li>
<li>Redis集群是所有master节点不可或缺，系统不会因为节点故障修改master节点管理的slot，当遇到故障时，master节点对应的replication/slave节点就会选举出新的master节点加入集群</li>
</ul>
</li>
</ul>
<h2 id="管理ElasticSearch"><a href="#管理ElasticSearch" class="headerlink" title="管理ElasticSearch"></a>管理ElasticSearch</h2><ul>
<li>目标：<ul>
<li>选择正确的目录实现，提升底层I/O效率</li>
<li>配置发现模块避免潜在问题</li>
<li>配置网关模块</li>
<li>恢复模块</li>
<li>查看段信息</li>
<li>ES缓存</li>
</ul>
</li>
<li>存储类型：<ul>
<li>SimpleFSDirectory。简单文件存储系统</li>
<li>NIOFSDirecotyr。NIO文件存储。linux上默认使用nio</li>
<li>MMapDirectory。文件映射。</li>
<li>内存索引。小索引，有备份数据支持重建时使用。</li>
</ul>
</li>
<li>发现模块：<ul>
<li>multicast（Zen）</li>
<li>unicast。向配置指定的服务器列表进行单播，减少不必要流量</li>
</ul>
</li>
<li>最小主节点数<ul>
<li>至少N/2+1，防止split brain</li>
</ul>
</li>
<li>网关</li>
<li>索引段统计<ul>
<li>可以通过API查看索引/分片/段信息</li>
</ul>
</li>
<li>ES缓存<ul>
<li>过滤器缓存。缓存filter查询结果，LRU策略。</li>
<li>字段数据缓存。主要用于aggregation</li>
<li>使用API可以清楚特定缓存</li>
</ul>
</li>
</ul>
<h2 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a>故障处理</h2><ul>
<li>垃圾处理器。java8引入了G1，G1主要目标是减少暂停，使用户感受不到卡顿，但是吞吐量比较差，目前默认还是Paralllel</li>
<li>避免内存交换。可以通过配置关闭。</li>
<li>I/O调节。限制每秒的I/O量，防止卡顿</li>
<li>预热器。空间换时间的操作，指定一个查询/aggregation，缓存其结果，提升查询效率。可以单独创建，也可以在indexing时实时更新</li>
</ul>
<h2 id="分片内部原理"><a href="#分片内部原理" class="headerlink" title="分片内部原理"></a>分片内部原理</h2><ul>
<li>如何使文本可搜索：<ul>
<li>段一旦生成就不能再改变</li>
<li>ES在lucene基础上引入了“按段搜索”的概念，这样新增的数据就可以通过建立新的段从而尽快变得可搜索</li>
<li>为了提升索引速度，ES索引的数据先写入memory buffer。ES定期commit生成新的段（行程一个commit point）</li>
<li>commit之后，ES要refresh Searcher之后索引才能对搜索可见</li>
<li>commit之后，新生成的段文件还处在文件缓冲区，没有真正落盘，需要使用fsync()来完成落盘操作</li>
<li>fsync因为IO调用会很慢，fsync也是定期执行完成落盘的。</li>
<li>因为fsync定期完成，当系统异常退出时，未落盘的文件会丢失。所以ES还有translog机制，将未落盘的事件记录文件日志，当出现系统异常时，系统会从translog完成未落盘的索引的恢复工作</li>
<li>translog的落盘也是定期执行的，同样有丢失的可能，用户可以根据使用场景，容忍部分可能的丢失场景。根据kafka的落盘原理，顺序日志落盘其实并不慢</li>
</ul>
</li>
</ul>
<h2 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h2><ul>
<li>coordinate节点有没有单点故障问题，客户端的角色，负责负载均衡，请求分发等。设置在同一个域名下设置多个coordinate节点做负载均衡避免单点故障问题。</li>
<li>为什么是准实时的？除了数据落盘、filebeat轮询传送事件、logstash处理事件过程的时间消耗，ES处理完document之后，还要暂存document缓存区，commit轮询生成新的段文件，新的段要经过Refresh Searcher操作，才能对客户端可见。</li>
<li>shard在索引创建之前就已确定，如何扩容？增加replica数量</li>
<li>了解一下scatter-gather过程。是否带routing两种情况，不带就遍历，带了可以定位到指定索引，完成scatter搜索，再进行结果的合并</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/20/笔记——《ElasticSearch技术内幕》/" data-id="cjr4jacth00033xfyxpsolvo8" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/技术内幕/">技术内幕</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/笔记/">笔记</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-服务集群异常监控" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/20/服务集群异常监控/" class="article-date">
  <time datetime="2018-12-20T10:00:07.000Z" itemprop="datePublished">2018-12-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/20/服务集群异常监控/">服务监控</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="服务监控"><a href="#服务监控" class="headerlink" title="服务监控"></a>服务监控</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><ul>
<li>业务trace<ul>
<li>按时间顺序追踪业务流程的关键节点，主要包括以下两个部分：</li>
<li>搜索部分：用户产品选择、验价结果记录等</li>
<li>订单部分：下单、付款、关单、出单、退改签等</li>
<li>日志跟踪效果：</li>
<li><img src="../images/query-trace-log.png" alt="image"></li>
</ul>
</li>
<li>商家接口监控报警<ul>
<li>每天机票、酒店、火车票商家的接口状态追踪，对异常情况进行通知报警（邮件/短信）</li>
<li>邮件报警效果：</li>
<li><img src="../images/task-item-notification.png" alt="image"></li>
<li>报表效果：</li>
<li><img src="../images/taskitem-report.png" alt="image"></li>
</ul>
</li>
<li>异常监控<ul>
<li>服务器异常及错误日志监控报警，超过阈值时进行通知(短信)</li>
<li><img src="../images/exception-report.png" alt="image"></li>
</ul>
</li>
</ul>
<h2 id="业务流程trace"><a href="#业务流程trace" class="headerlink" title="业务流程trace"></a>业务流程trace</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul>
<li>需求：我们的产品有很长的系统流转过程，从用户选择产品，下单，商品的预定与售后等，有些关键数据需要记录下来防止用户纠纷，而系统运维、问题排查等要依赖各个节点的数据（用户/商品快照/价格快照/用户操作记录等）。当给定一个订单或产品时，我们通过订单id或产品标示就可以查到其业务流转过程中的所有关键节点数据日志，从而可以快速定位问题，解决纠纷</li>
<li>方案：通过ELK，Filebeat收集日志数据，Logstash对日志数据进行处理，ElasticSearch存储处理后的数据。在ElasticSearch数据基础上，通过Kibana进行可视化报表展示，也可以通过watcher插件进行报警通知</li>
</ul>
<h3 id="日志生成策略"><a href="#日志生成策略" class="headerlink" title="日志生成策略"></a>日志生成策略</h3><ul>
<li>统一的key追踪<ul>
<li>产品搜索key。用户搜索产品时的唯一产品标识，通过URL参数生成UUID，用这个UUID作为产品的唯一标识和日志追踪key</li>
<li>订单key。用户产品下单后，需要用订单id来追踪日志</li>
<li>key关联。将产品key和订单key进行关联，从而通过一个key可以看到完整的日志数据</li>
</ul>
</li>
<li>日志结构<pre><code><br>  public static void trace(String key, String secondaryKey, StepEnum step, String msg) {<pre><code>JSONObject traceLog = new JSONObject();
traceLog.put(&quot;key&quot;, key);
traceLog.put(&quot;secondaryKey&quot;, secondaryKey);
traceLog.put(&quot;step&quot;, step.getStepName());
traceLog.put(&quot;subStep&quot;, step.getSubStepName());
traceLog.put(&quot;message&quot;, msg);
traceLog.put(&quot;@timestamp&quot;, LocalDateTime.now());
log.info(traceLog.toJSONString());
</code></pre>  }<br></code></pre></li>
<li>在产品下单时，通过key和secondarykey将产品和订单进行关联</li>
<li>logstash数据处理。日志是json格式文本，通过json插件来完成数据提取(date插件提取时间戳)<pre><code><br>  json {<pre><code>source =&gt; &quot;message&quot;
remove_field =&gt; [&quot;message&quot;]
</code></pre>  }<br>  date {<pre><code>locale=&gt;&quot;en&quot;
match =&gt; [ &quot;startTime&quot;, &quot;ISO8601&quot; ]
target =&gt; &quot;startTime&quot;
</code></pre>  }<br></code></pre></li>
<li>ElasticSearch存储。按时间rotate数据，每天一个索引，最多保存7天</li>
<li>搜索<ul>
<li>排序，只按时间进行排序</li>
<li>关于分页，日志数量不大，暂时不做分页，后期考虑先在前端分页。最终可以通过doc_id或时间戳进行分页查询</li>
<li>通过产品链接或订单号查询所有日志</li>
</ul>
</li>
<li>watcher<ul>
<li>watcher现在是付费账户专享插件，费用比较高</li>
<li>我们自己通过spring-quartz定制定时任务来完成报警通知</li>
<li>通常定时任务都是单机完成的，通过指定运行ip来限制一下</li>
</ul>
</li>
</ul>
<h2 id="商家接口监控报警"><a href="#商家接口监控报警" class="headerlink" title="商家接口监控报警"></a>商家接口监控报警</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><ul>
<li>需求：每天多达数千万的接口调用，需要及时获知各接口的状态<ul>
<li>接口实时异常通知</li>
<li>报表展示</li>
</ul>
</li>
<li>方案<ul>
<li>接口调用通过任务队列调度异步完成，完成之后任务有统一的日志，通过与上文所述同样的ELK方案来处理</li>
</ul>
</li>
</ul>
<h3 id="日志收集"><a href="#日志收集" class="headerlink" title="日志收集"></a>日志收集</h3><ul>
<li>filebeat。单行日志，配置一般的harvester即可<pre><code><br>filebeat:<h1 id="List-of-prospectors-to-fetch-data"><a href="#List-of-prospectors-to-fetch-data" class="headerlink" title="List of prospectors to fetch data."></a>List of prospectors to fetch data.</h1>prospectors:<br>  -<pre><code>paths:
  - &quot;/opt/jdy-applog/*/taskitem.log&quot;
input_type: log
</code></pre>output:<br>logstash:<br>  hosts: [“logstash1.jdydev.cn:5043”, “logstash2.jdydev.cn:5043”, “logstash3.jdydev.cn:5043”]<br></code></pre></li>
<li>logstash grok。<pre><code><br>ruby {<br>code =&gt; “<br>  require ‘date’<br>  event.set(‘[@metadata][localdate]’, event.get(‘logdate’)[0,10].gsub(/[-]/,’.’))<br>“<br>}<br>ruby {<pre><code>code =&gt; &quot;
    require &apos;date&apos;
    event.set(&apos;execEnd&apos;, event.get(&apos;execEnd&apos;)+&apos;+0800&apos;)
    event.set(&apos;execStart&apos;, event.get(&apos;execStart&apos;)+&apos;+0800&apos;)
    event.set(&apos;assignStart&apos;, event.get(&apos;assignStart&apos;)+&apos;+0800&apos;)
    event.set(&apos;assignEnd&apos;, event.get(&apos;assignEnd&apos;)+&apos;+0800&apos;)
    # event.set(&apos;@timestamp&apos;, event.get(&apos;@timestamp&apos;)+&apos;+0800&apos;)
&quot;
</code></pre>  }<br>grok {<pre><code>break_on_match =&gt; false
match =&gt; { &quot;message&quot; =&gt; [ &quot;\&quot;webSiteID\&quot;:%{NUMBER:webSiteId:int}&quot;, &quot;\&quot;fromCityCode\&quot;:\&quot;%{DATA:flightFromCity}\&quot;&quot;, &quot;\&quot;toCityCode\&quot;:\&quot;%{DATA:flightToCit
</code></pre>y}\””, “\”depDate\”:\”%{DATA:flightDepDate}\””, “\”retDate\”:\”%{DATA:flightRetDate}\””, “\”verifyFlightProductIden\”:\”%{DATA:verifyFlightProductIden}\”” ] }<pre><code>}
</code></pre>mutate { add_field =&gt; { “businessLine” =&gt; “flight” } }<br></code></pre></li>
<li>ElasticSearch按业务线分集群flight/train/hotel，每个业务一个索引，索引每天rotate，每天一个索引</li>
</ul>
<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ul>
<li>使用kibana配置，<ul>
<li>注意粒度，一般使用最小一分钟作为最细粒度就可以了</li>
<li>多维统计可以拆图（split chart）或拆线（split line），也可以组合使用来实现更详尽的图表表达</li>
<li>酒店status报表，代理商拆图，status拆表。用于监控接口状态</li>
<li><img src="../images/hotel-taskitem-split.png" alt="image"></li>
<li>酒店执行时间报表。用于监控接口执行时间</li>
<li><img src="../images/hotel-taskitem-exectime.png" alt="image"></li>
</ul>
</li>
<li>可以将多个报表iframe嵌入其它系统统一查看（如运营后台）</li>
</ul>
<h3 id="报警通知"><a href="#报警通知" class="headerlink" title="报警通知"></a>报警通知</h3><ul>
<li>通过定时任务，并为每一指标配置阈值，达到报警阈值时短信+邮件报警</li>
</ul>
<h2 id="异常监控"><a href="#异常监控" class="headerlink" title="异常监控"></a>异常监控</h2><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><ul>
<li>需求：对系统运行过程中产生异常和错误日志进行监控和实时通知</li>
<li>方案：同样通过ELK收集、处理并存储</li>
</ul>
<h3 id="日志收集-1"><a href="#日志收集-1" class="headerlink" title="日志收集"></a>日志收集</h3><ul>
<li>filebeat 多行处理。filebeat默认每行日志作为一个事件来处理，而异常日志多是多行的，需要进行额外的配置<pre><code><br>filebeat:<h1 id="List-of-prospectors-to-fetch-data-1"><a href="#List-of-prospectors-to-fetch-data-1" class="headerlink" title="List of prospectors to fetch data."></a>List of prospectors to fetch data.</h1>prospectors:<br>  -<pre><code>paths:
  - &quot;/opt/jdy-applog/*/error.log&quot;
input_type: log
multiline.pattern: &apos;^[0-9]{4}-[0-9]{2}-[0-9]{2}&apos;
multiline.negate: true
multiline.match: after
</code></pre>output:<br>logstash:<br>  hosts: [“logstash1.jdydev.cn:5043”, “logstash2.jdydev.cn:5043”, “logstash3.jdydev.cn:5043”]<br></code></pre></li>
<li>Exception/Error 名称。grok有对应的exceptionName正则式，可以在logstash grok filter中使用下列语句进行截取<pre><code><br>filter{<br>  mutate { add_field =&gt; { “businessLine” =&gt; “errorlog” } }<br>  grok {<pre><code>patterns_dir =&gt; [&quot;/home/jdy/jdy-elk/logstash-5.3.0/config/patterns&quot;]
match =&gt; { &quot;message&quot; =&gt; [&quot;%{JAVA_EXCEPTION_SIGNATURE:exceptionName}&quot;]}
</code></pre>  }<br>}<br></code></pre></li>
</ul>
<h3 id="可视化-1"><a href="#可视化-1" class="headerlink" title="可视化"></a>可视化</h3><ul>
<li>用kibana配置报表</li>
<li>重点异常重点跟踪，例如我们将redis异常的跟踪到每台机器，这样可以从报表中获得更多信息：</li>
<li><img src="../images/redis-exception-report.png" alt="image"></li>
</ul>
<h3 id="报警"><a href="#报警" class="headerlink" title="报警"></a>报警</h3><ul>
<li>定时程序汇总，例如查询过去5分钟内的异常数量，当超过一定值时进行报警，可以针对某一异常单独配置阈值，也可以自动累积历史数值，创建基线作为阈值。threshold = a * threshold + val(0&lt;a&lt;1, val是当前异常数量)</li>
<li>短信告警（云片）。异常的通知通常属于紧急事件，需要保证通知触达率及打开率，因此使用短信通知，可以使用邮件额外</li>
</ul>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><h3 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h3><ul>
<li>理论上可以实现at least once机制，保证数据不丢失，但是可能会有重复</li>
<li>logstash需要persistent queue来保证100%的不丢失</li>
<li>如果进程异常退出或被异常关闭（kill -9），会导致inflight数据丢失，请注意ELK各进程的规范退出</li>
</ul>
<h3 id="实时性"><a href="#实时性" class="headerlink" title="实时性"></a>实时性</h3><ul>
<li>在统一的内网环境部署，忽略网络传输时间</li>
<li>日志落地。Logback日志本地缓存到异步落盘的时间在毫秒级别</li>
<li>filebeat生成事件。扫描间隔1s，强制上传时间（事件本地缓存的时间）是5s。</li>
<li>logstash处理时间。一般是毫秒级，可以通过x-pack查看延迟，可以按需求配置workers数量增加并发，提升排队延迟</li>
<li>索引延迟及索引可见的时间约1s</li>
<li>总计有1-10s的延迟，能够满足准实时需求</li>
<li>@timestamp使用默认的logstash处理时间，日志时间单独存储，可以比较出延迟时间（日志生成event -&gt; grok之间）</li>
</ul>
<h3 id="查询速度"><a href="#查询速度" class="headerlink" title="查询速度"></a>查询速度</h3><ul>
<li>global ordinals<ul>
<li>global_ordinals 是用于减少string类型的fielddata占用内存的技术。以我们的系统为例一个doc至少有10个keyword类型的field需要用于查询、聚合操作，假设每个keyword类型的平均长度是20个byte，1G（10亿）个doc的所有keyword field所占用的内存是10<em>20</em>1G=200G。global_ordinals对这些keyword的值进行编号，使用整数值来替代原始的字符串，查询计算完成之后，再用对应的字符串值替换序号，从而减小内存占用。由于一个整数值只占一个byte，因此这些field全都加载到内存占用的内存大小是10*1G=20G。只有原来的1/20</li>
<li>好处：1. 降低内存占用2. 极大提高汇总排序查询的速度</li>
<li>global ordinals默认在搜索时加载，text和keyword field默认在搜索时构建global ordinals，这样在第一次搜索时，在数据量很大的情况下，用户会感受到明显的延迟。</li>
<li>可以通过配置eager_global_ordinals将global_ordinals的构建从搜索转移到索引的构建刷新。</li>
</ul>
</li>
<li>缓存。<ul>
<li>不使用类似now的时间戳</li>
<li>使用恒定的范围查询和聚类，例如[10-20),[20-30),…，而不要使用[9-22),[23-57)之类，或者使用不恒定的变量</li>
<li>对某些经常聚类的字段进行缓存冗余，如val=17，冗余存储一个范围10-20</li>
</ul>
</li>
</ul>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>日志记录要在侵入性和灵活性之间做权衡，我们处在业务初始阶段，变化较多，因此目前记录的日志都是侵入性日志</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/20/服务集群异常监控/" data-id="cjpwfntqk00006nqhdrlfmsvb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/bigdata/">bigdata</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-旅行基础数据搜索" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/20/旅行基础数据搜索/" class="article-date">
  <time datetime="2018-12-20T09:40:59.000Z" itemprop="datePublished">2018-12-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="旅行基础数据搜索"><a href="#旅行基础数据搜索" class="headerlink" title="旅行基础数据搜索"></a>旅行基础数据搜索</h1><ul>
<li>支持旅行基础数据的全文搜索</li>
<li>支持数据全部属性的搜索，包括名称、拼音、简拼、英文名称、内容介绍等</li>
<li>支持的行业数据包括<ul>
<li>地理数据：国家/地区/省份/城市</li>
<li>POI数据：餐厅/景点/地标/酒店</li>
</ul>
</li>
</ul>
<h2 id="索引构建"><a href="#索引构建" class="headerlink" title="索引构建"></a>索引构建</h2><ul>
<li>使用logstash <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html" target="_blank" rel="external">jdbc input plugin</a>从数据库导入数据</li>
<li>数据导入。配置驱动、user、password、sql</li>
<li>指定doc_id保证数据唯一性，比如用表明+id拼一个字段作为document_id，在elasticsearch output插件中指定document_id，防止数据重复导入</li>
<li>定时调度。配置schedule语句</li>
<li>实现示例<pre><code><br>jdbc {<pre><code>jdbc_driver_library =&gt; &quot;/home/jdy/jdy-elk/logstash-5.3.0/vendor/jdbc/mysql-connector-java-5.1.35.jar&quot;
jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;
jdbc_connection_string =&gt; &quot;jdbc:mysql://59.110.207.194:3306/mytrip_basic&quot;
jdbc_user =&gt; &quot;jdy_db_admin&quot;
jdbc_password =&gt; &quot;******&quot;
schedule =&gt; &quot;0 * * * * &quot;
statement =&gt; &quot;SELECT p.*, c.name as countryName, &apos;province&apos; as table_name, CONCAT(&apos;PROVINCE-&apos;, provinceID) as doc_id FROM mytrip_basic.sys_province p le
</code></pre>ft join mytrip_basic.sys_country c on p.countryID=c.countryID where provinceID in (29)”<br>}<br>filter {<br>}<br>output {<br>  elasticsearch {<pre><code>hosts =&gt; &quot;10.30.137.118:9200&quot;
document_id =&gt; &quot;%{[doc_id]}&quot;
index =&gt; &quot;logstash-jdbc-basic&quot;
</code></pre>  }<br>}<br></code></pre></li>
</ul>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><ul>
<li>主要的查询语法<ul>
<li>Match Query。全文检索（full text query），ES会先对请求进行解析(analyze)，得到多个单独的词汇，逐个查询并综合评分，相当于google的搜索机制</li>
<li>Term Query。直接查询单独的term（要求term完全匹配），主要针对结构化的数据，例如数字、日期、枚举等，这些字段都是.keyword类型的field。</li>
<li>Bool组合。对多个Match Query和/或TermQuery进行组合查询</li>
</ul>
</li>
<li>前缀查询<ul>
<li>对Term Query可以支持前缀查询，尤其用户输入过程中一般要实现类似提示的效果，需要通过前缀查询进行支持</li>
<li>filter。相比Query，filter可以省去评分计算等过程，比Query的速度要更快，因此在不需要评分的场景应尽量使用filter替代query</li>
</ul>
</li>
<li>大小写处理。<ul>
<li>通过jdbc input插件的lowercase_column_names选项，指定想要小写处理的表属性    - 如果不使用动态mapping（dynamic mapping），可以通过ES mapping，指定某些字段为小写，之后用小写查询</li>
<li>注意需要显示指定某些字段进行小写处理，有些大小写混用的id类属性，全部转为小写会造成数据错误，例如服务器的hostName，Base64编码的属性等</li>
<li>我们在实际处理过程中没有改变存储的大小写，而是针对属性值的实际情况将查询串进行特殊处理（如小写、大写、首字母大写等）</li>
</ul>
</li>
<li>全拼音/拼音首字母<ul>
<li>有条件的进行拼音手工维护，能够保证准确率，如beijing，bj，shanghai，shh</li>
<li>通过github一些资源来生成拼音</li>
</ul>
</li>
<li>Boost设置。boost&gt;1可以增加某一子查询的评分重要程度。例如，我们认为在查询过程中name匹配应该比其他内容的匹配更重要，因此我们把name的boost设置为5.0</li>
<li>完整的查询方案<pre><code><br>{<br>  “query”: {<pre><code>&quot;filter&quot;: [
    {&quot;term&quot;: {&quot;table_name&quot;: &quot;hotel&quot;} }
],
&quot;bool: {
    &quot;should: [
        {&quot;match&quot;: {&quot;name&quot;: {&quot;query&quot;: keyword, &quot;operator&quot;: &quot;or&quot;}}},
        {&quot;match&quot;: {&quot;enname&quot;: keyword}},
        {&quot;prefix&quot;: {&quot;fs.keyword&quot;: keywordLowerCase}},
        {&quot;prefix&quot;: {&quot;pinyin.keyword&quot;: keywordLowerCase}},
        {&quot;prefix&quot;: {&quot;name.keyword&quot;: {&quot;value&quot;: keywordLowerCase, &quot;boost&quot;: 5.0}}},
        {&quot;prefix&quot;: {&quot;enname.keyword&quot;: {&quot;value&quot;: keywordLowerCase, &quot;boost&quot;: 5.0}}},
        {&quot;prefix&quot;: {&quot;fs.keyword&quot;: keywordFirstCapital}},
        {&quot;prefix&quot;: {&quot;pinyin.keyword&quot;: keywordFirstCapital}},
        {&quot;prefix&quot;: {&quot;name.keyword&quot;: {&quot;value&quot;: keywordFirstCapital, &quot;boost&quot;: 5.0}}},
        {&quot;prefix&quot;: {&quot;enname.keyword&quot;: {&quot;value&quot;: keywordFirstCapital, &quot;boost&quot;: 5.0}}}
    ]
},
&quot;minimum_should_match&quot;: 1
</code></pre>  },<br>  “size”:200,<br>  “_source”: true<br>}<br></code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/20/旅行基础数据搜索/" data-id="cjpwf1wq500004eqhj9cgcq64" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-筋斗云ELK集群" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/19/筋斗云ELK集群/" class="article-date">
  <time datetime="2018-12-19T05:34:12.000Z" itemprop="datePublished">2018-12-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="筋斗云ELK集群简介"><a href="#筋斗云ELK集群简介" class="headerlink" title="筋斗云ELK集群简介"></a>筋斗云ELK集群简介</h1><ul>
<li><font color="blue">本篇只对ELK的各组件做概要介绍，并描述他们可以实现的典型功能。后续的文章会陆续对不同需求场景的实现及服务运维进行陈述总结</font>

</li>
</ul>
<h2 id="筋斗云ELK集群支撑的功能"><a href="#筋斗云ELK集群支撑的功能" class="headerlink" title="筋斗云ELK集群支撑的功能"></a>筋斗云ELK集群支撑的功能</h2><ul>
<li>服务运行异常实时监控。收集各服务器上的异常及错误日志，归类统计与展示报警，用于实时的监控系统运行状态，今早发现问题</li>
<li>旅游内容搜索。国家/地区/城市/景点/餐馆/酒店等内容的全文搜索支持</li>
<li>业务数据监控。主要是各行业各合作商家的API状态监控，即时发现有问题的接口，防止对业务服务造成影响</li>
<li>全流程业务跟踪。将旅游产品从打包搜索-交易下单-出票出单-售后服务的全流程关键节点进行记录，并按照统一的key进行搜索，</li>
</ul>
<h2 id="ELK功能及特点简介"><a href="#ELK功能及特点简介" class="headerlink" title="ELK功能及特点简介"></a>ELK功能及特点简介</h2><ul>
<li><img src="../images/ELK-stack.png" alt="image"></li>
</ul>
<h3 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h3><ul>
<li>filebeat是一个轻量级的日志收集器（shipper for forwarding and centralizing log data）,在想要收集日志的服务器上，将filebeat作为agent安装，并指定要收集的日志文件路径和名称，指定日志的输出目标（Logstash或ElasticSearch服务）</li>
<li><img src="../images/filebeat.png" alt="image"></li>
</ul>
<h3 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h3><ul>
<li>Logstash通过实时管道（realtime pipelining）对数据进行实时处理，有良好的扩展机制，社区中也有大量实用的input、filter、output插件。能满足不同场景的数据导入和数据处理功能</li>
<li><img src="../images/logstash-process.png" alt="image"></li>
</ul>
<h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><ul>
<li>Elasticsearch是一个开源的、高度可扩展的全文检索与数据分析引擎</li>
<li>有以下重要特点：<ul>
<li>分布式支持，集群扩展/缩减透明</li>
<li>海量数据容量</li>
<li>准实时的索引速度（主要是ES索引可见大约有1s左右的延迟）</li>
</ul>
</li>
</ul>
<h3 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h3><ul>
<li>基于ElasticSearch数据进行数据可视化分析与展示</li>
</ul>
<h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><h3 id="集群效果"><a href="#集群效果" class="headerlink" title="集群效果"></a>集群效果</h3><ul>
<li>filebeat属于agent，部署在各个应用服务器上负责收集日志</li>
<li>logstash<ul>
<li>1个jdbc节点，处理数据库数据</li>
<li>3个log节点，处理log数据</li>
</ul>
</li>
<li>elasticsearch<ul>
<li>1个coordinate节点，类似于一个门面（facade），不存储数据，不做master节点，只负责将请求拆分到各个数据节点，并汇总各个数据节点的搜索结果返回给请求方</li>
<li>3个数据节点(80G SATA硬盘，8G内存，双核2.5GHz)</li>
</ul>
</li>
<li>elasticsearch性能指标<ul>
<li>业务数据每个业务一个索引，业务日志按每天一个索引，</li>
<li>200+索引</li>
<li>1亿+document</li>
<li>170G数据（60G/机器，实际落盘可能有压缩）</li>
<li>峰值document增量1000qps，primary shard 500qps</li>
<li>保留最近一周的数据</li>
</ul>
</li>
</ul>
<h3 id="系统初始化"><a href="#系统初始化" class="headerlink" title="系统初始化"></a>系统初始化</h3><ul>
<li>线上生产系统不能使用root启动ELK（filebeat可以），需要创建用户。另外需要修改最大文件数配置。在CentOS6系统下的配置脚本如下</li>
<li><pre><code>#!/bin/bash
useradd jdy
passwd jdy
sudo usermod -aG wheel jdy
sed -i "s/# %wheel\tALL=(ALL)\tALL/%wheel\tALL=(ALL)\tALL/g" /etc/sudoers
echo -e "\nulimit -n 100000" >> /etc/profile
sed -i "s/soft nofile 65535/soft nofile 100000/g" /etc/security/limits.conf
sed -i "s/hard nofile 65535/hard nofile 100000/g" /etc/security/limits.conf
echo -e "\njdy soft nproc 2048" >> /etc/security/limits.conf
echo -e "\njdy hard nproc 2048" >> /etc/security/limits.conf
echo -e "\nvm.max_map_count = 262144" >> /etc/sysctl.conf
reboot</code></pre>

</li>
</ul>
<h3 id="Elastic初始化配置"><a href="#Elastic初始化配置" class="headerlink" title="Elastic初始化配置"></a>Elastic初始化配置</h3><ul>
<li>配置文件：elasticsearch.yml &amp; log4j2.properties</li>
<li>重要配置：<ul>
<li><ol>
<li>node.name：node-n</li>
</ol>
</li>
<li><ol>
<li>cluster.name:系统通过广播发现使用相同cluster.name的节点，组成一个cluster（jdy-log）</li>
</ol>
</li>
<li><ol>
<li>bootstrap.memory_lock:要保证elastic进程内存不被swap到磁盘，需要设置memory_lock</li>
</ol>
</li>
<li><ol>
<li>设置network.host为<em>site</em></li>
</ol>
</li>
<li><ol>
<li>设置discovery.zen.ping.unicast.hosts为：[“10.27.246.125”, “10.27.74.199”, “10.27.72.7”, “10.170.247.171”]</li>
</ol>
</li>
<li><ol>
<li>设置discovery.zen.minimum_master_nodes为：（master_eligible_nodes / 2) + 1</li>
</ol>
</li>
<li><ol>
<li>堆内存大约设置到虚拟机内存的一半。我们使用8G内存的ECS，jvm设置为3G</li>
</ol>
</li>
<li><ol>
<li>centOS下关闭memory_lock：bootstrap.memory_lock: false, bootstrap.system_call_filter: false</li>
</ol>
</li>
</ul>
</li>
<li>配置配置<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#coordinating-node" target="_blank" rel="external">coordinate结点</a>，设置node.data, node.master_eligible, node.ingest为false，该结点不存储数据，只向数据结点分发数据请求，并合并计算结果</li>
<li>设置network.publish_host和network.bind_host，测试环境单机模式下，可使用network.host同时设置两个值为相同的ip，但在生产环境集群模式下通常这两个值不同。publish_host用于集群内网间监听和数据传输，bind_host用于提供外部网络访问</li>
</ul>
<h3 id="Logstash配置"><a href="#Logstash配置" class="headerlink" title="Logstash配置"></a>Logstash配置</h3><ul>
<li>主要的配置文件logstash.yml taskitem-pipeline.conf</li>
<li>通过在taskitem-pipeline.conf中配置input、filter及output，指定数据的输入输出及数据处理过程</li>
<li><img src="../images/basic_logstash_pipeline.png" alt="image"></li>
<li>至少2个logstash服务以保证服务可用性（filebeat有at least once机制保证数据不丢）</li>
<li>需要在filebeat中配置loadbalance：true，loadbalance模式包括：RoundRobin（default）、lock-step（强制保证多台机器的平均）</li>
<li>高吞吐量下，建议使用HAProxy做负载均衡</li>
<li>配置事件处理线程数：pipeline.batch.size=125</li>
<li>持久化input -&gt; queue -&gt; filter -&gt; output<ul>
<li><ol>
<li>防止内存数据丢失；</li>
</ol>
</li>
<li><ol>
<li>减缓事件峰值对事件处理造成的瞬间压力</li>
</ol>
</li>
<li><ol>
<li>配置queue.type: persisted, path.queue: $QUEUE_PATH, queue.max_events: 65536, queue.max_bytes:100M</li>
</ol>
</li>
<li><ol>
<li>基于checkpoint的<a href="https://www.elastic.co/guide/en/logstash/current/persistent-queues.html#durability-persistent-queues" target="_blank" rel="external">commit机制</a>,很多跟磁盘密切相关的操作都使用类似机制</li>
</ol>
</li>
<li><ol>
<li>注意如果logstash进程终止或硬件失败，队列中未commit（checkpointed）的数据会丢失。可以设置queue.checkpoint.writes=1来避免，但是要考虑由此带来的IO消耗，可能会阻塞logstash本身的运行   </li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="x-pack"><a href="#x-pack" class="headerlink" title="x-pack"></a>x-pack</h3><ul>
<li>x-pack集成了elk许多高级特性，包括安全、监控、报警等。事实上，原来elasticsearch中许多有用的插件都被转移到了x-pack中，其中许多也变成了收费的功能，比如原来的watcher监控插件集成到x-pack的监控功能中后，需要收费的高级账号才能使用</li>
<li>由于都是内网运维，为了简单期间，我们关闭了访问密码的使用，在elasticsearch.yml中配置<pre><code><br>xpack.security.enabled: false<br></code></pre></li>
<li>监控功能默认是打开的，也可以在上述文件中配置关闭</li>
</ul>
<h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><h3 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h3><ul>
<li>不同版本之间的升级方案可能各不相同，具体请参考官方文档，这里仅给出我们一次升级过程</li>
<li>elastic 5.2-5.3 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/rolling-upgrades.html" target="_blank" rel="external">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/rolling-upgrades.html</a></li>
<li>logstash 5.2-5.3  <a href="https://www.elastic.co/guide/en/logstash/current/upgrading-logstash.html" target="_blank" rel="external">https://www.elastic.co/guide/en/logstash/current/upgrading-logstash.html</a><ul>
<li><ol>
<li>解压缩logstash安装包</li>
</ol>
</li>
<li><ol>
<li>复制原路径config目录到新的安装位置</li>
</ol>
</li>
<li><ol>
<li>复制原data目录到新安装路径</li>
</ol>
</li>
<li><ol>
<li>重启logstash</li>
</ol>
</li>
</ul>
</li>
<li>kibana 5.2-5.3:<br><a href="https://www.elastic.co/guide/en/kibana/current/upgrade-standard.html" target="_blank" rel="external">https://www.elastic.co/guide/en/kibana/current/upgrade-standard.html</a><ul>
<li><ol>
<li>解压缩kibana安装包</li>
</ol>
</li>
<li><ol>
<li>复制原路径config目录到新的安装位置</li>
</ol>
</li>
<li><ol>
<li>复制原路径data目录到新的安装位置</li>
</ol>
</li>
<li><ol>
<li>重启kibana</li>
</ol>
</li>
</ul>
</li>
<li>x-pack license升级<ul>
<li>x-pack运行需要license，免费的license包括1年的basic和30天完整试用，免费的可以支持monitoring，目前我们的需求可以满足，因此需要每隔1年替换一次basic license。<font color="red">而且阿里云的ES集群价格对我们来说还是挺高的，相比我自己购买ECS部署，价格大约是3-4倍</font></li>
<li>查看license<pre><code><br>curl –user elastic:${password} -XGET <a href="http://localhost:9200/_xpack/license/" target="_blank" rel="external">http://localhost:9200/_xpack/license/</a><br></code></pre></li>
<li>申请新的license<br><a href="https://register.elastic.co/" target="_blank" rel="external">https://register.elastic.co/</a></li>
<li>license upgrade（在线执行，不需要停elastic服务）<pre><code><br>curl -XPUT -u elastic ‘<a href="http://localhost:9200/_xpack/license" target="_blank" rel="external">http://localhost:9200/_xpack/license</a>‘ -H “Content-Type: application/json” -d @/root/wang-xiaodong-a7d09d57-aab5-41b4-8b23-f185c899d10e-v5.json<br></code></pre></li>
</ul>
</li>
<li>force merge<ul>
<li>所有数据到位后(read only indices)，强制进行索引merge，可以减小索引文件数量，也有助于解决run out of file handles问题，便于长期数据存储。segment越多查询速度就会越慢，合并也有利于提升查询效率</li>
<li>进行force merge时所有请求都会被block，只应该用于read only索引</li>
<li>合并前后比较<ul>
<li>merge前 641.3mb  merge后634.8mb</li>
<li>merge前2.3g merge后2.2g</li>
</ul>
</li>
<li>设置crontab任务，调用API每天force merge readonly indices</li>
<li><pre><code>curl -X POST "http://localhost:9200/logstash-*-`date -d -10days +%Y.%m.%d`/_forcemerge?max_num_segments=1&flush=true&only_expunge_deletes=false"</code></pre>

</li>
</ul>
</li>
</ul>
<h2 id="重点问题："><a href="#重点问题：" class="headerlink" title="重点问题："></a>重点问题：</h2><ul>
<li>数据一致性<ul>
<li>filebeat-&gt;logstash：At Least Once机制，filebeat通过维护日志文件已处理行数的偏移量，确保Output对event进行confirm之后才不会重发。会导致重复接收。</li>
<li>logstash-&gt;elastic：At Least Once机制，logstash可以通过queue.type: persisted选项配置使用<a href="https://www.elastic.co/guide/en/logstash/current/persistent-queues.html" target="_blank" rel="external">persisted queue</a>或redis/kafka等消息中间件，实现at least once保证，并提供削峰平谷的功能。也可能会导致重复接收。</li>
<li><font color="red">checkpoint机制下，在checkpoint文件完成fsync前，logstash异常退出或硬件故障时，已进队列，但是未写入checkpoint的数据会丢失</font></li>
<li>如果document有唯一id，可以通过mapping制定id，来保证唯一性，防止接收重复数据导致的问题</li>
</ul>
</li>
<li>各节点的延迟问题<ul>
<li>filebeat收集。日志落地到文件后，filebeat默认的扫描间隔是1s，最小数据处理间隔filebeat.idle_timeout默认5s，可以按需求配置缩小扫描间隔和最小处理间隔。比如日志量很大时，缩小扫描间隔；日志量很小时，缩小filebeat.idle_timeout</li>
<li>logstash处理。当事件qps较高时，会有秒级的延迟，grok插件的使用非常消耗cpu，在每台机器用满的情况下，可以考虑扩展logstash集群。目前我们业务组的3台集群，在峰值1000qps时约有2-3秒的延迟</li>
<li>elasticsearch延迟。es构建索引的延迟是很小的，一般在1毫米以内，但是索引构建完成到索引可见仍有大约1s左右的延迟</li>
<li><font color="red">总的来说，elk是一套准实时的流式数据处理机制，数据从产生到可见，客观上会有大约1s-10s的延迟。可以满足绝大多数需求的实时性要求</font>

</li>
</ul>
</li>
</ul>
<h2 id="refernce"><a href="#refernce" class="headerlink" title="refernce"></a>refernce</h2><ul>
<li><a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-overview.html" target="_blank" rel="external">filebeat官方文档</a></li>
<li><a href="https://www.elastic.co/guide/en/logstash/current/persistent-queues.html" target="_blank" rel="external">logstash persistent queue</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/19/筋斗云ELK集群/" data-id="cjpuzqwvv0000e7qhfzzm8vz0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-lucene数据结构解析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/17/lucene数据结构解析/" class="article-date">
  <time datetime="2018-12-17T09:42:10.000Z" itemprop="datePublished">2018-12-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="lucene数据结构解析"><a href="#lucene数据结构解析" class="headerlink" title="lucene数据结构解析"></a>lucene数据结构解析</h1><ul>
<li><a href="https://github.com/apache/lucene-solr" target="_blank" rel="external">git代码地址</a></li>
<li>如果想深入了解底层实现，可以参考<a href="https://gitsea.com/wp-content/uploads/2013/04/Annotated-Lucene%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E4%B8%AD%E6%96%87%E7%89%88.pdf" target="_blank" rel="external">这里</a></li>
</ul>
<h2 id="lucene主要的包结构"><a href="#lucene主要的包结构" class="headerlink" title="lucene主要的包结构"></a>lucene主要的包结构</h2><ul>
<li>索引搜索 org.apache.lucene.search</li>
<li>索引构建 org.apache.lucene.index</li>
<li>语言分析器 org.apache.lucene.analysis</li>
<li>查询分析器 org.apache.lucene.queryparser</li>
<li>底层存储结构 org.apache.lucene.store</li>
<li>外部存储结构 org.apache.lucene.document</li>
</ul>
<h2 id="索引与查询基础结构（document）"><a href="#索引与查询基础结构（document）" class="headerlink" title="索引与查询基础结构（document）"></a>索引与查询基础结构（document）</h2><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ul>
<li>文本处理<ul>
<li>Analyzer。处理text类型内容，例如去掉“a/an/the”等，去掉介词，名词复数变单数，动词时态转换<ul>
<li>StandardAnalyzer</li>
<li>SimpleAnalyzer</li>
<li>不同的语言实现类EnglishAnalyzer、JapaneseAnalyzer等</li>
</ul>
</li>
<li>Tokenizer。文本拆分为token流<ul>
<li>StandardTokenizer</li>
</ul>
</li>
<li>Filters。对每个token进行处理<ul>
<li>StandardFilter</li>
<li>LowerCaseFilter</li>
</ul>
</li>
</ul>
</li>
<li>IndexWriter：索引写入的外层API接口，底层依赖DocumentWriter，入口函数IndexWriter#addDocument</li>
<li>Document，代表了某一个存储对象的抽象，类似于数据库中一行具体的数据</li>
<li>Field，及Field的不同类型子类StringField,TextField,IntPoint等</li>
</ul>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><ul>
<li>Query/TermQuery。查询请求参数<ul>
<li>TermQuery</li>
<li>BooleanQuery</li>
</ul>
</li>
<li>QueryParser。查询请求转换器，将符合语法要求的queryString转化为Query对象</li>
<li>IndexSearcher：索引搜索的外层API接口，底层依赖index包的IndexReader类来完成数据搜索，入口函数IndexSearcher#search(Query, CollectorManager<c,t>)</c,t></li>
<li>Hit。搜索结果</li>
</ul>
<h2 id="索引存储结构（store）"><a href="#索引存储结构（store）" class="headerlink" title="索引存储结构（store）"></a>索引存储结构（store）</h2><ul>
<li>index<ul>
<li>segment文件。lucene的一个所以可以由多个子索引或segment组成，每一个segment都是一个完全独立的索引，可以独立进行检索。这种子索引的组织方式，可以使lucene在新增document时不断的创建新的segment以保障索引和查询速度，同时lucene会定期将小的segment合并为大的segment。</li>
<li>lock文件。写索引锁，保证同一时刻只有一个writer可以修改索引</li>
<li>Compound文件。这是一个简单的容器（container）来服务所有下一章节（next section）描述的文件（除了.del 文件）</li>
</ul>
</li>
<li>segment文件<ul>
<li>Field信息。Field 的名字都存储在 Field 信息文件中，后缀是.fnm。</li>
<li>Field数据。存储的 fields通过两个文件来呈现，即 field 索引文件（.fdx）和<br>field 数据文件（.fdt）。</li>
<li>Term字典。①存储 term 信息（TermInfoFile）的文件，即.tis 文件②存储 term 信息的索引文件，即.tii 文件，该文件包含.tis 文件中每一个 IndexInterval 的值，与它在.tis<br>中的位置一起被存储，这被设计来完全地读进内存中（read entirely into memory），以便用来提供随机访问.tis<br>文件。</li>
<li>Term频率数据。Term 频率数据文件（.frq 文件）存储容纳了每一个 term 的文档列表，以及该 term 出现在该文档中的频率</li>
<li>Positions位置信息数据。Positions 位置信息数据文件（.prx 文件）容纳了每一个 term 出现在所有文档中的位置的列表。</li>
<li>Norms调节因子文件</li>
<li>Terms向量文件</li>
<li>删除的文档</li>
</ul>
</li>
<li><img src="../images/lucene-segment-file-structure.png" alt="image"></li>
</ul>
<h2 id="lucene设计特点"><a href="#lucene设计特点" class="headerlink" title="lucene设计特点"></a>lucene设计特点</h2><ul>
<li>lucene索引的创新之处在于，在扩展索引的时候不断创建新的索引文件，然后定期把这些新的小索引文件合并到大的索引中，这样在不影响检索效率的前提下，提高了索引的效率</li>
<li>lucene的API接口设计比较通用，输入输出结构都很像数据库的表-&gt;记录-&gt;字段，所以很多传统应用的文件、数据库等都可以方便的映射到lucene的存储结构中</li>
<li>应用入口简单易懂，Searcher、Indexer，入口配合底层一系列组件协同完成索引/搜索的任务</li>
<li>所有的问题都设计了一个抽象层来方便以后的扩展和重用，使用者可以按自己的需求定制不同的模块，而其它模块功能可以保持不变，同时变更范围都是隔离可控的。在这些接口上，lucene提供了适合多数用户的标准实现，如Analyzer接口实现了SimpleAnalyser和StandardAnalyser</li>
</ul>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ul>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-lucene1/index.html" target="_blank" rel="external">初识Lucene</a> 周登鹏</li>
<li><a href="https://www.chedong.com/tech/lucene.html" target="_blank" rel="external">Lucene：基于Java的全文检索引擎简介</a> 车东</li>
<li><a href="https://gitsea.com/wp-content/uploads/2013/04/Annotated-Lucene%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E4%B8%AD%E6%96%87%E7%89%88.pdf" target="_blank" rel="external">Anotated Lucene</a>  naven</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/17/lucene数据结构解析/" data-id="cjptnh2ar0000i9qh7c3ic83s" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-git命令行常用总结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/17/git命令行常用总结/" class="article-date">
  <time datetime="2018-12-17T07:39:28.000Z" itemprop="datePublished">2018-12-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="git命令行常用命令"><a href="#git命令行常用命令" class="headerlink" title="git命令行常用命令"></a>git命令行常用命令</h1><h3 id="使用命令行的优势"><a href="#使用命令行的优势" class="headerlink" title="使用命令行的优势"></a>使用命令行的优势</h3><ul>
<li>使用命令行需要知其然，也需知其所以然，强迫你更完整的了解git，减少犯错</li>
<li>命令行速度更快，因为敲命令比移动光标快多了（不然还要vi干什么），我个人基本所有的工具都是命令行向的，idea除外，毕竟使用vi开发的段位实在太高了……</li>
<li>命令行使用更方便，打开个终端就能用</li>
</ul>
<h3 id="本地分支与远程分支"><a href="#本地分支与远程分支" class="headerlink" title="本地分支与远程分支"></a>本地分支与远程分支</h3><ul>
<li>同一个分支有远程origin和本地两个副本。远程分支是所有人可见的版本，本地分支只有本人可见。在合适的时机进行本地和远程分支之间的同步，从而保证每个人开发的隔离</li>
</ul>
<h3 id="复制远程仓库-git-clone-HOST"><a href="#复制远程仓库-git-clone-HOST" class="headerlink" title="复制远程仓库 git clone $HOST"></a>复制远程仓库 git clone $HOST</h3><ul>
<li>$HOST可以是ssh地址或者http地址，一般我习惯于使用ssh地址，不需要额外管理账号密码，直接在git服务器配置本机ssh-key即可</li>
</ul>
<h3 id="检出某一分支-git-checkout"><a href="#检出某一分支-git-checkout" class="headerlink" title="检出某一分支 git checkout"></a>检出某一分支 git checkout</h3><ul>
<li>git checkout $BRANCH_NAME，注意不要带origin，git会自动将本地$BRANCH_NAME分支和远程origin/BRANCH_NAME分支绑定</li>
<li>类似linux shell中”cd -“，git也支持”git checkout -“切换到上一个分支</li>
</ul>
<h3 id="从origin更新分支-git-pull"><a href="#从origin更新分支-git-pull" class="headerlink" title="从origin更新分支 git pull"></a>从origin更新分支 git pull</h3><ul>
<li>若本地有未同步的提交（commit），建议使用rebase选项git pull –rebase。想了解rebase的目的及和merge的区别请看<a href="https://git-scm.com/book/zh/v2/Git-%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA" target="_blank" rel="external">这里</a></li>
<li>如果本地有未commit的变更，可以使用stash先暂存变更，更新后再恢复原有的变更<ol>
<li>git stash</li>
<li>git pull –rebase</li>
<li>git stash pop</li>
</ol>
</li>
</ul>
<h3 id="提交本地变更-git-commit"><a href="#提交本地变更-git-commit" class="headerlink" title="提交本地变更 git commit"></a>提交本地变更 git commit</h3><ul>
<li>git commit -m “testtest”</li>
</ul>
<h3 id="将本地变更同步到远程-git-push"><a href="#将本地变更同步到远程-git-push" class="headerlink" title="将本地变更同步到远程 git push"></a>将本地变更同步到远程 git push</h3><ul>
<li>git push</li>
</ul>
<h3 id="合并分支"><a href="#合并分支" class="headerlink" title="合并分支"></a>合并分支</h3><ul>
<li>git merge $TARGET_BRANCH。这里的分支可以指定本地或远程（带origin或不带origin），在保证本地跟远程是同步的情况下，这两种操作没有区别。建议使用先pull后merge origin/master这种操作</li>
</ul>
<h3 id="IDEA中的常用GUI操作"><a href="#IDEA中的常用GUI操作" class="headerlink" title="IDEA中的常用GUI操作"></a>IDEA中的常用GUI操作</h3><ul>
<li>​由于使用IDEA开发，所以也经常要在IDEA中进行代码的更新提交等操作，有一些操作用起来也很方便</li>
<li>pull操作，idea会自动使用stash和rebase选项（可配置），设置快捷键可以使代码的更新非常方便</li>
<li>commit操作，使用GUI可以方便的进行code review比对，减少错误代码甚至误提交的代码</li>
<li>冲突处理，IDEA中可以做local changes/remote changes比较，并合并出最终结果，非常方便</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/17/git命令行常用总结/" data-id="cjps0hy8r0004s6qhtpd6iu6j" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Time-Series-Data-Introduction" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/27/Time-Series-Data-Introduction/" class="article-date">
  <time datetime="2018-11-27T10:15:07.000Z" itemprop="datePublished">2018-11-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/27/Time-Series-Data-Introduction/">Time-Series Data Introduction</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>翻译自Time-ScaleDB博客：<a href="https://blog.timescale.com/what-the-heck-is-time-series-data-and-why-do-i-need-a-time-series-database-dcf3b1b18563" target="_blank" rel="external">What the heck is time series data</a></li>
</ul>
<h3 id="时间序列数据介绍"><a href="#时间序列数据介绍" class="headerlink" title="时间序列数据介绍"></a>时间序列数据介绍</h3><ul>
<li>我们先思考一个问题：特斯拉汽车自动驾驶系统、华尔街金融交易算法、智能家居系统、支持当日闪电送达的物流网络，以及纽约警察局的信息发布系统之间有什么共同点</li>
<li>首先他们都是我们的世界正在超速运转的缩影。随着技术的发展，数据的收集和处理能力越来越强，数据累积膨胀的速度也越来越快</li>
<li>但是，如果你进一步思考，应该可以注意到，上述的每一个系统都涉及一种特殊的数据<ul>
<li>自动驾驶汽车要持续收集汽车在行驶过程中不断变化的外部环境</li>
<li>金融交易系统要不断的收集瞬息万变的市场信息</li>
<li>智能家居实时监控家居内部的信息，支持它完成温度调节、识别入侵者、响应主人的指令等</li>
<li>我们习惯于便宜的当日达快递服务，背后是因为零售工业可以极为有效和准确的监控快速移动中的资产</li>
<li>纽约警察局跟踪警车的服务状态，以便更好的提供警务服务</li>
</ul>
</li>
<li>这些系统全都依赖一种特殊形式的数据，这种数据以时间为维度记录事务的状态变化。时间在这里不仅仅是一个属性，而是组织数据的主轴</li>
<li>这种数据就是我们要描述的时间序列数据（Time-Series Data），它正起到越来越重要的作用</li>
<li>DB-Engines提供的过去24个月不同类型数据库的增长曲线显示，时间序列数据库（以下简称TSDBs）是增长最快的数据库类型</li>
<li><img src="../images/db-ranking-categories.jpeg" alt="image"></li>
<li>作为一种全新的开源时间序列数据库开发者，我们经常被问及这种趋势和它所代表的意义。我们总结了以下三个问题，并进行深入回答<ul>
<li>什么是时间序列数据</li>
<li>我什么时候要用TSDBs</li>
<li>选择TimescaleDB的理由</li>
</ul>
</li>
</ul>
<h3 id="什么是时间序列数据time-series-data"><a href="#什么是时间序列数据time-series-data" class="headerlink" title="什么是时间序列数据time-series data"></a>什么是时间序列数据time-series data</h3><ul>
<li>有人认为时间序列数据是按时间排序的，描述同一事物的，一系列的数据点的集合。然而这只看到了表面特征</li>
<li>也有的人把time-series data看成是带时间戳和不同属性的数值，这实际上是time-series data的一种建模方式，不是time-series data本身</li>
<li>让我们继续深入</li>
<li>下图描述了一个简单的场景，图像感应器收集来自城市、农场、工厂的数据。每个数据源周期性的将收集到的数据发送发送出去</li>
<li><img src="https://cdn-images-1.medium.com/max/1600/1*GIOYjAyTjAaOK7HgAdAdVA.gif" alt="image"></li>
<li>举另一个例子，以下是纽约市2016年最初几秒记录的出租车运营信息，请注意下图，每行数据都是特定时间点的记录</li>
<li><img src="../images/nyc-taxi rides for the first few seconds of 2016.jpeg" alt="image"></li>
<li>更多time-series data的例子：devOps的监控数据，互联网/移动互联网应用的事件流，工业数据，科学计量数据等</li>
<li>这些数据集合有以下3个共同特征<ul>
<li><font color="red">数据只插入不更新</font><br>- <font color="red">数据按时间顺序写入</font><br>- <font color="red">时间是主轴</font></li>
</ul>
</li>
<li>换句话说，teim-series data基本都是append-only，只在修正错误数据等特殊情况下，会需要修改已插入的数据</li>
<li>所以，这<font color="red">跟在普通数据上加个时间戳有什么区别</font></li>
<li>这取决于如何跟踪数据变化，是在现有数据上更新，还是新增一条数据</li>
<li>从sensor_x传来的新数据，是覆盖原有的数据还是插入一条新数据？两种方法都能表示当前系统的状态，但是通过插入新数据，可以实现对系统历史状态（不同时间数据）的追踪</li>
<li>记住一条：time-series data通过插入新数据跟踪系统的变化</li>
<li>这种记录每时每刻系统的数据变化的实践方法，是time-series data强大功能的根本。通过历史数据跟踪系统变化：分析历史数据如何变化，监控当前系统状态，预测系统未来的变化趋势</li>
<li>综上，我们对time-series data的定义如下：<font color="red">通过一个数据集合跟踪反应系统/进程/行为随时间的变化过程的数据</font>我们的定义的核心就在“变化”</li>
<li>事实上，我们在很多场景都在不知情的情况下使用time-series data</li>
<li>以网站跟踪用户登录为例，一种方案是在一条数据上，每次都更新用户的最后登录时间；另一种方案是每次用户登录都记录一条登录数据，这样我们就可以跟踪历史登录活动，跟踪用户的使用增减情况，追踪用户的使用频率等</li>
<li>在这个例子中，通过分析数据固有的时间特征，我们可以从数据随时间的变化中，挖掘出更多有价值的信息（从这个例子可以想到，事件流数据也是time-series data）</li>
<li>当然，time-series data也有一个显而易见的问题：数据增长非常快</li>
<li>在这样大的数据量集下，高效的写入和查询数据就面临很多问题，这也正是人们开始使用time-series databases的原因</li>
</ul>
<h3 id="什么情况下使用TSDB"><a href="#什么情况下使用TSDB" class="headerlink" title="什么情况下使用TSDB"></a>什么情况下使用TSDB</h3><ul>
<li>为什么不能使用普通数据库（非time-series database）呢？</li>
<li>事实是，有很多人用的正是普通数据库，如下图</li>
<li><img src="../images/percentage of respondents.jpeg" alt="image"></li>
<li>但是，为什么多数受访者选择使用TSDB而不是普通数据库？为什么TSDB发展这么快？</li>
<li>2个原因：<ul>
<li>Scale。Time-Series data累积的速度非常快，普通数据库的设计思路没有专门考虑处理这么大的数据量级，关系数据库处理海量数据性能非常差，NoSQL在海量数据下性能表现要好些，但是仍远比不上设计优秀的time-series database。相反，TSDB（可能是基于关系数据设计实现的）针对time-series data的时间优先特性进行了改进设计。这种设计带来了性能的提升，包括更高的吞吐量、海量数据下的快速查询、以及更好的数据压缩。</li>
<li>Usability。TSDB也提供time-series data分析涉及的功能和操作。包括数据保留政策、持续查询、便捷的聚合功能等。即便在数据量不大的时候，这些特性也能提升time-series data操作过程的可用性和易用性</li>
</ul>
</li>
<li>这是开发者使用TSDB的原因，以下是一些典型的use case<ul>
<li>软件系统监控：虚拟机、容器、服务、应用等</li>
<li>物理系统监控：设备、机械、物联网、环境、家具、人体等</li>
<li>财务交易系统：保险行业、在线货币</li>
<li>事件应用：跟踪用户/客户交互信息</li>
<li>BI工具：跟踪business特性和整体的健康状况</li>
</ul>
</li>
<li>即便是TSDB普遍拥有这些强大的特性，根据实际的业务模型、读写特性选择合适的TSDB也很重要</li>
</ul>
<h3 id="使用TimescaleDB的优势"><a href="#使用TimescaleDB的优势" class="headerlink" title="使用TimescaleDB的优势"></a>使用TimescaleDB的优势</h3><ul>
<li>其它<a href="https://misfra.me/2016/04/09/tsdb-list/" target="_blank" rel="external">tsdb列表</a></li>
<li>TimescaleDB设计的初衷是使用完整的SQL特性，这是以上其它tsdb所不具备的特征</li>
<li>其它一些问题：<ul>
<li>查询延迟高</li>
<li>有些查询不支持</li>
<li>需要学习新的查询语言（非SQL）</li>
<li>不支持很多工具</li>
<li>很多数据要准备relational数据库和time-series 数据库两份数据</li>
</ul>
</li>
<li>为了解决这些问题，我们开发了TimescaleDB，并在Apache2 license下开源</li>
<li>如果你有以下需求，可以考虑TimescaleDB：<ul>
<li>通过SQL访问数据</li>
<li>统一关系数据库和tsdb</li>
<li>关系数据和time-series 数据连接查询</li>
<li>PostgreSQL</li>
<li>查询性能提升</li>
<li>geospatial支持</li>
<li>三方工具：SQL相关工具、BI工具</li>
</ul>
</li>
<li>如果你的业务有以下特征，不应该使用TimescaleDB<ul>
<li>查询方式简单（kv查询，简单一维查询）</li>
<li>稀松数据，非结构化数据</li>
</ul>
</li>
</ul>
<h3 id="延伸思考：所有的数据都是time-series-data？"><a href="#延伸思考：所有的数据都是time-series-data？" class="headerlink" title="延伸思考：所有的数据都是time-series data？"></a>延伸思考：所有的数据都是time-series data？</h3><ul>
<li>我们前文讲过，我们在很多场景都在使用time-series data但是我们没有意识到</li>
<li>考虑几个普通的数据集，比如银行的账户和流水、比如软件工程的源代码、博客内容</li>
<li>通常我们存储系统的最终状态。但是，如果换个思路，我们记录数据的每次变化，并在查询时计算当前状态。所谓的普通数据，不就是固有时间属性的数据集反应出的最终状态吗（从性能考虑缓存了最终状态）？软件源代码不是都有版本控制吗？博客本身不也有版本修订记录吗？</li>
<li>再者，是不是所有的数据库都有日志？</li>
<li>许多应用可能永远也不会用到time-series data，但是它们可以被认为是使用current-state view的TSDB版本。随着业务的发展，可能current-state view模式会产生瓶颈。这时候就可以考虑将数据转为time-series data。比如现在流行使用事件流来记录订单，从而更好的跟踪订单的历史状态和变化过程</li>
<li>是不是所有的数据都是time-series data呢？我们还没找到有说服力的反例来，如果你觉得有，欢迎联系我们讨论学习</li>
<li>最后，time-series data已经形成潮流，开始用起来吧！</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/27/Time-Series-Data-Introduction/" data-id="cjps0hy8o0003s6qhn19m5t6v" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-java团队code style规范" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/01/java团队code style规范/" class="article-date">
  <time datetime="2018-04-01T13:06:52.000Z" itemprop="datePublished">2018-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/01/java团队code style规范/">java团队code style规范</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="java团队code-style规范"><a href="#java团队code-style规范" class="headerlink" title="java团队code style规范"></a>java团队code style规范</h1><ul>
<li>摘选自《阿里巴巴Java开发手册》（孤尽），主要挑选个人感受最多的，影响代码阅读和维护、易于产生错误或误解的点，期望在团队层面建立良好的、易于接受推进的编码习惯和风格。</li>
<li>总结了少量重要的java知识点错用、误用的场景，需要在日常coding中避免</li>
<li>《阿里巴巴Java开发手册》原文可以在<a href="https://m.aliyun.com/yunqi/articles/215391" target="_blank" rel="external">阿里云</a>下载，也可以购买纸质版（略贵）、</li>
</ul>
<h2 id="Code-Style"><a href="#Code-Style" class="headerlink" title="Code Style"></a>Code Style</h2><h3 id="命名风格"><a href="#命名风格" class="headerlink" title="命名风格"></a>命名风格</h3><ul>
<li><font colore="blue">以达到代码自解释为目的</font></li>
<li>常量全部使用大写，单次之间用下划线”_”隔开；非常量及函数使用UpperCamelCase风格</li>
<li>不要嫌明明太长，不合理的缩写产生的影响远比多读几个单次要大</li>
<li>禁止使用拼音英文混合的命名方式，一般也不建议使用全拼音</li>
<li>数组定义统一使用String[] args的格式，不要使用String args[]</li>
<li>POJO类的bool类型变量不加is，防止有些框架解析错误（自动去掉is）</li>
</ul>
<h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><ul>
<li>拒绝magic value</li>
</ul>
<h3 id="代码格式"><a href="#代码格式" class="headerlink" title="代码格式"></a>代码格式</h3><ul>
<li>long类型赋值，用L结尾，不要用l，容易与1产生混淆。long testValue = 0L；不要用做long testValue = 0l</li>
<li>关于换行<ul>
<li>第二行相对第一行缩进4个空格，第三行开始不再持续缩进</li>
<li>运算符与下文一起缩进。<pre><code><br>boolean testFlag = aVeryLongNameMethodWithBoolReturnValueFoo1()<pre><code>&amp;&amp; anotherVeryLongNameMethodWithBoolReturnValueFoo2()
&amp;&amp; anotherVeryLongNameMethodWithBoolReturnValueFoo3();
</code></pre>  </code></pre></li>
<li>.与下文一起缩进。<pre><code><br>StringBuilder testStringBuilder = new StringBuilder()<pre><code>.append(&quot;test&quot;)
.append(&quot;test1&quot;);
</code></pre></code></pre></li>
</ul>
</li>
<li>不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开</li>
</ul>
<h3 id="OOP"><a href="#OOP" class="headerlink" title="OOP"></a>OOP</h3><ul>
<li>复写方法必须加@Override</li>
<li>开放出去的接口不允许修改或删除接口签名（包括类名、方法名、常量名）</li>
<li>禁止使用@Deprecated方法</li>
<li>Object.equals()，为防止NPE，使用”test”.equals(aStr)替代aStr.equals(“test”)</li>
<li>注意primitive类型比较时，注意auto box和unbox的规则，如不了解，全部是primitive时使用==，涉及包装类对象时，使用equals</li>
<li>POJO属性全部使用包装类对象，RPC方法参数、返回值使用包装类对象</li>
<li>类内部的方法定义顺序：public方法/protected方法 &gt; private方法 &gt; getter/setter</li>
<li>集合初始化时指定集合初始大小</li>
<li>Map遍历使用entrySet，不要使用keySet</li>
</ul>
<h3 id="控制语句"><a href="#控制语句" class="headerlink" title="控制语句"></a>控制语句</h3><ul>
<li>多重嵌套的if-else语句使用卫语句代替</li>
</ul>
<h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><ul>
<li>通过好的命名来达到自解释</li>
<li>类、类属性、类方法注释必须使用Javadoc规范，功能复杂的难以做到self descriptive的需要说明类和方法分别做什么事情，根据需要也应该增加复杂逻辑的解释</li>
<li>所有类都要添加创建者和创建日期</li>
</ul>
<h3 id="日志规约"><a href="#日志规约" class="headerlink" title="日志规约"></a>日志规约</h3><ul>
<li>使用占位符替代字符串拼接，特别注意debug日志，可以防止不必要的字符串拼接<pre><code><br>// 使用<br>log.debug(“processing trade, id={}, name={}”, id, name);<br>// 不使用<br>log.debug(“processing trade, id=” + id + “, name=” + name);<br></code></pre></li>
</ul>
<h3 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h3><ul>
<li>索引命名<ul>
<li>主键 PK_${fieldName}</li>
<li>唯一索引 UK_${fieldName}</li>
<li>普通索引 IDX_${fieldName}</li>
</ul>
</li>
<li>小数类型使用decimal，禁止使用double和float</li>
<li>表必备字段id，gmt_create, gmt_modified</li>
<li>varchar字段建索引时要指定长度，不需要全部索引</li>
<li>不要使用count(1), count(列名)替代count（*）</li>
<li>POJO类bool属性命名不能加is前缀，而数据库字段需加is</li>
<li>更新时指定字段更新，不要传入对象全部更新</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/01/java团队code style规范/" data-id="cjps0hy9d0008s6qhu0x57zn8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/bigdata/">bigdata</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell-linux-ops/">shell,linux,ops</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/技术内幕/">技术内幕</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/用户触达/">用户触达</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/笔记/">笔记</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/设计模式/">设计模式</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/运维-DevOps/">运维,DevOps</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/elasticsearch/" style="font-size: 20px;">elasticsearch</a> <a href="/tags/redis/" style="font-size: 10px;">redis</a> <a href="/tags/shell-linux-ops/" style="font-size: 10px;">shell,linux,ops</a> <a href="/tags/技术内幕/" style="font-size: 20px;">技术内幕</a> <a href="/tags/用户触达/" style="font-size: 10px;">用户触达</a> <a href="/tags/笔记/" style="font-size: 20px;">笔记</a> <a href="/tags/设计模式/" style="font-size: 10px;">设计模式</a> <a href="/tags/运维-DevOps/" style="font-size: 10px;">运维,DevOps</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/01/20/笔记：redis设计与实现/">笔记：redis设计与实现</a>
          </li>
        
          <li>
            <a href="/2019/01/20/常见设计模式总结/">常用设计模式总结</a>
          </li>
        
          <li>
            <a href="/2019/01/20/笔记——《ElasticSearch技术内幕》/">笔记——《ElasticSearch技术内幕》</a>
          </li>
        
          <li>
            <a href="/2018/12/20/服务集群异常监控/">服务监控</a>
          </li>
        
          <li>
            <a href="/2018/12/20/旅行基础数据搜索/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 SeventyNine<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>