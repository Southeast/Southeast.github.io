<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Life Career</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Life Career">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Life Career">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Life Career">
  
    <link rel="alternate" href="/atom.xml" title="Life Career" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Life Career</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-服务集群异常监控" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/20/服务集群异常监控/" class="article-date">
  <time datetime="2018-12-20T10:00:07.000Z" itemprop="datePublished">2018-12-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/12/20/服务集群异常监控/">服务监控</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="服务监控"><a href="#服务监控" class="headerlink" title="服务监控"></a>服务监控</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><ul>
<li>业务trace<ul>
<li>按时间顺序追踪业务流程的关键节点，主要包括以下两个部分：</li>
<li>搜索部分：用户产品选择、验价结果记录等</li>
<li>订单部分：下单、付款、关单、出单、退改签等</li>
<li>日志跟踪效果：</li>
<li><img src="../images/query-trace-log.png" alt="image"></li>
</ul>
</li>
<li>商家接口监控报警<ul>
<li>每天机票、酒店、火车票商家的接口状态追踪，对异常情况进行通知报警（邮件/短信）</li>
<li>邮件报警效果：</li>
<li><img src="../images/task-item-notification.png" alt="image"></li>
<li>报表效果：</li>
<li><img src="../images/taskitem-report.png" alt="image"></li>
</ul>
</li>
<li>异常监控<ul>
<li>服务器异常及错误日志监控报警，超过阈值时进行通知(短信)</li>
<li><img src="../images/exception-report.png" alt="image"></li>
</ul>
</li>
</ul>
<h2 id="业务流程trace"><a href="#业务流程trace" class="headerlink" title="业务流程trace"></a>业务流程trace</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><ul>
<li>需求：我们的产品有很长的系统流转过程，从用户选择产品，下单，商品的预定与售后等，有些关键数据需要记录下来防止用户纠纷，而系统运维、问题排查等要依赖各个节点的数据（用户/商品快照/价格快照/用户操作记录等）。当给定一个订单或产品时，我们通过订单id或产品标示就可以查到其业务流转过程中的所有关键节点数据日志，从而可以快速定位问题，解决纠纷</li>
<li>方案：通过ELK，Filebeat收集日志数据，Logstash对日志数据进行处理，ElasticSearch存储处理后的数据。在ElasticSearch数据基础上，通过Kibana进行可视化报表展示，也可以通过watcher插件进行报警通知</li>
</ul>
<h3 id="日志生成策略"><a href="#日志生成策略" class="headerlink" title="日志生成策略"></a>日志生成策略</h3><ul>
<li>统一的key追踪<ul>
<li>产品搜索key。用户搜索产品时的唯一产品标识，通过URL参数生成UUID，用这个UUID作为产品的唯一标识和日志追踪key</li>
<li>订单key。用户产品下单后，需要用订单id来追踪日志</li>
<li>key关联。将产品key和订单key进行关联，从而通过一个key可以看到完整的日志数据</li>
</ul>
</li>
<li>日志结构<pre><code><br>  public static void trace(String key, String secondaryKey, StepEnum step, String msg) {<pre><code>JSONObject traceLog = new JSONObject();
traceLog.put(&quot;key&quot;, key);
traceLog.put(&quot;secondaryKey&quot;, secondaryKey);
traceLog.put(&quot;step&quot;, step.getStepName());
traceLog.put(&quot;subStep&quot;, step.getSubStepName());
traceLog.put(&quot;message&quot;, msg);
traceLog.put(&quot;@timestamp&quot;, LocalDateTime.now());
log.info(traceLog.toJSONString());
</code></pre>  }<br></code></pre></li>
<li>在产品下单时，通过key和secondarykey将产品和订单进行关联</li>
<li>logstash数据处理。日志是json格式文本，通过json插件来完成数据提取(date插件提取时间戳)<pre><code><br>  json {<pre><code>source =&gt; &quot;message&quot;
remove_field =&gt; [&quot;message&quot;]
</code></pre>  }<br>  date {<pre><code>locale=&gt;&quot;en&quot;
match =&gt; [ &quot;startTime&quot;, &quot;ISO8601&quot; ]
target =&gt; &quot;startTime&quot;
</code></pre>  }<br></code></pre></li>
<li>ElasticSearch存储。按时间rotate数据，每天一个索引，最多保存7天</li>
<li>搜索<ul>
<li>排序，只按时间进行排序</li>
<li>关于分页，日志数量不大，暂时不做分页，后期考虑先在前端分页。最终可以通过doc_id或时间戳进行分页查询</li>
<li>通过产品链接或订单号查询所有日志</li>
</ul>
</li>
</ul>
<h2 id="商家接口监控报警"><a href="#商家接口监控报警" class="headerlink" title="商家接口监控报警"></a>商家接口监控报警</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><h3 id="日志收集"><a href="#日志收集" class="headerlink" title="日志收集"></a>日志收集</h3><ul>
<li>filebeat</li>
<li>logstash grok</li>
<li>ElasticSearch按业务线分集群flight/train/hotel，每个业务一个索引，索引每天rotate，每天一个索引</li>
</ul>
<h3 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h3><ul>
<li>使用kibana配置，<ul>
<li>注意粒度，一般使用最小一分钟作为最细粒度就可以了</li>
<li>多维统计可以拆图（split chart）或拆线（split line），也可以组合使用来实现更详尽的图表表达</li>
<li>酒店status报表，代理商拆图，status拆表。用于监控接口状态</li>
<li><img src="../images/hotel-taskitem-split.png" alt="image"></li>
<li>酒店执行时间报表。用于监控接口执行时间</li>
<li><img src="../images/hotel-taskitem-exectime.png" alt="image"></li>
</ul>
</li>
<li>可以将多个报表iframe嵌入其它系统统一查看（如运营后台）</li>
</ul>
<p>### </p>
<h2 id="异常监控"><a href="#异常监控" class="headerlink" title="异常监控"></a>异常监控</h2><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><ul>
<li>需求：对系统运行过程中产生异常和错误日志进行监控和实时通知</li>
<li>方案：同样通过ELK收集、处理并存储</li>
</ul>
<h3 id="日志收集-1"><a href="#日志收集-1" class="headerlink" title="日志收集"></a>日志收集</h3><ul>
<li>filebeat 多行处理。filebeat默认每行日志作为一个事件来处理，而异常日志多是多行的，需要进行额外的配置<pre><code><br>filebeat:<h1 id="List-of-prospectors-to-fetch-data"><a href="#List-of-prospectors-to-fetch-data" class="headerlink" title="List of prospectors to fetch data."></a>List of prospectors to fetch data.</h1>prospectors:<br>  -<pre><code>paths:
  - &quot;/opt/jdy-applog/*/*/*/taskitem*.log&quot;
input_type: log
</code></pre>  -<pre><code>paths:
  - &quot;/opt/jdy-applog/*/*/*/error*.log&quot;
input_type: log
multiline.pattern: &apos;^[0-9]{4}-[0-9]{2}-[0-9]{2}&apos;
multiline.negate: true
multiline.match: after
</code></pre>output:<br>logstash:<br>  hosts: [“logstash1.jdydev.cn:5043”, “logstash2.jdydev.cn:5043”, “logstash3.jdydev.cn:5043”]<br></code></pre></li>
<li>Exception/Error 名称。grok有对应的exceptionName正则式，可以在logstash grok filter中使用下列语句进行截取<pre><code><br>filter{<br>  mutate { add_field =&gt; { “businessLine” =&gt; “errorlog” } }<br>  grok {<pre><code>patterns_dir =&gt; [&quot;/home/jdy/jdy-elk/logstash-5.3.0/config/patterns&quot;]
match =&gt; { &quot;message&quot; =&gt; [&quot;%{JAVA_EXCEPTION_SIGNATURE:exceptionName}&quot;]}
</code></pre>  }<br>}<br></code></pre></li>
</ul>
<h3 id="可视化-1"><a href="#可视化-1" class="headerlink" title="可视化"></a>可视化</h3><ul>
<li>用kibana配置报表</li>
<li>重点异常重点跟踪，例如我们将redis异常的跟踪到每台机器，这样可以从报表中获得更多信息：</li>
<li><img src="../images/redis-exception-report.png" alt="image"></li>
</ul>
<h3 id="报警"><a href="#报警" class="headerlink" title="报警"></a>报警</h3><ul>
<li>定时程序汇总，例如查询过去5分钟内的异常数量，当超过一定值时进行报警，可以针对某一异常单独配置阈值，也可以自动累积历史数值，创建基线作为阈值。threshold = a * threshold + val(0&lt;a&lt;1, val是当前异常数量)</li>
<li>短信告警（云片）。异常的通知通常属于紧急事件，需要保证通知触达率及打开率，因此使用短信通知，可以使用邮件额外</li>
</ul>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><h3 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h3><ul>
<li>理论上可以实现at least once机制，保证数据不丢失，但是可能会有重复</li>
<li>logstash需要persistent queue来保证100%的不丢失</li>
<li>如果进程异常退出或被异常关闭（kill -9），会导致inflight数据丢失，请注意ELK各进程的规范退出</li>
</ul>
<h3 id="实时性"><a href="#实时性" class="headerlink" title="实时性"></a>实时性</h3><ul>
<li>在统一的内网环境部署，忽略网络传输时间</li>
<li>日志落地。Logback日志本地缓存到异步落盘的时间在毫秒级别</li>
<li>filebeat生成事件。扫描间隔1s，强制上传时间（事件本地缓存的时间）是5s。</li>
<li>logstash处理时间。一般是毫秒级，可以通过x-pack查看延迟，可以按需求配置workers数量增加并发，提升排队延迟</li>
<li>索引延迟及索引可见的时间约1s</li>
<li>总计有1-10s的延迟，能够满足准实时需求</li>
<li>@timestamp使用默认的logstash处理时间，日志时间单独存储，可以比较出延迟时间（日志生成event -&gt; grok之间）</li>
</ul>
<h3 id="查询速度"><a href="#查询速度" class="headerlink" title="查询速度"></a>查询速度</h3><ul>
<li>global ordinals<ul>
<li>global_ordinals 是用于减少string类型的fielddata占用内存的技术。以我们的系统为例一个doc至少有10个keyword类型的field需要用于查询、聚合操作，假设每个keyword类型的平均长度是20个byte，1G（10亿）个doc的所有keyword field所占用的内存是10<em>20</em>1G=200G。global_ordinals对这些keyword的值进行编号，使用整数值来替代原始的字符串，查询计算完成之后，再用对应的字符串值替换序号，从而减小内存占用。由于一个整数值只占一个byte，因此这些field全都加载到内存占用的内存大小是10*1G=20G。只有原来的1/20</li>
<li>好处：1. 降低内存占用2. 极大提高汇总排序查询的速度</li>
<li>global ordinals默认在搜索时加载，text和keyword field默认在搜索时构建global ordinals，这样在第一次搜索时，在数据量很大的情况下，用户会感受到明显的延迟。</li>
<li>可以通过配置eager_global_ordinals将global_ordinals的构建从搜索转移到索引的构建刷新。</li>
</ul>
</li>
<li>缓存</li>
</ul>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>日志记录要在侵入性和灵活性之间做权衡，我们处在业务初始阶段，变化较多，因此目前记录的日志都是侵入性日志</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/20/服务集群异常监控/" data-id="cjpwfntqk00006nqhdrlfmsvb" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/bigdata/">bigdata</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-旅行基础数据搜索" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/20/旅行基础数据搜索/" class="article-date">
  <time datetime="2018-12-20T09:40:59.000Z" itemprop="datePublished">2018-12-20</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="旅行基础数据搜索"><a href="#旅行基础数据搜索" class="headerlink" title="旅行基础数据搜索"></a>旅行基础数据搜索</h1><ul>
<li>支持旅行基础数据的全文搜索</li>
<li>支持数据全部属性的搜索，包括名称、拼音、简拼、英文名称、内容介绍等</li>
<li>支持的行业数据包括<ul>
<li>地理数据：国家/地区/省份/城市</li>
<li>POI数据：餐厅/景点/地标/酒店</li>
</ul>
</li>
</ul>
<h2 id="索引构建"><a href="#索引构建" class="headerlink" title="索引构建"></a>索引构建</h2><ul>
<li>使用logstash <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html" target="_blank" rel="external">jdbc input plugin</a>从数据库导入数据</li>
<li>数据导入。配置驱动、user、password、sql</li>
<li>指定doc_id保证数据唯一性，比如用表明+id拼一个字段作为document_id，在elasticsearch output插件中指定document_id，防止数据重复导入</li>
<li>定时调度。配置schedule语句</li>
<li>实现示例<pre><code><br>jdbc {<pre><code>jdbc_driver_library =&gt; &quot;/home/jdy/jdy-elk/logstash-5.3.0/vendor/jdbc/mysql-connector-java-5.1.35.jar&quot;
jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;
jdbc_connection_string =&gt; &quot;jdbc:mysql://59.110.207.194:3306/mytrip_basic&quot;
jdbc_user =&gt; &quot;jdy_db_admin&quot;
jdbc_password =&gt; &quot;******&quot;
schedule =&gt; &quot;0 * * * * &quot;
statement =&gt; &quot;SELECT p.*, c.name as countryName, &apos;province&apos; as table_name, CONCAT(&apos;PROVINCE-&apos;, provinceID) as doc_id FROM mytrip_basic.sys_province p le
</code></pre>ft join mytrip_basic.sys_country c on p.countryID=c.countryID where provinceID in (29)”<br>}<br>filter {<br>}<br>output {<br>  elasticsearch {<pre><code>hosts =&gt; &quot;10.30.137.118:9200&quot;
document_id =&gt; &quot;%{[doc_id]}&quot;
index =&gt; &quot;logstash-jdbc-basic&quot;
</code></pre>  }<br>}<br></code></pre></li>
</ul>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><ul>
<li>主要的查询语法<ul>
<li>Match Query。全文检索（full text query），ES会先对请求进行解析(analyze)，得到多个单独的词汇，逐个查询并综合评分，相当于google的搜索机制</li>
<li>Term Query。直接查询单独的term（要求term完全匹配），主要针对结构化的数据，例如数字、日期、枚举等，这些字段都是.keyword类型的field。</li>
<li>Bool组合。对多个Match Query和/或TermQuery进行组合查询</li>
</ul>
</li>
<li>前缀查询<ul>
<li>对Term Query可以支持前缀查询，尤其用户输入过程中一般要实现类似提示的效果，需要通过前缀查询进行支持</li>
<li>filter。相比Query，filter可以省去评分计算等过程，比Query的速度要更快，因此在不需要评分的场景应尽量使用filter替代query</li>
</ul>
</li>
<li>大小写处理。<ul>
<li>通过jdbc input插件的lowercase_column_names选项，指定想要小写处理的表属性    - 如果不使用动态mapping（dynamic mapping），可以通过ES mapping，指定某些字段为小写，之后用小写查询</li>
<li>注意需要显示指定某些字段进行小写处理，有些大小写混用的id类属性，全部转为小写会造成数据错误，例如服务器的hostName，Base64编码的属性等</li>
<li>我们在实际处理过程中没有改变存储的大小写，而是针对属性值的实际情况将查询串进行特殊处理（如小写、大写、首字母大写等）</li>
</ul>
</li>
<li>全拼音/拼音首字母<ul>
<li>有条件的进行拼音手工维护，能够保证准确率，如beijing，bj，shanghai，shh</li>
<li>通过github一些资源来生成拼音</li>
</ul>
</li>
<li>Boost设置。boost&gt;1可以增加某一子查询的评分重要程度。例如，我们认为在查询过程中name匹配应该比其他内容的匹配更重要，因此我们把name的boost设置为5.0</li>
<li>完整的查询方案<pre><code><br>{<br>  “query”: {<pre><code>&quot;filter&quot;: [
    {&quot;term&quot;: {&quot;table_name&quot;: &quot;hotel&quot;} }
],
&quot;bool: {
    &quot;should: [
        {&quot;match&quot;: {&quot;name&quot;: {&quot;query&quot;: keyword, &quot;operator&quot;: &quot;or&quot;}}},
        {&quot;match&quot;: {&quot;enname&quot;: keyword}},
        {&quot;prefix&quot;: {&quot;fs.keyword&quot;: keywordLowerCase}},
        {&quot;prefix&quot;: {&quot;pinyin.keyword&quot;: keywordLowerCase}},
        {&quot;prefix&quot;: {&quot;name.keyword&quot;: {&quot;value&quot;: keywordLowerCase, &quot;boost&quot;: 5.0}}},
        {&quot;prefix&quot;: {&quot;enname.keyword&quot;: {&quot;value&quot;: keywordLowerCase, &quot;boost&quot;: 5.0}}},
        {&quot;prefix&quot;: {&quot;fs.keyword&quot;: keywordFirstCapital}},
        {&quot;prefix&quot;: {&quot;pinyin.keyword&quot;: keywordFirstCapital}},
        {&quot;prefix&quot;: {&quot;name.keyword&quot;: {&quot;value&quot;: keywordFirstCapital, &quot;boost&quot;: 5.0}}},
        {&quot;prefix&quot;: {&quot;enname.keyword&quot;: {&quot;value&quot;: keywordFirstCapital, &quot;boost&quot;: 5.0}}}
    ]
},
&quot;minimum_should_match&quot;: 1
</code></pre>  },<br>  “size”:200,<br>  “_source”: true<br>}<br></code></pre></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/20/旅行基础数据搜索/" data-id="cjpwf1wq500004eqhj9cgcq64" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-筋斗云ELK集群" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/19/筋斗云ELK集群/" class="article-date">
  <time datetime="2018-12-19T05:34:12.000Z" itemprop="datePublished">2018-12-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="筋斗云ELK集群简介"><a href="#筋斗云ELK集群简介" class="headerlink" title="筋斗云ELK集群简介"></a>筋斗云ELK集群简介</h1><ul>
<li><font color="blue">本篇只对ELK的各组件做概要介绍，并描述他们可以实现的典型功能。后续的文章会陆续对不同需求场景的实现及服务运维进行陈述总结</font>

</li>
</ul>
<h2 id="筋斗云ELK集群支撑的功能"><a href="#筋斗云ELK集群支撑的功能" class="headerlink" title="筋斗云ELK集群支撑的功能"></a>筋斗云ELK集群支撑的功能</h2><ul>
<li>服务运行异常实时监控。收集各服务器上的异常及错误日志，归类统计与展示报警，用于实时的监控系统运行状态，今早发现问题</li>
<li>旅游内容搜索。国家/地区/城市/景点/餐馆/酒店等内容的全文搜索支持</li>
<li>业务数据监控。主要是各行业各合作商家的API状态监控，即时发现有问题的接口，防止对业务服务造成影响</li>
<li>全流程业务跟踪。将旅游产品从打包搜索-交易下单-出票出单-售后服务的全流程关键节点进行记录，并按照统一的key进行搜索，</li>
</ul>
<h2 id="ELK功能及特点简介"><a href="#ELK功能及特点简介" class="headerlink" title="ELK功能及特点简介"></a>ELK功能及特点简介</h2><ul>
<li><img src="../images/ELK-stack.png" alt="image"></li>
</ul>
<h3 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h3><ul>
<li>filebeat是一个轻量级的日志收集器（shipper for forwarding and centralizing log data）,在想要收集日志的服务器上，将filebeat作为agent安装，并指定要收集的日志文件路径和名称，指定日志的输出目标（Logstash或ElasticSearch服务）</li>
<li><img src="../images/filebeat.png" alt="image"></li>
</ul>
<h3 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h3><ul>
<li>Logstash通过实时管道（realtime pipelining）对数据进行实时处理，有良好的扩展机制，社区中也有大量实用的input、filter、output插件。能满足不同场景的数据导入和数据处理功能</li>
<li><img src="../images/logstash-process.png" alt="image"></li>
</ul>
<h3 id="ElasticSearch"><a href="#ElasticSearch" class="headerlink" title="ElasticSearch"></a>ElasticSearch</h3><ul>
<li>Elasticsearch是一个开源的、高度可扩展的全文检索与数据分析引擎</li>
<li>有以下重要特点：<ul>
<li>分布式支持，集群扩展/缩减透明</li>
<li>海量数据容量</li>
<li>准实时的索引速度（主要是ES索引可见大约有1s左右的延迟）</li>
</ul>
</li>
</ul>
<h3 id="Kibana"><a href="#Kibana" class="headerlink" title="Kibana"></a>Kibana</h3><ul>
<li>基于ElasticSearch数据进行数据可视化分析与展示</li>
</ul>
<h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><h3 id="集群效果"><a href="#集群效果" class="headerlink" title="集群效果"></a>集群效果</h3><ul>
<li>filebeat属于agent，部署在各个应用服务器上负责收集日志</li>
<li>logstash<ul>
<li>1个jdbc节点，处理数据库数据</li>
<li>3个log节点，处理log数据</li>
</ul>
</li>
<li>elasticsearch<ul>
<li>1个coordinate节点，类似于一个门面（facade），不存储数据，不做master节点，只负责将请求拆分到各个数据节点，并汇总各个数据节点的搜索结果返回给请求方</li>
<li>3个数据节点(80G SATA硬盘，8G内存，双核2.5GHz)</li>
</ul>
</li>
<li>elasticsearch性能指标<ul>
<li>业务数据每个业务一个索引，业务日志按每天一个索引，</li>
<li>200+索引</li>
<li>1亿+document</li>
<li>170G数据（60G/机器，实际落盘可能有压缩）</li>
<li>峰值document增量1000qps，primary shard 500qps</li>
<li>保留最近一周的数据</li>
</ul>
</li>
</ul>
<h3 id="系统初始化"><a href="#系统初始化" class="headerlink" title="系统初始化"></a>系统初始化</h3><ul>
<li>线上生产系统不能使用root启动ELK（filebeat可以），需要创建用户。另外需要修改最大文件数配置。在CentOS6系统下的配置脚本如下</li>
<li><pre><code>#!/bin/bash
useradd jdy
passwd jdy
sudo usermod -aG wheel jdy
sed -i "s/# %wheel\tALL=(ALL)\tALL/%wheel\tALL=(ALL)\tALL/g" /etc/sudoers
echo -e "\nulimit -n 100000" >> /etc/profile
sed -i "s/soft nofile 65535/soft nofile 100000/g" /etc/security/limits.conf
sed -i "s/hard nofile 65535/hard nofile 100000/g" /etc/security/limits.conf
echo -e "\njdy soft nproc 2048" >> /etc/security/limits.conf
echo -e "\njdy hard nproc 2048" >> /etc/security/limits.conf
echo -e "\nvm.max_map_count = 262144" >> /etc/sysctl.conf
reboot</code></pre>

</li>
</ul>
<h3 id="Elastic初始化配置"><a href="#Elastic初始化配置" class="headerlink" title="Elastic初始化配置"></a>Elastic初始化配置</h3><ul>
<li>配置文件：elasticsearch.yml &amp; log4j2.properties</li>
<li>重要配置：<ul>
<li><ol>
<li>node.name：node-n</li>
</ol>
</li>
<li><ol>
<li>cluster.name:系统通过广播发现使用相同cluster.name的节点，组成一个cluster（jdy-log）</li>
</ol>
</li>
<li><ol>
<li>bootstrap.memory_lock:要保证elastic进程内存不被swap到磁盘，需要设置memory_lock</li>
</ol>
</li>
<li><ol>
<li>设置network.host为<em>site</em></li>
</ol>
</li>
<li><ol>
<li>设置discovery.zen.ping.unicast.hosts为：[“10.27.246.125”, “10.27.74.199”, “10.27.72.7”, “10.170.247.171”]</li>
</ol>
</li>
<li><ol>
<li>设置discovery.zen.minimum_master_nodes为：（master_eligible_nodes / 2) + 1</li>
</ol>
</li>
<li><ol>
<li>堆内存大约设置到虚拟机内存的一半</li>
</ol>
</li>
<li><ol>
<li>centOS下关闭memory_lock：bootstrap.memory_lock: false, bootstrap.system_call_filter: false</li>
</ol>
</li>
</ul>
</li>
<li>配置配置<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#coordinating-node" target="_blank" rel="external">coordinate结点</a>，设置node.data, node.master_eligible, node.ingest为false，该结点不存储数据，只向数据结点分发数据请求，并合并计算结果</li>
<li>设置network.publish_host和network.bind_host，测试环境单机模式下，可使用network.host同时设置两个值为相同的ip，但在生产环境集群模式下通常这两个值不同。publish_host用于集群内网间监听和数据传输，bind_host用于提供外部网络访问</li>
</ul>
<h3 id="Logstash配置"><a href="#Logstash配置" class="headerlink" title="Logstash配置"></a>Logstash配置</h3><ul>
<li>主要的配置文件logstash.yml taskitem-pipeline.conf</li>
<li>通过在taskitem-pipeline.conf中配置input、filter及output，指定数据的输入输出及数据处理过程</li>
<li><img src="../images/basic_logstash_pipeline.png" alt="image"></li>
<li>至少2个logstash服务以保证服务可用性（filebeat有at least once机制保证数据不丢）</li>
<li>需要在filebeat中配置loadbalance：true，loadbalance模式包括：RoundRobin（default）、lock-step（强制保证多台机器的平均）</li>
<li>高吞吐量下，建议使用HAProxy做负载均衡</li>
<li>配置事件处理线程数：pipeline.batch.size=125</li>
<li>持久化input -&gt; queue -&gt; filter -&gt; output<ul>
<li><ol>
<li>防止内存数据丢失；</li>
</ol>
</li>
<li><ol>
<li>减缓事件峰值对事件处理造成的瞬间压力</li>
</ol>
</li>
<li><ol>
<li>配置queue.type: persisted, path.queue: $QUEUE_PATH, queue.max_events: 65536, queue.max_bytes:100M</li>
</ol>
</li>
<li><ol>
<li>基于checkpoint的<a href="https://www.elastic.co/guide/en/logstash/current/persistent-queues.html#durability-persistent-queues" target="_blank" rel="external">commit机制</a>,很多跟磁盘密切相关的操作都使用类似机制</li>
</ol>
</li>
<li><ol>
<li>注意如果logstash进程终止或硬件失败，队列中未commit（checkpointed）的数据会丢失。可以设置queue.checkpoint.writes=1来避免，但是要考虑由此带来的IO消耗，可能会阻塞logstash本身的运行   </li>
</ol>
</li>
</ul>
</li>
</ul>
<h3 id="x-pack"><a href="#x-pack" class="headerlink" title="x-pack"></a>x-pack</h3><ul>
<li>x-pack集成了elk许多高级特性，包括安全、监控、报警等。事实上，原来elasticsearch中许多有用的插件都被转移到了x-pack中，其中许多也变成了收费的功能，比如原来的watcher监控插件集成到x-pack的监控功能中后，需要收费的高级账号才能使用</li>
<li>由于都是内网运维，为了简单期间，我们关闭了访问密码的使用，在elasticsearch.yml中配置<pre><code><br>xpack.security.enabled: false<br></code></pre></li>
<li>监控功能默认是打开的，也可以在上述文件中配置关闭</li>
</ul>
<h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><h3 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h3><ul>
<li>不同版本之间的升级方案可能各不相同，具体请参考官方文档，这里仅给出我们一次升级过程</li>
<li>elastic 5.2-5.3 <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/rolling-upgrades.html" target="_blank" rel="external">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/rolling-upgrades.html</a></li>
<li>logstash 5.2-5.3  <a href="https://www.elastic.co/guide/en/logstash/current/upgrading-logstash.html" target="_blank" rel="external">https://www.elastic.co/guide/en/logstash/current/upgrading-logstash.html</a><ul>
<li><ol>
<li>解压缩logstash安装包</li>
</ol>
</li>
<li><ol>
<li>复制原路径config目录到新的安装位置</li>
</ol>
</li>
<li><ol>
<li>复制原data目录到新安装路径</li>
</ol>
</li>
<li><ol>
<li>重启logstash</li>
</ol>
</li>
</ul>
</li>
<li>kibana 5.2-5.3:<br><a href="https://www.elastic.co/guide/en/kibana/current/upgrade-standard.html" target="_blank" rel="external">https://www.elastic.co/guide/en/kibana/current/upgrade-standard.html</a><ul>
<li><ol>
<li>解压缩kibana安装包</li>
</ol>
</li>
<li><ol>
<li>复制原路径config目录到新的安装位置</li>
</ol>
</li>
<li><ol>
<li>复制原路径data目录到新的安装位置</li>
</ol>
</li>
<li><ol>
<li>重启kibana</li>
</ol>
</li>
</ul>
</li>
<li>x-pack license升级<ul>
<li>x-pack运行需要license，免费的license包括1年的basic和30天完整试用，免费的可以支持monitoring，目前我们的需求可以满足，因此需要每隔1年替换一次basic license。<font color="red">而且阿里云的ES集群价格对我们来说还是挺高的，相比我自己购买ECS部署，价格大约是3-4倍</font></li>
<li>查看license<pre><code><br>curl –user elastic:${password} -XGET <a href="http://localhost:9200/_xpack/license/" target="_blank" rel="external">http://localhost:9200/_xpack/license/</a><br></code></pre></li>
<li>申请新的license<br><a href="https://register.elastic.co/" target="_blank" rel="external">https://register.elastic.co/</a></li>
<li>license upgrade（在线执行，不需要停elastic服务）<pre><code><br>curl -XPUT -u elastic ‘<a href="http://localhost:9200/_xpack/license" target="_blank" rel="external">http://localhost:9200/_xpack/license</a>‘ -H “Content-Type: application/json” -d @/root/wang-xiaodong-a7d09d57-aab5-41b4-8b23-f185c899d10e-v5.json<br></code></pre></li>
</ul>
</li>
<li>force merge<ul>
<li>所有数据到位后(read only indices)，强制进行索引merge，可以减小索引文件数量，也有助于解决run out of file handles问题，便于长期数据存储。segment越多查询速度就会越慢，合并也有利于提升查询效率</li>
<li>进行force merge时所有请求都会被block，只应该用于read only索引</li>
<li>合并前后比较<ul>
<li>merge前 641.3mb  merge后634.8mb</li>
<li>merge前2.3g merge后2.2g</li>
</ul>
</li>
<li>设置crontab任务，调用API每天force merge readonly indices</li>
<li><pre><code>curl -X POST "http://localhost:9200/logstash-*-`date -d -10days +%Y.%m.%d`/_forcemerge?max_num_segments=1&flush=true&only_expunge_deletes=false"</code></pre>

</li>
</ul>
</li>
</ul>
<h2 id="重点问题："><a href="#重点问题：" class="headerlink" title="重点问题："></a>重点问题：</h2><ul>
<li>数据一致性<ul>
<li>filebeat-&gt;logstash：At Least Once机制，filebeat通过维护日志文件已处理行数的偏移量，确保Output对event进行confirm之后才不会重发。会导致重复接收。</li>
<li>logstash-&gt;elastic：At Least Once机制，logstash可以通过queue.type: persisted选项配置使用<a href="https://www.elastic.co/guide/en/logstash/current/persistent-queues.html" target="_blank" rel="external">persisted queue</a>或redis/kafka等消息中间件，实现at least once保证，并提供削峰平谷的功能。也可能会导致重复接收。</li>
<li><font color="red">checkpoint机制下，在checkpoint文件完成fsync前，logstash异常退出或硬件故障时，已进队列，但是未写入checkpoint的数据会丢失</font></li>
<li>如果document有唯一id，可以通过mapping制定id，来保证唯一性，防止接收重复数据导致的问题</li>
</ul>
</li>
<li>各节点的延迟问题<ul>
<li>filebeat收集。日志落地到文件后，filebeat默认的扫描间隔是1s，最小数据处理间隔filebeat.idle_timeout默认5s，可以按需求配置缩小扫描间隔和最小处理间隔。比如日志量很大时，缩小扫描间隔；日志量很小时，缩小filebeat.idle_timeout</li>
<li>logstash处理。当事件qps较高时，会有秒级的延迟，grok插件的使用非常消耗cpu，在每台机器用满的情况下，可以考虑扩展logstash集群。目前我们业务组的3台集群，在峰值1000qps时约有2-3秒的延迟</li>
<li>elasticsearch延迟。es构建索引的延迟是很小的，一般在1毫米以内，但是索引构建完成到索引可见仍有大约1s左右的延迟</li>
<li><font color="red">总的来说，elk是一套准实时的流式数据处理机制，数据从产生到可见，客观上会有大约1s-10s的延迟。可以满足绝大多数需求的实时性要求</font>

</li>
</ul>
</li>
</ul>
<h2 id="refernce"><a href="#refernce" class="headerlink" title="refernce"></a>refernce</h2><ul>
<li><a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-overview.html" target="_blank" rel="external">filebeat官方文档</a></li>
<li><a href="https://www.elastic.co/guide/en/logstash/current/persistent-queues.html" target="_blank" rel="external">logstash persistent queue</a></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/19/筋斗云ELK集群/" data-id="cjpuzqwvv0000e7qhfzzm8vz0" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-lucene数据结构解析" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/17/lucene数据结构解析/" class="article-date">
  <time datetime="2018-12-17T09:42:10.000Z" itemprop="datePublished">2018-12-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="lucene数据结构解析"><a href="#lucene数据结构解析" class="headerlink" title="lucene数据结构解析"></a>lucene数据结构解析</h1><ul>
<li><a href="https://github.com/apache/lucene-solr" target="_blank" rel="external">git代码地址</a></li>
<li>如果想深入了解底层实现，可以参考<a href="https://gitsea.com/wp-content/uploads/2013/04/Annotated-Lucene%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E4%B8%AD%E6%96%87%E7%89%88.pdf" target="_blank" rel="external">这里</a></li>
</ul>
<h2 id="lucene主要的包结构"><a href="#lucene主要的包结构" class="headerlink" title="lucene主要的包结构"></a>lucene主要的包结构</h2><ul>
<li>索引搜索 org.apache.lucene.search</li>
<li>索引构建 org.apache.lucene.index</li>
<li>语言分析器 org.apache.lucene.analysis</li>
<li>查询分析器 org.apache.lucene.queryparser</li>
<li>底层存储结构 org.apache.lucene.store</li>
<li>外部存储结构 org.apache.lucene.document</li>
</ul>
<h2 id="索引与查询基础结构（document）"><a href="#索引与查询基础结构（document）" class="headerlink" title="索引与查询基础结构（document）"></a>索引与查询基础结构（document）</h2><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><ul>
<li>文本处理<ul>
<li>Analyzer。处理text类型内容，例如去掉“a/an/the”等，去掉介词，名词复数变单数，动词时态转换<ul>
<li>StandardAnalyzer</li>
<li>SimpleAnalyzer</li>
<li>不同的语言实现类EnglishAnalyzer、JapaneseAnalyzer等</li>
</ul>
</li>
<li>Tokenizer。文本拆分为token流<ul>
<li>StandardTokenizer</li>
</ul>
</li>
<li>Filters。对每个token进行处理<ul>
<li>StandardFilter</li>
<li>LowerCaseFilter</li>
</ul>
</li>
</ul>
</li>
<li>IndexWriter：索引写入的外层API接口，底层依赖DocumentWriter，入口函数IndexWriter#addDocument</li>
<li>Document，代表了某一个存储对象的抽象，类似于数据库中一行具体的数据</li>
<li>Field，及Field的不同类型子类StringField,TextField,IntPoint等</li>
</ul>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><ul>
<li>Query/TermQuery。查询请求参数<ul>
<li>TermQuery</li>
<li>BooleanQuery</li>
</ul>
</li>
<li>QueryParser。查询请求转换器，将符合语法要求的queryString转化为Query对象</li>
<li>IndexSearcher：索引搜索的外层API接口，底层依赖index包的IndexReader类来完成数据搜索，入口函数IndexSearcher#search(Query, CollectorManager<c,t>)</c,t></li>
<li>Hit。搜索结果</li>
</ul>
<h2 id="索引存储结构（store）"><a href="#索引存储结构（store）" class="headerlink" title="索引存储结构（store）"></a>索引存储结构（store）</h2><ul>
<li>index<ul>
<li>segment文件。lucene的一个所以可以由多个子索引或segment组成，每一个segment都是一个完全独立的索引，可以独立进行检索。这种子索引的组织方式，可以使lucene在新增document时不断的创建新的segment以保障索引和查询速度，同时lucene会定期将小的segment合并为大的segment。</li>
<li>lock文件。写索引锁，保证同一时刻只有一个writer可以修改索引</li>
<li>Compound文件。这是一个简单的容器（container）来服务所有下一章节（next section）描述的文件（除了.del 文件）</li>
</ul>
</li>
<li>segment文件<ul>
<li>Field信息。Field 的名字都存储在 Field 信息文件中，后缀是.fnm。</li>
<li>Field数据。存储的 fields通过两个文件来呈现，即 field 索引文件（.fdx）和<br>field 数据文件（.fdt）。</li>
<li>Term字典。①存储 term 信息（TermInfoFile）的文件，即.tis 文件②存储 term 信息的索引文件，即.tii 文件，该文件包含.tis 文件中每一个 IndexInterval 的值，与它在.tis<br>中的位置一起被存储，这被设计来完全地读进内存中（read entirely into memory），以便用来提供随机访问.tis<br>文件。</li>
<li>Term频率数据。Term 频率数据文件（.frq 文件）存储容纳了每一个 term 的文档列表，以及该 term 出现在该文档中的频率</li>
<li>Positions位置信息数据。Positions 位置信息数据文件（.prx 文件）容纳了每一个 term 出现在所有文档中的位置的列表。</li>
<li>Norms调节因子文件</li>
<li>Terms向量文件</li>
<li>删除的文档</li>
</ul>
</li>
<li><img src="../images/lucene-segment-file-structure.png" alt="image"></li>
</ul>
<h2 id="lucene设计特点"><a href="#lucene设计特点" class="headerlink" title="lucene设计特点"></a>lucene设计特点</h2><ul>
<li>lucene索引的创新之处在于，在扩展索引的时候不断创建新的索引文件，然后定期把这些新的小索引文件合并到大的索引中，这样在不影响检索效率的前提下，提高了索引的效率</li>
<li>lucene的API接口设计比较通用，输入输出结构都很像数据库的表-&gt;记录-&gt;字段，所以很多传统应用的文件、数据库等都可以方便的映射到lucene的存储结构中</li>
<li>应用入口简单易懂，Searcher、Indexer，入口配合底层一系列组件协同完成索引/搜索的任务</li>
<li>所有的问题都设计了一个抽象层来方便以后的扩展和重用，使用者可以按自己的需求定制不同的模块，而其它模块功能可以保持不变，同时变更范围都是隔离可控的。在这些接口上，lucene提供了适合多数用户的标准实现，如Analyzer接口实现了SimpleAnalyser和StandardAnalyser</li>
</ul>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ul>
<li><a href="https://www.ibm.com/developerworks/cn/java/j-lo-lucene1/index.html" target="_blank" rel="external">初识Lucene</a> 周登鹏</li>
<li><a href="https://www.chedong.com/tech/lucene.html" target="_blank" rel="external">Lucene：基于Java的全文检索引擎简介</a> 车东</li>
<li><a href="https://gitsea.com/wp-content/uploads/2013/04/Annotated-Lucene%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E4%B8%AD%E6%96%87%E7%89%88.pdf" target="_blank" rel="external">Anotated Lucene</a>  naven</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/17/lucene数据结构解析/" data-id="cjptnh2ar0000i9qh7c3ic83s" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-git命令行常用总结" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/17/git命令行常用总结/" class="article-date">
  <time datetime="2018-12-17T07:39:28.000Z" itemprop="datePublished">2018-12-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="git命令行常用命令"><a href="#git命令行常用命令" class="headerlink" title="git命令行常用命令"></a>git命令行常用命令</h1><h3 id="使用命令行的优势"><a href="#使用命令行的优势" class="headerlink" title="使用命令行的优势"></a>使用命令行的优势</h3><ul>
<li>使用命令行需要知其然，也需知其所以然，强迫你更完整的了解git，减少犯错</li>
<li>命令行速度更快，因为敲命令比移动光标快多了（不然还要vi干什么），我个人基本所有的工具都是命令行向的，idea除外，毕竟使用vi开发的段位实在太高了……</li>
<li>命令行使用更方便，打开个终端就能用</li>
</ul>
<h3 id="本地分支与远程分支"><a href="#本地分支与远程分支" class="headerlink" title="本地分支与远程分支"></a>本地分支与远程分支</h3><ul>
<li>同一个分支有远程origin和本地两个副本。远程分支是所有人可见的版本，本地分支只有本人可见。在合适的时机进行本地和远程分支之间的同步，从而保证每个人开发的隔离</li>
</ul>
<h3 id="复制远程仓库-git-clone-HOST"><a href="#复制远程仓库-git-clone-HOST" class="headerlink" title="复制远程仓库 git clone $HOST"></a>复制远程仓库 git clone $HOST</h3><ul>
<li>$HOST可以是ssh地址或者http地址，一般我习惯于使用ssh地址，不需要额外管理账号密码，直接在git服务器配置本机ssh-key即可</li>
</ul>
<h3 id="检出某一分支-git-checkout"><a href="#检出某一分支-git-checkout" class="headerlink" title="检出某一分支 git checkout"></a>检出某一分支 git checkout</h3><ul>
<li>git checkout $BRANCH_NAME，注意不要带origin，git会自动将本地$BRANCH_NAME分支和远程origin/BRANCH_NAME分支绑定</li>
<li>类似linux shell中”cd -“，git也支持”git checkout -“切换到上一个分支</li>
</ul>
<h3 id="从origin更新分支-git-pull"><a href="#从origin更新分支-git-pull" class="headerlink" title="从origin更新分支 git pull"></a>从origin更新分支 git pull</h3><ul>
<li>若本地有未同步的提交（commit），建议使用rebase选项git pull –rebase。想了解rebase的目的及和merge的区别请看<a href="https://git-scm.com/book/zh/v2/Git-%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA" target="_blank" rel="external">这里</a></li>
<li>如果本地有未commit的变更，可以使用stash先暂存变更，更新后再恢复原有的变更<ol>
<li>git stash</li>
<li>git pull –rebase</li>
<li>git stash pop</li>
</ol>
</li>
</ul>
<h3 id="提交本地变更-git-commit"><a href="#提交本地变更-git-commit" class="headerlink" title="提交本地变更 git commit"></a>提交本地变更 git commit</h3><ul>
<li>git commit -m “testtest”</li>
</ul>
<h3 id="将本地变更同步到远程-git-push"><a href="#将本地变更同步到远程-git-push" class="headerlink" title="将本地变更同步到远程 git push"></a>将本地变更同步到远程 git push</h3><ul>
<li>git push</li>
</ul>
<h3 id="合并分支"><a href="#合并分支" class="headerlink" title="合并分支"></a>合并分支</h3><ul>
<li>git merge $TARGET_BRANCH。这里的分支可以指定本地或远程（带origin或不带origin），在保证本地跟远程是同步的情况下，这两种操作没有区别。建议使用先pull后merge origin/master这种操作</li>
</ul>
<h3 id="IDEA中的常用GUI操作"><a href="#IDEA中的常用GUI操作" class="headerlink" title="IDEA中的常用GUI操作"></a>IDEA中的常用GUI操作</h3><ul>
<li>​由于使用IDEA开发，所以也经常要在IDEA中进行代码的更新提交等操作，有一些操作用起来也很方便</li>
<li>pull操作，idea会自动使用stash和rebase选项（可配置），设置快捷键可以使代码的更新非常方便</li>
<li>commit操作，使用GUI可以方便的进行code review比对，减少错误代码甚至误提交的代码</li>
<li>冲突处理，IDEA中可以做local changes/remote changes比较，并合并出最终结果，非常方便</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/12/17/git命令行常用总结/" data-id="cjps0hy8r0004s6qhtpd6iu6j" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-Time-Series-Data-Introduction" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/11/27/Time-Series-Data-Introduction/" class="article-date">
  <time datetime="2018-11-27T10:15:07.000Z" itemprop="datePublished">2018-11-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/27/Time-Series-Data-Introduction/">Time-Series Data Introduction</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <ul>
<li>翻译自Time-ScaleDB博客：<a href="https://blog.timescale.com/what-the-heck-is-time-series-data-and-why-do-i-need-a-time-series-database-dcf3b1b18563" target="_blank" rel="external">What the heck is time series data</a></li>
</ul>
<h3 id="时间序列数据介绍"><a href="#时间序列数据介绍" class="headerlink" title="时间序列数据介绍"></a>时间序列数据介绍</h3><ul>
<li>我们先思考一个问题：特斯拉汽车自动驾驶系统、华尔街金融交易算法、智能家居系统、支持当日闪电送达的物流网络，以及纽约警察局的信息发布系统之间有什么共同点</li>
<li>首先他们都是我们的世界正在超速运转的缩影。随着技术的发展，数据的收集和处理能力越来越强，数据累积膨胀的速度也越来越快</li>
<li>但是，如果你进一步思考，应该可以注意到，上述的每一个系统都涉及一种特殊的数据<ul>
<li>自动驾驶汽车要持续收集汽车在行驶过程中不断变化的外部环境</li>
<li>金融交易系统要不断的收集瞬息万变的市场信息</li>
<li>智能家居实时监控家居内部的信息，支持它完成温度调节、识别入侵者、响应主人的指令等</li>
<li>我们习惯于便宜的当日达快递服务，背后是因为零售工业可以极为有效和准确的监控快速移动中的资产</li>
<li>纽约警察局跟踪警车的服务状态，以便更好的提供警务服务</li>
</ul>
</li>
<li>这些系统全都依赖一种特殊形式的数据，这种数据以时间为维度记录事务的状态变化。时间在这里不仅仅是一个属性，而是组织数据的主轴</li>
<li>这种数据就是我们要描述的时间序列数据（Time-Series Data），它正起到越来越重要的作用</li>
<li>DB-Engines提供的过去24个月不同类型数据库的增长曲线显示，时间序列数据库（以下简称TSDBs）是增长最快的数据库类型</li>
<li><img src="../images/db-ranking-categories.jpeg" alt="image"></li>
<li>作为一种全新的开源时间序列数据库开发者，我们经常被问及这种趋势和它所代表的意义。我们总结了以下三个问题，并进行深入回答<ul>
<li>什么是时间序列数据</li>
<li>我什么时候要用TSDBs</li>
<li>选择TimescaleDB的理由</li>
</ul>
</li>
</ul>
<h3 id="什么是时间序列数据time-series-data"><a href="#什么是时间序列数据time-series-data" class="headerlink" title="什么是时间序列数据time-series data"></a>什么是时间序列数据time-series data</h3><ul>
<li>有人认为时间序列数据是按时间排序的，描述同一事物的，一系列的数据点的集合。然而这只看到了表面特征</li>
<li>也有的人把time-series data看成是带时间戳和不同属性的数值，这实际上是time-series data的一种建模方式，不是time-series data本身</li>
<li>让我们继续深入</li>
<li>下图描述了一个简单的场景，图像感应器收集来自城市、农场、工厂的数据。每个数据源周期性的将收集到的数据发送发送出去</li>
<li><img src="https://cdn-images-1.medium.com/max/1600/1*GIOYjAyTjAaOK7HgAdAdVA.gif" alt="image"></li>
<li>举另一个例子，以下是纽约市2016年最初几秒记录的出租车运营信息，请注意下图，每行数据都是特定时间点的记录</li>
<li><img src="../images/nyc-taxi rides for the first few seconds of 2016.jpeg" alt="image"></li>
<li>更多time-series data的例子：devOps的监控数据，互联网/移动互联网应用的事件流，工业数据，科学计量数据等</li>
<li>这些数据集合有以下3个共同特征<ul>
<li><font color="red">数据只插入不更新</font><br>- <font color="red">数据按时间顺序写入</font><br>- <font color="red">时间是主轴</font></li>
</ul>
</li>
<li>换句话说，teim-series data基本都是append-only，只在修正错误数据等特殊情况下，会需要修改已插入的数据</li>
<li>所以，这<font color="red">跟在普通数据上加个时间戳有什么区别</font></li>
<li>这取决于如何跟踪数据变化，是在现有数据上更新，还是新增一条数据</li>
<li>从sensor_x传来的新数据，是覆盖原有的数据还是插入一条新数据？两种方法都能表示当前系统的状态，但是通过插入新数据，可以实现对系统历史状态（不同时间数据）的追踪</li>
<li>记住一条：time-series data通过插入新数据跟踪系统的变化</li>
<li>这种记录每时每刻系统的数据变化的实践方法，是time-series data强大功能的根本。通过历史数据跟踪系统变化：分析历史数据如何变化，监控当前系统状态，预测系统未来的变化趋势</li>
<li>综上，我们对time-series data的定义如下：<font color="red">通过一个数据集合跟踪反应系统/进程/行为随时间的变化过程的数据</font>我们的定义的核心就在“变化”</li>
<li>事实上，我们在很多场景都在不知情的情况下使用time-series data</li>
<li>以网站跟踪用户登录为例，一种方案是在一条数据上，每次都更新用户的最后登录时间；另一种方案是每次用户登录都记录一条登录数据，这样我们就可以跟踪历史登录活动，跟踪用户的使用增减情况，追踪用户的使用频率等</li>
<li>在这个例子中，通过分析数据固有的时间特征，我们可以从数据随时间的变化中，挖掘出更多有价值的信息（从这个例子可以想到，事件流数据也是time-series data）</li>
<li>当然，time-series data也有一个显而易见的问题：数据增长非常快</li>
<li>在这样大的数据量集下，高效的写入和查询数据就面临很多问题，这也正是人们开始使用time-series databases的原因</li>
</ul>
<h3 id="什么情况下使用TSDB"><a href="#什么情况下使用TSDB" class="headerlink" title="什么情况下使用TSDB"></a>什么情况下使用TSDB</h3><ul>
<li>为什么不能使用普通数据库（非time-series database）呢？</li>
<li>事实是，有很多人用的正是普通数据库，如下图</li>
<li><img src="../images/percentage of respondents.jpeg" alt="image"></li>
<li>但是，为什么多数受访者选择使用TSDB而不是普通数据库？为什么TSDB发展这么快？</li>
<li>2个原因：<ul>
<li>Scale。Time-Series data累积的速度非常快，普通数据库的设计思路没有专门考虑处理这么大的数据量级，关系数据库处理海量数据性能非常差，NoSQL在海量数据下性能表现要好些，但是仍远比不上设计优秀的time-series database。相反，TSDB（可能是基于关系数据设计实现的）针对time-series data的时间优先特性进行了改进设计。这种设计带来了性能的提升，包括更高的吞吐量、海量数据下的快速查询、以及更好的数据压缩。</li>
<li>Usability。TSDB也提供time-series data分析涉及的功能和操作。包括数据保留政策、持续查询、便捷的聚合功能等。即便在数据量不大的时候，这些特性也能提升time-series data操作过程的可用性和易用性</li>
</ul>
</li>
<li>这是开发者使用TSDB的原因，以下是一些典型的use case<ul>
<li>软件系统监控：虚拟机、容器、服务、应用等</li>
<li>物理系统监控：设备、机械、物联网、环境、家具、人体等</li>
<li>财务交易系统：保险行业、在线货币</li>
<li>事件应用：跟踪用户/客户交互信息</li>
<li>BI工具：跟踪business特性和整体的健康状况</li>
</ul>
</li>
<li>即便是TSDB普遍拥有这些强大的特性，根据实际的业务模型、读写特性选择合适的TSDB也很重要</li>
</ul>
<h3 id="使用TimescaleDB的优势"><a href="#使用TimescaleDB的优势" class="headerlink" title="使用TimescaleDB的优势"></a>使用TimescaleDB的优势</h3><ul>
<li>其它<a href="https://misfra.me/2016/04/09/tsdb-list/" target="_blank" rel="external">tsdb列表</a></li>
<li>TimescaleDB设计的初衷是使用完整的SQL特性，这是以上其它tsdb所不具备的特征</li>
<li>其它一些问题：<ul>
<li>查询延迟高</li>
<li>有些查询不支持</li>
<li>需要学习新的查询语言（非SQL）</li>
<li>不支持很多工具</li>
<li>很多数据要准备relational数据库和time-series 数据库两份数据</li>
</ul>
</li>
<li>为了解决这些问题，我们开发了TimescaleDB，并在Apache2 license下开源</li>
<li>如果你有以下需求，可以考虑TimescaleDB：<ul>
<li>通过SQL访问数据</li>
<li>统一关系数据库和tsdb</li>
<li>关系数据和time-series 数据连接查询</li>
<li>PostgreSQL</li>
<li>查询性能提升</li>
<li>geospatial支持</li>
<li>三方工具：SQL相关工具、BI工具</li>
</ul>
</li>
<li>如果你的业务有以下特征，不应该使用TimescaleDB<ul>
<li>查询方式简单（kv查询，简单一维查询）</li>
<li>稀松数据，非结构化数据</li>
</ul>
</li>
</ul>
<h3 id="延伸思考：所有的数据都是time-series-data？"><a href="#延伸思考：所有的数据都是time-series-data？" class="headerlink" title="延伸思考：所有的数据都是time-series data？"></a>延伸思考：所有的数据都是time-series data？</h3><ul>
<li>我们前文讲过，我们在很多场景都在使用time-series data但是我们没有意识到</li>
<li>考虑几个普通的数据集，比如银行的账户和流水、比如软件工程的源代码、博客内容</li>
<li>通常我们存储系统的最终状态。但是，如果换个思路，我们记录数据的每次变化，并在查询时计算当前状态。所谓的普通数据，不就是固有时间属性的数据集反应出的最终状态吗（从性能考虑缓存了最终状态）？软件源代码不是都有版本控制吗？博客本身不也有版本修订记录吗？</li>
<li>再者，是不是所有的数据库都有日志？</li>
<li>许多应用可能永远也不会用到time-series data，但是它们可以被认为是使用current-state view的TSDB版本。随着业务的发展，可能current-state view模式会产生瓶颈。这时候就可以考虑将数据转为time-series data。比如现在流行使用事件流来记录订单，从而更好的跟踪订单的历史状态和变化过程</li>
<li>是不是所有的数据都是time-series data呢？我们还没找到有说服力的反例来，如果你觉得有，欢迎联系我们讨论学习</li>
<li>最后，time-series data已经形成潮流，开始用起来吧！</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/11/27/Time-Series-Data-Introduction/" data-id="cjps0hy8o0003s6qhn19m5t6v" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-java团队code style规范" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/01/java团队code style规范/" class="article-date">
  <time datetime="2018-04-01T13:06:52.000Z" itemprop="datePublished">2018-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/01/java团队code style规范/">java团队code style规范</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="java团队code-style规范"><a href="#java团队code-style规范" class="headerlink" title="java团队code style规范"></a>java团队code style规范</h1><ul>
<li>摘选自《阿里巴巴Java开发手册》（孤尽），主要挑选个人感受最多的，影响代码阅读和维护、易于产生错误或误解的点，期望在团队层面建立良好的、易于接受推进的编码习惯和风格。</li>
<li>总结了少量重要的java知识点错用、误用的场景，需要在日常coding中避免</li>
<li>《阿里巴巴Java开发手册》原文可以在<a href="https://m.aliyun.com/yunqi/articles/215391" target="_blank" rel="external">阿里云</a>下载，也可以购买纸质版（略贵）、</li>
</ul>
<h2 id="Code-Style"><a href="#Code-Style" class="headerlink" title="Code Style"></a>Code Style</h2><h3 id="命名风格"><a href="#命名风格" class="headerlink" title="命名风格"></a>命名风格</h3><ul>
<li><font colore="blue">以达到代码自解释为目的</font></li>
<li>常量全部使用大写，单次之间用下划线”_”隔开；非常量及函数使用UpperCamelCase风格</li>
<li>不要嫌明明太长，不合理的缩写产生的影响远比多读几个单次要大</li>
<li>禁止使用拼音英文混合的命名方式，一般也不建议使用全拼音</li>
<li>数组定义统一使用String[] args的格式，不要使用String args[]</li>
<li>POJO类的bool类型变量不加is，防止有些框架解析错误（自动去掉is）</li>
</ul>
<h3 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h3><ul>
<li>拒绝magic value</li>
</ul>
<h3 id="代码格式"><a href="#代码格式" class="headerlink" title="代码格式"></a>代码格式</h3><ul>
<li>long类型赋值，用L结尾，不要用l，容易与1产生混淆。long testValue = 0L；不要用做long testValue = 0l</li>
<li>关于换行<ul>
<li>第二行相对第一行缩进4个空格，第三行开始不再持续缩进</li>
<li>运算符与下文一起缩进。<pre><code><br>boolean testFlag = aVeryLongNameMethodWithBoolReturnValueFoo1()<pre><code>&amp;&amp; anotherVeryLongNameMethodWithBoolReturnValueFoo2()
&amp;&amp; anotherVeryLongNameMethodWithBoolReturnValueFoo3();
</code></pre>  </code></pre></li>
<li>.与下文一起缩进。<pre><code><br>StringBuilder testStringBuilder = new StringBuilder()<pre><code>.append(&quot;test&quot;)
.append(&quot;test1&quot;);
</code></pre></code></pre></li>
</ul>
</li>
<li>不同逻辑、不同语义、不同业务的代码之间插入一个空行分隔开</li>
</ul>
<h3 id="OOP"><a href="#OOP" class="headerlink" title="OOP"></a>OOP</h3><ul>
<li>复写方法必须加@Override</li>
<li>开放出去的接口不允许修改或删除接口签名（包括类名、方法名、常量名）</li>
<li>禁止使用@Deprecated方法</li>
<li>Object.equals()，为防止NPE，使用”test”.equals(aStr)替代aStr.equals(“test”)</li>
<li>注意primitive类型比较时，注意auto box和unbox的规则，如不了解，全部是primitive时使用==，涉及包装类对象时，使用equals</li>
<li>POJO属性全部使用包装类对象，RPC方法参数、返回值使用包装类对象</li>
<li>类内部的方法定义顺序：public方法/protected方法 &gt; private方法 &gt; getter/setter</li>
<li>集合初始化时指定集合初始大小</li>
<li>Map遍历使用entrySet，不要使用keySet</li>
</ul>
<h3 id="控制语句"><a href="#控制语句" class="headerlink" title="控制语句"></a>控制语句</h3><ul>
<li>多重嵌套的if-else语句使用卫语句代替</li>
</ul>
<h3 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h3><ul>
<li>通过好的命名来达到自解释</li>
<li>类、类属性、类方法注释必须使用Javadoc规范，功能复杂的难以做到self descriptive的需要说明类和方法分别做什么事情，根据需要也应该增加复杂逻辑的解释</li>
<li>所有类都要添加创建者和创建日期</li>
</ul>
<h3 id="日志规约"><a href="#日志规约" class="headerlink" title="日志规约"></a>日志规约</h3><ul>
<li>使用占位符替代字符串拼接，特别注意debug日志，可以防止不必要的字符串拼接<pre><code><br>// 使用<br>log.debug(“processing trade, id={}, name={}”, id, name);<br>// 不使用<br>log.debug(“processing trade, id=” + id + “, name=” + name);<br></code></pre></li>
</ul>
<h3 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h3><ul>
<li>索引命名<ul>
<li>主键 PK_${fieldName}</li>
<li>唯一索引 UK_${fieldName}</li>
<li>普通索引 IDX_${fieldName}</li>
</ul>
</li>
<li>小数类型使用decimal，禁止使用double和float</li>
<li>表必备字段id，gmt_create, gmt_modified</li>
<li>varchar字段建索引时要指定长度，不需要全部索引</li>
<li>不要使用count(1), count(列名)替代count（*）</li>
<li>POJO类bool属性命名不能加is前缀，而数据库字段需加is</li>
<li>更新时指定字段更新，不要传入对象全部更新</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/04/01/java团队code style规范/" data-id="cjps0hy9d0008s6qhu0x57zn8" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-旅行行业基础数据本地管理" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/26/旅行行业基础数据本地管理/" class="article-date">
  <time datetime="2018-03-26T08:06:52.000Z" itemprop="datePublished">2018-03-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/26/旅行行业基础数据本地管理/">旅行行业基础数据本地管理</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><ul>
<li>旅行行业有许多稳定的、要查询反复使用的数据，如火车票的站点信息、航路信息，酒店的基础信息等。且这些数据往往单体数据较大，在频繁查询过程中要占用大量的网络带宽。</li>
<li>鉴于以上特点，我们考虑把这些数据放到其所在服务之中，不用再通过网络访问，由于数据稳定，使用定期同步（外加手动同步）的方式进行更新</li>
</ul>
<h1 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h1><ul>
<li>解决核心基础数据就（country,province,city,district,landmark,guide,intro等）的数据单点问题，减少其服务压力(20个系统依赖一个数据服务)</li>
<li>使用服务器上的本地存储，维护旅行行业基础信息，减少不必要的网络带宽占用，提高访问速度</li>
</ul>
<h1 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h1><h2 id="内存缓存"><a href="#内存缓存" class="headerlink" title="内存缓存"></a>内存缓存</h2><ul>
<li>在服务启动时，将数据库中存储的数据加载到内存中，并根据使用需要建立map，查询数据时用相关的key从map中取数据</li>
</ul>
<h3 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h3><pre><code>
    private static volatile Map<integer, hotelbrand=""> _hotelBrandResult = Maps.newHashMap();

    // 数据初始化，注意如果不使用ConcurrentMap，不能并发写数据
    protected boolean handle_DataInit() {
        boolean isSuccess = true;

        try {
            // 计算数据，填充数据
            Map<integer, hotelbrand=""> hotelBrandMap = Maps.newHashMap();
            List<hotelbrand> dataList = hotelBrandDao.queryListAll();
            for (HotelBrand data : dataList) {
                hotelBrandMap.put(data.getBrandID(), data);
            }

            _hotelBrandResult = hotelBrandMap;

            // 设置数据加载成功标识
            _isDataLoaded = true;

        } catch (Throwable ex) {
            isSuccess = false;
            getLogger().error(String.format(LogInfoUtils.HAS_DATA_TMPL, methodName, logData), ex);
        }

        return isSuccess;
    }

    /** ==================== 读取数据部分 ==================== **/
    /**
     * 读取酒店品牌数据
     * 
     * @param brandID
     * @return
     */
    public HotelBrand getHotelBrand(int brandID) {
        //缓存加载完成前查询，需要等待缓存加载完成
        if (checkLocalDataIsLoaded()) {
            if (_hotelBrandResult.containsKey(brandID)) {
                return _hotelBrandResult.get(brandID);
            }
        }

        return null;
    }
</hotelbrand></integer,></integer,></code></pre>

<h3 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h3><ul>
<li>优点<ul>
<li>现成的对象存储，无需ORMapping</li>
<li>访问速度最快</li>
</ul>
</li>
<li>缺点<ul>
<li>需要在服务启动时初始化，拖累启动速度；</li>
<li>只能KV存储，同一份数据，如果需要多个key，就需要建立多个map</li>
<li>如不阻塞服务，在服务上线时缓存可能仍未加载完成，导致服务长时间阻塞</li>
<li>当数据增长到一定规模，服务启动时间会长到无法接受</li>
</ul>
</li>
</ul>
<h2 id="BerkeleyDB"><a href="#BerkeleyDB" class="headerlink" title="BerkeleyDB"></a>BerkeleyDB</h2><h3 id="bdb简介"><a href="#bdb简介" class="headerlink" title="bdb简介"></a>bdb简介</h3><ul>
<li>设计思想：简单、小巧、可靠、高性能</li>
<li>kv存储，支持k-List<v>存储，支持secondary key，不支持sql，不需要sql编译解析</v></li>
<li>支持1000并发，最大256T存储</li>
<li>嵌入式数据库，不支持网络访问，与应用程序运行在一个地址空间，不需要进程间通信</li>
<li><a href="https://www.cnblogs.com/chenny7/p/4864547.html" target="_blank" rel="external">bdb架构设计分析</a></li>
<li>我们使用bdb java edition，<a href="http://www.oracle.com/technetwork/database/berkeleydb/overview/index-093405.html" target="_blank" rel="external">使用文档</a></li>
</ul>
<h3 id="设计思路"><a href="#设计思路" class="headerlink" title="设计思路"></a>设计思路</h3><ul>
<li>从基础数据源（一般是mysql或分库分表的mysql）</li>
<li>数据存储与访问</li>
<li>数据更新策略<ul>
<li>增量模式，通过数据时间戳（不支持物理删除）或数据库binlog</li>
<li>全量重新构建（时间较长，只在服务启动时检查）</li>
</ul>
</li>
<li>从PrimaryIndex可以进行K-V读取</li>
<li>从SubIndex可以进行</li>
</ul>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul>
<li>多个服务不能同时使用同一个数据库文件</li>
<li>注意cursor打开后需要手动关闭</li>
</ul>
<h3 id="代码示例-1"><a href="#代码示例-1" class="headerlink" title="代码示例"></a>代码示例</h3><ul>
<li>bdb java edition的DPL API可以方便的使用注解实现</li>
<li><p>数据对象,通过Persistent（在基类中使用）和Entity标示bdb的数具实体，@PrimaryKey和@SecondaryKey分别标示主键和外键。通常主键是1对1的（k-v），外键可以指定1对1，1对多，多对1，多对多等不同关系<pre><code><br>@Entity<br>@Getter@Setter<br>@ToString<br>public class HotelBasic extends HotelBase implements Serializable {</code></pre></p>
<p>  /**</p>
<ul>
<li><p>酒店类型枚举<br>*/<br>private HotelTypeEnum hotelType;</p>
<p>/**</p>
</li>
<li><p>酒店名称<br>*/<br>private String name = “”;</p>
<p>/**</p>
</li>
<li><p>酒店英文名称<br>*/<br>private String enName = “”;</p>
<p>/**</p>
</li>
<li>酒店地址<br>*/<br>private String address = “”;</li>
</ul>
</li>
</ul>
<p>}</p>
<p>@Persistent<br>@Getter@Setter<br>@ToString<br>public class HotelBase implements Serializable {<br>    private static final long serialVersionUID = 3692698826181676533L;</p>
<pre><code>/** =============== field =============== */
/**
 * hotelID
 */
@PrimaryKey
private int hotelID;

/**
 * 国家ID
 */
private int countryID;

/**
 * cityID
 */
@SecondaryKey(relate = MANY_TO_ONE)
private int cityID;

/**
 * 酒店级别
 */
private HotelSeriesEnum hotelSeries = HotelSeriesEnum.ECONOMY;
</code></pre><p>}</p>
<p></p>
<ul>
<li><p>数据操作</p>
<ul>
<li>依赖方引入包依赖，并加入服务开机启动配置（如servlet）。如果需要默认启用该缓存，也可以直接实现InitializingBean，但是因为数据量较大，且不同系统的依赖不同，因此都没有直接做默认启用。</li>
<li>同一个数据库文件不能被多服务并发访问。如果单机部署不同服务，可以配置环境变量来建立多个DbEnvironment。如HOTEL_BDB_DATA_DIRECTORY = new File(“/opt/bdb/$projectName/hotel/hotelbasic”)</li>
<li><p><pre><code><br>/**</code></pre></p>
<ul>
<li>Created by tomxiaodong on 17/4/6.<br>*/<br>@Slf4j<br>@Component<br>public class HotelBasic_BdbProxy extends HotelBdbProxyBase {</li>
</ul>
<p>private static File HOTEL_BDB_DATA_DIRECTORY;<br>private static EnvironmentConfig envConfig = (EnvironmentConfig) new EnvironmentConfig().setAllowCreate(true).setCacheSize(100<em>1024</em>1024);<br>private static StoreConfig storeConfig = new StoreConfig().setAllowCreate(true);<br>private Environment env;</p>
<p>static {<br>  HOTEL_BDB_DATA_DIRECTORY = new File(“/opt/bdb/hotel/hotelbasic”);</p>
<p>  if(!HOTEL_BDB_DATA_DIRECTORY.exists()) {</p>
<pre><code>HOTEL_BDB_DATA_DIRECTORY.mkdirs();
</code></pre><p>  }<br>}</p>
<p>private EntityStore hotelBasicStore;<br>private PrimaryIndex<integer, hotelbasic=""> pIdx;<br>private SecondaryIndex<integer, integer,="" hotelbasic=""> sIdx;</integer,></integer,></p>
<p>private final ExecutorService _dataInitExecutorPool = Executors.newCachedThreadPool();</p>
</li>
</ul>
</li>
</ul>
<pre><code>private Random rand = new Random();

@Resource
private BdbUpdateTime_BdbProxy bdbUpdateTime_BdbProxy;

@Resource
private SysCityDao sysCityDao;

@Resource
private HotelBasic_CacheProxy hotelBasic_CacheProxy;

@Resource
private HotelComment_CacheProxy hotelComment_CacheProxy;

/**
 * 读取某城市下的 HotelBasic 列表（全部）
 *
 * @param cityID
 * @return
 */

public List&lt;HotelBasic&gt; getHotelBasicList(int cityID) {
    List&lt;HotelBasic&gt; result = Lists.newArrayList();
    EntityCursor&lt;HotelBasic&gt; cursor = sIdx.subIndex(cityID).entities();
    cursor.forEach(x -&gt; result.add(x));
    cursor.close();
    return result;
}

/**
 * 读取某城市下的 HotelBasic 列表（每个酒店的评论必须大于minCommentCount，并且评分&gt;0）
 *
 * @param cityID
 * @param minCommentCount
 * @return
 */
public List&lt;HotelBasic&gt; getHotelBasicListHasComment(int cityID, int minCommentCount) {

    long now = System.currentTimeMillis();
    List&lt;HotelBasic&gt; result = Lists.newArrayList();

    List&lt;HotelBasic&gt; hotelBasics = getHotelBasicList(cityID);
    for (HotelBasic hotelBasic : hotelBasics) {
        if (hotelBasic.getCommentCount() &gt; minCommentCount &amp;&amp; hotelBasic.getScore() &gt; 0) {
            result.add(hotelBasic);
        }
    }
    return result;
}

/**
 * 读取 HotelBasic 对象
 *
 * @param hotelID
 * @return
 */
public HotelBasic getHotelBasic(int hotelID) {
    return pIdx.get(hotelID);
}

private void putHotelBasic(HotelBasic hotelBasic){
    pIdx.put(hotelBasic);
}

@Override
/**
* 从源数据同步
*/
public void syncData(boolean replace){
    long startTimeMillis = System.currentTimeMillis();
    Date lastUpdateTime = bdbUpdateTime_BdbProxy.getLastUpdateTime(getClass().getSimpleName());
    if(lastUpdateTime!=null){
        LocalDateTime ldt = LocalDateTime.ofEpochSecond(lastUpdateTime.getTime()/1000, 0, ZoneOffset.UTC);
        if(ldt.plusHours(getRefreshInterval()).isAfter(LocalDateTime.now())) {
            log.warn(&quot;sync hotelbasic bdb skipped!&quot;);
            return;
        }
    }

    try {
        Map&lt;Integer, List&lt;HotelBasic&gt;&gt; hotelBasicsMap = Maps.newHashMap();
        int total = 0;

        // 计算自由行目的城市ID列表
        //List&lt;Integer&gt; arrCityIDs = (!DebugConfigUtils.isDebug()) ? sysCityDao.querySolutionArrCityIDs() : new DebugCityConfigDaoProtoImpl().getDebugToCityIDs();
        List&lt;Integer&gt; arrCityIDs =sysCityDao.querySolutionArrCityIDs();

        // 多线程分批读取缓存数据
        List&lt;List&lt;Integer&gt;&gt; arrCityIDsList = CustomListMathUtils.splitToListsByListItemCount(arrCityIDs, 10);
        for (List&lt;Integer&gt; cityIDs : arrCityIDsList) {
            List&lt;Callable&lt;List&lt;HotelBasic&gt;&gt;&gt; tasks = Lists.newArrayList();
            for (final int cityID : cityIDs) {
                tasks.add(() -&gt; hotelBasic_CacheProxy.getCityHotelBasicList(cityID));
            }

            // 执行 Callable 线程，取得结果
            List&lt;Future&lt;List&lt;HotelBasic&gt;&gt;&gt; futures = _dataInitExecutorPool.invokeAll(tasks);
            for (Future&lt;List&lt;HotelBasic&gt;&gt; future : futures) {
                List&lt;HotelBasic&gt; hotelBasics = future.get();
                if(hotelBasics.size()&gt;0){
                    hotelBasicsMap.put(hotelBasics.get(0).getCityID(), hotelBasics);
                    total+=hotelBasics.size();
                }
            }
        }

        // 多线程分批读取酒店评论数
        int hasCommentCount = 0;
        for (Map.Entry&lt;Integer, List&lt;HotelBasic&gt;&gt; entry : hotelBasicsMap.entrySet()) {
            Map&lt;Integer, Integer&gt; hotelListCommentCountMap = getHotelListCommentCountMap(entry.getValue());

            for (HotelBasic hotelBasic : entry.getValue()) {
                if (hotelListCommentCountMap.containsKey(hotelBasic.getHotelID())) {
                    hasCommentCount++;
                    hotelBasic.setCommentCount(hotelListCommentCountMap.get(hotelBasic.getHotelID()));
                    putHotelBasic(hotelBasic);
                }
            }
        }

        bdbUpdateTime_BdbProxy.setLastUpdateTime(getClass().getSimpleName());

        log.warn(&quot;sync hotelbasic bdb success! totalCount:{}, hasCommentCount:{}, time consumed:{}&quot;, total, hasCommentCount, System.currentTimeMillis()-startTimeMillis);
    } catch (Throwable ex) {
        log.error(&quot;sync hotelbasic bdb failed!&quot;, ex);
    }

}

public long count(){
    return pIdx.count();
}

@Override
public long getRefreshInterval() {
    return 24*150;
}

@Override
public TimeUnit getIntervalTimeUnit() {
    return TimeUnit.HOURS;
}

/**
 * 多线程分批读取酒店评论数
 *
 * @param hotelBasics
 * @return
 */
private Map&lt;Integer, Integer&gt; getHotelListCommentCountMap(List&lt;HotelBasic&gt; hotelBasics) {
    Map&lt;Integer, Integer&gt; result = Maps.newHashMap();

    try {
        List&lt;Integer&gt; allHotelIDs = hotelBasics.stream().map(x -&gt; x.getHotelID()).collect(Collectors.toList());
        List&lt;List&lt;Integer&gt;&gt; hotelIDsList = CustomListMathUtils.splitToListsByListCount(allHotelIDs, PagingUtils.calPageCount(allHotelIDs.size(), 50));

        // 分批读取酒店评论数
        for (final List&lt;Integer&gt; hotelIDs : hotelIDsList) {
            List&lt;Callable&lt;KeyValuePair&lt;Integer, Integer&gt;&gt;&gt; tasks = Lists.newArrayList();
            for (final int hotelID : hotelIDs) {
                tasks.add(() -&gt; new KeyValuePair(hotelID, hotelComment_CacheProxy.getHotelCommentCount_All(hotelID)));
            }

            // 执行 Callable 线程，取得结果
            List&lt;Future&lt;KeyValuePair&lt;Integer, Integer&gt;&gt;&gt; futures = _dataInitExecutorPool.invokeAll(tasks);
            for (Future&lt;KeyValuePair&lt;Integer, Integer&gt;&gt; future : futures) {
                KeyValuePair&lt;Integer, Integer&gt; kv = future.get();
                result.put(kv.getKey(), kv.getValue());
            }
        }
    } catch (Throwable ex) {
        log.error(&quot;getHotelListCommentCountMap failed!&quot;, ex);
    }

    return result;
}

public PrimaryIndex&lt;Integer, HotelBasic&gt; getpIdx() {
    return pIdx;
}

public void close(){
    if(hotelBasicStore!=null){
        hotelBasicStore.close();
        hotelBasicStore = null;
    }
    if(env!=null) {
        env.close();
        env = null;
    }
}

public void init(){
    env = new Environment(HOTEL_BDB_DATA_DIRECTORY, envConfig);
    hotelBasicStore = new EntityStore(env, &quot;hotelBasic&quot;, storeConfig);
    pIdx = hotelBasicStore.getPrimaryIndex(Integer.class, HotelBasic.class);
    sIdx = hotelBasicStore.getSecondaryIndex(pIdx, Integer.class, &quot;cityID&quot;);
}
</code></pre><p>}<br></p>
<h3 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h3><ul>
<li>百万数据量，100M bdb缓存，K-V访问平均小于1ms，K-List<v>访问在1-5ms之间，峰值qps&gt;500</v></li>
<li>收集一组日志，通过ELK做图</li>
</ul>
<h1 id="深入BerkeleyDB"><a href="#深入BerkeleyDB" class="headerlink" title="深入BerkeleyDB"></a>深入BerkeleyDB</h1><ul>
<li>并发支持</li>
<li>cache</li>
<li>index<ul>
<li>secondary key</li>
<li>secondary database</li>
</ul>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/26/旅行行业基础数据本地管理/" data-id="cjps0hy9v000gs6qhxyzm51sr" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="shellcommands-shell-commands-case-study" class="article article-type-shellcommands" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/03/21/shell-commands-case-study/" class="article-date">
  <time datetime="2018-03-21T03:12:35.000Z" itemprop="datePublished">2018-03-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/21/shell-commands-case-study/">shell commands case study</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="高频shell命令及使用场景总结"><a href="#高频shell命令及使用场景总结" class="headerlink" title="高频shell命令及使用场景总结"></a>高频shell命令及使用场景总结</h1><ul>
<li><font color="blue">本文的目的是通过列举一些高频命令的常见使用场景，帮助后端开发或ops快速铺平道路，因此很多命令都只有很基础的使用方式，更多更深入的用法请使用man命令来阅读详尽的使用说明</font></li>
<li>不必因为自己会的命令不如别人多或不如别人熟练而沮丧，使自己能够高效的围绕linux平台工作学习才是最终的目的，只要通过持续的学习和使用就一定能很快达到</li>
</ul>
<h2 id="磁盘与文件"><a href="#磁盘与文件" class="headerlink" title="磁盘与文件"></a>磁盘与文件</h2><h3 id="基础磁盘文件操作"><a href="#基础磁盘文件操作" class="headerlink" title="基础磁盘文件操作"></a>基础磁盘文件操作</h3><ul>
<li>cp 使用-r选项来复制目录 cp -r a/b a1/b1</li>
<li>mkdir 使用-p选项创建嵌套的目录 mkdir -p a/b/c/d</li>
<li>rm -rf 强制静默删除，虽然看起来挺危险的，但是这确实是我最常使用的方式</li>
<li>mv 用来移动或重命名 mv a b</li>
<li>ls list directory，文件不多的时候一般我都使用ls -al以便一次性看到全部文件和必要的时间、大小等属性。可以创建一个别名alias ll = ‘ls -al’来更方便的使用</li>
<li>chmod 给指定文件增减权限 chmod o+x给文件增加可执行权限，写shell时肯定要用到</li>
<li>chown 改变文件owner， 有时候使用了错误的用户执行创建/复制/下载/安装等操作，会希望改变文件的owner</li>
</ul>
<h3 id="文件查找"><a href="#文件查找" class="headerlink" title="文件查找"></a>文件查找</h3><ul>
<li>find    <ul>
<li>按名称 -name，如查找当前目录以test加任意三个字符结尾的文件或文件夹find . -name “*test???” </li>
<li>按类型 -type，如查找当前目录所有文件：find . -type f</li>
<li>通过-exec来<font color="blue">批量操作</font><ul>
<li>find . -maxdepth 1 -name “*test” -exec rm -rf {} \;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="scp"><a href="#scp" class="headerlink" title="scp"></a>scp</h3><ul>
<li>复制远程目录到本地 scp -r root@10.0.0.1:/home/admin/test/ ./</li>
<li>复制本地文件到远程 scp ./test root@10.0.0.1:/home/admin/test/</li>
</ul>
<h2 id="字符处理"><a href="#字符处理" class="headerlink" title="字符处理"></a>字符处理</h2><h3 id="vi文件编辑"><a href="#vi文件编辑" class="headerlink" title="vi文件编辑"></a>vi文件编辑</h3><ul>
<li>vi<ul>
<li>上下左右j k l ;</li>
<li>f下一行 b上一行 Ctrl+f下一页 Ctrl+b上一页</li>
<li>查找 /</li>
<li>替换 :s替换当前行，:%s替换全文，可使用正则表达式</li>
<li>常用正则表达式（只按场景举例，基础规则可以参考<a href="http://qianjigui.iteye.com/blog/368449" target="_blank" rel="external">这里</a>）,学会用[a-zA-Z0-9]{m,n}的语法可以解决很多问题<ul>
<li>简化的ip地址[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}.[0-9]{1,3}</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="字符串查找与替换"><a href="#字符串查找与替换" class="headerlink" title="字符串查找与替换"></a>字符串查找与替换</h3><ul>
<li>grep 查找行。<font color="red">grep、awk、sed号称linux命令三剑客，如果你常年在服务端环境工作，或者你使用基于linux的开发环境（mac、ubuntu等），有必要熟练掌握这3个命令和基本的正则表达式，尽早舍弃那些低效的GUI吧！</font><ul>
<li>一般查找 grep “content” file</li>
<li>忽略大小写 grep -i “ConTEnt” file</li>
<li>反选（查找不包含指定内容的行） grep “inclusiveContent” file | grep -v “exclusiveContent” </li>
</ul>
</li>
<li>sed(stream editor for filtering and transforming text). 如果你经常使用vi，可以把这个命令理解为批量执行的vi命令。如果你man sed头痛的话，可以参考<a href="http://man.linuxde.net/sed" target="_blank" rel="external">这篇文章</a>其中有很多例子<ul>
<li>替换文件中的内容，类似vi中的:s和:%s。 sed -i “bak” ‘s/originContent/newContent/g’, 注意mac中必须指定 -i选项的备份文件后缀（如上述命令中的bak，自信的人可以直接使用空字符串””）</li>
<li>删除空白行，sed -i “bak” ‘/^$/d’ fileName</li>
<li>在第9行插入标记，sed -i “bak” ‘9a/tag’ fileName</li>
</ul>
</li>
</ul>
<h3 id="字符串截取"><a href="#字符串截取" class="headerlink" title="字符串截取"></a>字符串截取</h3><ul>
<li>awk类似sed，通常也是逐行接收文件内容，执行命令处理文本。不同的是，awk定义了自己的语言，叫做“样式扫描和处理语言”，通过创建剪短的程序读取文件、对数据进行排序、计算、生成报表等操作。使用方式为 awk ‘{pattern + action}’ {filenames}<ul>
<li>杀死某个关键字对应的进程 ps aux | grep tomcat | awk ‘{print $2}’ | xargs kill -9</li>
</ul>
</li>
<li>shell parameter expansion。把变量放入${}中，并指定一些特定的操作符，实现对变量的操作，通过这种方式，可以很便捷的对变量做很多常用的操作（比awk代码更简洁易上手，虽然功能没有awk多）<ul>
<li>如${parameter:7}返回截取字符串或数组第7位以后（不包括第7位）的子串或子集</li>
<li>${ #parameter}返回parameter的长度</li>
<li>${parameter##<em>:}返回左数最后一个:右边的内容，类似的${parameter#</em>:}返回的是左数第一个:右边的内容、${parameter%%:<em>}返回右数最后一个:左边的内容，${parameter%:</em>}返回右数第一个:左边的内容。这在文件名处理、行数据处理（如不同分隔符分隔的数据库记录）等很有用，特别是如果你的正则表达式也跟我一样二把刀，不想每次现用现查的话</li>
<li>IFS=’:’; arr=($line)可以把line数据按分隔符拆分并组织成数组，类似java中是String.split(“:”)。使用echo ${arr[0]}打印数组的第1个元素</li>
</ul>
</li>
</ul>
<h2 id="运维"><a href="#运维" class="headerlink" title="运维"></a>运维</h2><h3 id="ssh用于登陆远程linux服务器"><a href="#ssh用于登陆远程linux服务器" class="headerlink" title="ssh用于登陆远程linux服务器"></a>ssh用于登陆远程linux服务器</h3><ul>
<li>使用其他的linux终端（我使用的是iterm）来登陆远程linux服务器，可以像在本地终端一样使用各种命令操作远程服务器</li>
<li>通过将本地公钥复制到远程服务器的~/.ssh/authorized_keys文件实现免密登陆。</li>
<li>公钥的生成使用ssh-keygen -t rsa，密码可以设置为空，生成的公钥位于~/.ssh/id_rsa.pub</li>
<li>可以通过ssh，在脚本中批量登陆服务器执行命令。如你想一次性为多个服务器复制公钥，全部实现上述的免密登陆<pre><code><br>cat $fileName | while read line<br>do<br>  echo $line<br>  #在远程服务器创建.ssh目录<br>  ssh -n root@$line “mkdir -p /root/.ssh &amp;&amp; touch /root/.ssh/authorized_keys”<br>  #复制key到远程服务器<br>  ssh root@$line  “cat &gt;&gt; /root/.ssh/authorized_keys” &lt; ~/.ssh/id_rsa.pub<br>done<br></code></pre></li>
<li>-n选项可以防止标准输入打断批量脚本执行</li>
</ul>
<h3 id="top-amp-free"><a href="#top-amp-free" class="headerlink" title="top &amp; free"></a>top &amp; free</h3><ul>
<li>top。查看当前系统状态、各进程的资源（cpu、内存、load等）占用情况，想详细了解各行各列内容可以参考这篇<a href="https://www.cnblogs.com/dragonsuc/p/5512797.html" target="_blank" rel="external">文章</a><ul>
<li>打开top后，输入M按内存顺序排列进程，查看占用内存最多的进程 </li>
<li>P按cpu占用排序</li>
<li>多核状态下，默认显示的是所有cpu平均值，输入1查看多核各cpu的状态</li>
<li>top -Hp <pid>可以查看指定进程的所有线程的状态</pid></li>
</ul>
</li>
<li>free。top中显示的内存包含了buffer/cache占用，系统一般都会尽量多的占用内存以提升响应速度，所以可以用free命令来查看实际使用中的内存情况。<ul>
<li>free -m</li>
<li>考虑JVM占用内存时不能只考虑堆大小，堆大小可能只占整个虚拟机的40%，以一个2G大小堆的java进程为例，通常要预留2G（2M*1000线程）的栈内存，1G的Meta和其它内容。这意味着你要在系统中为java进程预留大约5G的内存</li>
</ul>
</li>
</ul>
<h3 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h3><ul>
<li>查看所有进程并按进程号过滤 ps -ef | grep <pid></pid></li>
<li>同上述命令类似，不过这个命令使用的是bsd格式来展示进程信息，并按关键字过滤，关键字可以是tomcat、项目名称等 ps aux | grep <keyword></keyword></li>
</ul>
<h3 id="netstat"><a href="#netstat" class="headerlink" title="netstat"></a>netstat</h3><ul>
<li>遇到端口被占用情况时可以用netstat -ap查看所有连接的端口和进程号，从而找到未正确退出或重复启动，导致新进程不能启动的进程。 netstat -ap | grep <port></port></li>
</ul>
<h3 id="var-logs-message"><a href="#var-logs-message" class="headerlink" title="/var/logs/message"></a>/var/logs/message</h3><ul>
<li>记录了一些系统级别的记录，比如目前我们遇到的最常见的是oomkill记录，由于服务压力较大，有时候会遇到物理内存耗尽，系统杀死内存大户的情况。如果你遇到一些奇怪的系统问题，比如进程莫名其妙没了，也没有留下退出日志(hs<em>err</em><pid>)，可以在这里查看</pid></li>
</ul>
<h3 id="var-logs-security"><a href="#var-logs-security" class="headerlink" title="/var/logs/security"></a>/var/logs/security</h3><ul>
<li>这个日志记录了一些安全方面的信息，可以查看是否有被暴力ssh登陆；有时候我们的ip被denyhosts误伤，可以在这里查到日志（当然也可以直接在denyhosts中查看）。<h3 id="keygen"><a href="#keygen" class="headerlink" title="keygen"></a>keygen</h3></li>
<li>keygen用来为系统用户生成密钥对，在ssh免密登陆和git访问等场景经常需要<ul>
<li>ssh-keygen -t rsa</li>
</ul>
</li>
</ul>
<h3 id="ulimit"><a href="#ulimit" class="headerlink" title="ulimit"></a>ulimit</h3><h3 id="du-amp-df"><a href="#du-amp-df" class="headerlink" title="du&amp;df"></a>du&amp;df</h3><ul>
<li>怀疑磁盘空间不足时，使用df查看</li>
<li>用du确定当前目录的磁盘占用情况<ul>
<li>用du -m以MegaByte为单位显示占用量</li>
<li>如果文件太多，可以用du –max-depth=1只显示当前目录（不递归查看子目录）</li>
</ul>
</li>
</ul>
<h3 id="curl"><a href="#curl" class="headerlink" title="curl"></a>curl</h3><ul>
<li>获取网页内容curl <a href="http://www.baidu.com" target="_blank" rel="external">http://www.baidu.com</a></li>
<li>下载文件。curl -O www.xxx.com/download/aaa.zip</li>
</ul>
<h1 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h1><h2 id="2017-06-13-load过高问题"><a href="#2017-06-13-load过高问题" class="headerlink" title="2017.06.13 load过高问题"></a>2017.06.13 load过高问题</h2><ul>
<li>热点代码定位 参考<a href="http://javaeesupportpatterns.blogspot.ca/2012/02/prstat-linux-how-to-pinpoint-high-cpu.html" target="_blank" rel="external">这里</a><ol>
<li>使用jstack <pid> &gt; /tmp/a dump线程到文件备查</pid></li>
<li>使用top -Hp <pid> 查看占用cpu最高的线程</pid></li>
<li>将2中linux线程id转为16进制，在1中文件查找，找到对应线程</li>
<li>如果是线程池pool-1-thread-1形式的线程，通常在栈信息中无法定位到具体的业务代码，你需要先把系统所有线程池自定义名称。如ExecutorService executor = Executors.newXXXExecutor(r -&gt; new Thread(r, “arbitrary-pool-thread-“))</li>
<li>找到有问题的代码，优化相关代码</li>
</ol>
</li>
<li>相关工具<ul>
<li>jstack <pid></pid></li>
<li>top -Hp <pid></pid></li>
<li>greys，在线诊断，类似btrace，但是使用更轻量（无需编写代码）。可以在线查看方法执行时间、追踪方法的每一步执行时间、方法调用次数和参数返回值等，非常强大。<a href="https://github.com/oldmanpushcart/greys-anatomy" target="_blank" rel="external">https://github.com/oldmanpushcart/greys-anatomy</a></li>
</ul>
</li>
</ul>
<h2 id="2017-07-12-load过高、内存泄漏问题"><a href="#2017-07-12-load过高、内存泄漏问题" class="headerlink" title="2017.07.12 load过高、内存泄漏问题"></a>2017.07.12 load过高、内存泄漏问题</h2><ol>
<li>热点代码定位同上，确认是VM线程gc overhead占用cpu，判断是内存已满</li>
<li>jstack -gcold <pid> 确认堆已满，一直fullgc且没有腾出内存</pid></li>
<li>jmap -histo <pid> 下载内存镜像</pid></li>
<li>使用mat查看对象最多的类型，定位问题</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/03/21/shell-commands-case-study/" data-id="cjps0hy9l000as6qhxhqu3t9o" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/shell-linux-ops/">shell,linux,ops</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-servermonitoring" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/07/15/servermonitoring/" class="article-date">
  <time datetime="2017-07-15T04:52:58.000Z" itemprop="datePublished">2017-07-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="系统监控"><a href="#系统监控" class="headerlink" title="系统监控"></a>系统监控</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li>目标</li>
<li>原理</li>
<li>方案选择<ul>
<li>商业方案：本地oneAPM(本地化服务)，国际NETWAYS（便宜，价钱一半）</li>
</ul>
</li>
</ul>
<h2 id="icinga介绍"><a href="#icinga介绍" class="headerlink" title="icinga介绍"></a>icinga介绍</h2><ul>
<li>简介</li>
<li>核心概念</li>
<li>模型</li>
</ul>
<h2 id="icinga实践"><a href="#icinga实践" class="headerlink" title="icinga实践"></a>icinga实践</h2><h3 id="服务监控搭建"><a href="#服务监控搭建" class="headerlink" title="服务监控搭建"></a>服务监控搭建</h3><h3 id="监控集群设计方案"><a href="#监控集群设计方案" class="headerlink" title="监控集群设计方案"></a>监控集群设计方案</h3><ul>
<li>监控报警</li>
<li>报表接入</li>
<li>配置方案选择：底层文件配置 or 可视化配置 Icinga Director</li>
<li>主机监控<ul>
<li>ping</li>
<li>ssh -p</li>
</ul>
</li>
<li>redis监控</li>
<li>ssdb监控</li>
<li>mysql监控</li>
</ul>
<h3 id="master机器迁移"><a href="#master机器迁移" class="headerlink" title="master机器迁移"></a>master机器迁移</h3><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><h3 id="1000个基于perl脚本命令的service导致high-load问题"><a href="#1000个基于perl脚本命令的service导致high-load问题" class="headerlink" title="1000个基于perl脚本命令的service导致high load问题"></a>1000个基于perl脚本命令的service导致high load问题</h3><p>### </p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/07/15/servermonitoring/" data-id="cjps0hy9h0009s6qht3f8wxf2" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


  <nav id="page-nav">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">__('next') &raquo;</a>
  </nav>
</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/bigdata/">bigdata</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elasticsearch/">elasticsearch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/shell-linux-ops/">shell,linux,ops</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/用户触达/">用户触达</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/运维-DevOps/">运维,DevOps</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/bigdata/" style="font-size: 10px;">bigdata</a> <a href="/tags/elasticsearch/" style="font-size: 10px;">elasticsearch</a> <a href="/tags/shell-linux-ops/" style="font-size: 10px;">shell,linux,ops</a> <a href="/tags/用户触达/" style="font-size: 10px;">用户触达</a> <a href="/tags/运维-DevOps/" style="font-size: 10px;">运维,DevOps</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/04/">April 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/12/20/服务集群异常监控/">服务监控</a>
          </li>
        
          <li>
            <a href="/2018/12/20/旅行基础数据搜索/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/12/19/筋斗云ELK集群/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/12/17/lucene数据结构解析/">(no title)</a>
          </li>
        
          <li>
            <a href="/2018/12/17/git命令行常用总结/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 SeventyNine<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>